{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of SimCLR with training the encoder and after the classification head\n",
    "\n",
    "**The encoder can be pretrained using an unsupervised way. It is after trained using the SimCLR algorithm and the classification head is trained by supervised learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # disable GPU devices\n",
    "os.environ[\"TFDS_DATA_DIR\"] = os.path.expanduser(\"~/tensorflow_datasets\")  # default location of tfds database\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import keras\n",
    "from keras import layers, models, regularizers\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import librosa.display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Turn off logging for TF\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "from dpmhm.datasets import preprocessing, feature, utils, transformer\n",
    "\n",
    "ds_all, ds_info = tfds.load(\n",
    "    'CWRU',\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "ds0 = ds_all['train']\n",
    "ds0.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compactor = transformer.DatasetCompactor(ds0,\n",
    "                                         channels=['DE', 'FE', 'BA'],\n",
    "                                         keys=['FaultLocation', 'FaultComponent', 'FaultSize'],\n",
    "                                         resampling_rate=12000)\n",
    "\n",
    "# Feature extractor\n",
    "# Spectrogram is computed on a time window of 0.025 second every 0.0125 second, then converted to decibel scale.\n",
    "_func = lambda x, sr: feature.spectral_features(x, sr, 'spectrogram',\n",
    "#                                                 n_mfcc=256,\n",
    "                                                time_window=0.025, hop_step=0.0125, n_fft=512,\n",
    "                                                normalize=False, to_db=True)[0]\n",
    "\n",
    "extractor = transformer.FeatureExtractor(compactor.dataset, _func)\n",
    "\n",
    "# A window of width w correspond to w*0.0125 seconds\n",
    "window = transformer.WindowSlider(extractor.dataset, window_size=(64,64), hop_size=(32,32))\n",
    "# window = transformer.WindowSlider(extractor.dataset, window_size=(256, 80), hop_size=40)  # 1s, full bandwidth\n",
    "# window = transformer.WindowSlider(extractor.dataset, window_size=64, hop_size=32)\n",
    "\n",
    "labels = list(compactor.full_label_dict.keys())\n",
    "\n",
    "preproc = preprocessing.get_mapping_supervised(labels)\n",
    "    \n",
    "ds_window = window.dataset.map(preproc, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "eles = list(ds_window.take(10).as_numpy_iterator())\n",
    "input_shape = eles[0][0].shape\n",
    "\n",
    "ds_window = ds_window.map(lambda x,y: (tf.ensure_shape(x, input_shape), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "splits = {'train':0.7, 'val':0.2, 'test':0.1}\n",
    "ds_split = utils.split_dataset(ds_window, splits, ds_size=int(ds_window.cardinality()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "ds_size = sum([1 for _ in ds_window])\n",
    "n_embedding  = 128 #128\n",
    "kernel_size = (3,3) #(3,3)\n",
    "tau = 0.1\n",
    "projection_dim = 128 #512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With an encoder from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Autoencoder**\n",
    "\n",
    "Adapt data for the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_split['train'].map(lambda x,l:(x,x))\n",
    "ds_val = ds_split['val'].map(lambda x,l:(x,x)).batch(batch_size)\n",
    "\n",
    "ds_train = ds_train.shuffle(ds_size, reshuffle_each_iteration=True).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.utils.register_keras_serializable()\n",
    "class Autoencoder(models.Model):\n",
    "    \"\"\"Convolution Auto-Encoder stacks.\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Shape (H,W) of the input tensor must be power of 2.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape, n_embedding,kernel_size):\n",
    "        self.input_shape = input_shape\n",
    "        activation = 'relu'\n",
    "        padding = 'same'\n",
    "        strides = (2,2)\n",
    "        pool_size = (2,2)\n",
    "        a_reg = 0. \n",
    "\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        # Use more blocks and larger kernel size to get more smoothing in the reconstruction.\n",
    "        input_layer= layers.Input(shape=input_shape, name='input_enc')\n",
    "\n",
    "        layers_encoder = [\n",
    "            # Block 1\n",
    "            layers.Conv2D(32, kernel_size=kernel_size, activation=activation, padding=padding, name='conv1_enc'),\n",
    "            layers.MaxPooling2D(pool_size=pool_size, strides=strides, name='pool1_enc'),\n",
    "            layers.BatchNormalization(name='bn1_enc'), # by default axis=-1 for channel-last\n",
    "\n",
    "            # Block 2\n",
    "            layers.Conv2D(64, kernel_size=kernel_size, activation=activation, padding=padding, name='conv2_enc'),\n",
    "            layers.MaxPooling2D(pool_size=pool_size, strides=strides, name='pool2_enc'),\n",
    "            layers.BatchNormalization(name='bn2_enc'),\n",
    "\n",
    "            # Block 3\n",
    "            layers.Conv2D(128, kernel_size=kernel_size, activation=activation, padding=padding, name='conv3_enc'),\n",
    "            layers.MaxPooling2D(pool_size=pool_size, strides=strides, name='pool3_enc'),\n",
    "            layers.BatchNormalization(name='bn3_enc'),\n",
    "\n",
    "            # # Block 4\n",
    "            # layers.Conv2D(256, kernel_size=kernel_size, activation=activation, padding=padding, name='conv4_enc'),\n",
    "            # layers.MaxPooling2D(pool_size=pool_size, strides=strides, name='pool4_enc'),\n",
    "            # layers.BatchNormalization(name='bn4_enc'),\n",
    "\n",
    "            # Block fc\n",
    "            layers.Flatten(name='flatten'),\n",
    "            layers.Dense(n_embedding, activation=activation,activity_regularizer=regularizers.L1(a_reg), name='fc1_enc') if a_reg > 0\n",
    "            else layers.Dense(n_embedding, activation=activation, name='fc1_enc')\n",
    "        ]\n",
    "\n",
    "        self.encoder = models.Sequential([input_layer] +layers_encoder, name='encoder')\n",
    "\n",
    "        output_layer = layers.Input(shape=(n_embedding,), name='input_dec')\n",
    "        layers_decoder = [\n",
    "            # Block fc\n",
    "            layers.Dense(128 * (input_shape[0] // 8) * (input_shape[1] // 8), activation=activation, activity_regularizer=regularizers.L1(a_reg), name='fc1_dec') if a_reg > 0 else layers.Dense(128 * (input_shape[0] // 8) * (input_shape[1] // 8), activation=activation, name='fc1_dec'),\n",
    "            layers.Reshape((input_shape[0] // 8, input_shape[1] // 8, 128), name='reshape'),\n",
    "\n",
    "            # # Block 4\n",
    "            # layers.BatchNormalization(name='bn4_dec'),\n",
    "            # layers.UpSampling2D(strides, name='ups4_dec'),\n",
    "            # layers.Conv2DTranspose(128, kernel_size=kernel_size, activation=activation, padding=padding, name='tconv4_dec'),\n",
    "\n",
    "            # Block 3\n",
    "            layers.BatchNormalization(name='bn3_dec'),\n",
    "            layers.UpSampling2D(strides, name='ups3_dec'),\n",
    "            layers.Conv2DTranspose(64, kernel_size=kernel_size, activation=activation, padding=padding, name='tconv3_dec'),\n",
    "\n",
    "            # Block 2\n",
    "            layers.BatchNormalization(name='bn2_dec'),\n",
    "            layers.UpSampling2D(strides, name='ups2_dec'),\n",
    "            layers.Conv2DTranspose(32, kernel_size=kernel_size, activation=activation, padding=padding, name='tconv2_dec'),\n",
    "\n",
    "            # Block 1\n",
    "            layers.BatchNormalization(name='bn1_dec'),\n",
    "            layers.UpSampling2D(strides, name='ups1_dec'),\n",
    "            layers.Conv2DTranspose(input_shape[-1], kernel_size=kernel_size, activation=None, padding=padding, name='tconv1_dec'),\n",
    "        ]\n",
    "\n",
    "        self.decoder = models.Sequential([output_layer] + layers_decoder, name='decoder')\n",
    "        # self.decoder.build()\n",
    "\n",
    "        self.autoencoder = models.Sequential([input_layer] + layers_encoder + layers_decoder, name='auto-encoder')\n",
    "        # self.build(input_shape=(None, *input_shape))\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.decoder(self.encoder(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and train the autoencoder on unlabeled data under the form (img,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder(input_shape,n_embedding,kernel_size)\n",
    "\n",
    "# autoencoder.compile(\n",
    "#     optimizer=keras.optimizers.Adam(),\n",
    "#     loss=keras.losses.MeanSquaredError(),\n",
    "#     # metrics=['accuracy'],\n",
    "# )\n",
    "\n",
    "# history = autoencoder.fit(\n",
    "#     ds_train,\n",
    "#     validation_data=ds_val,\n",
    "#     epochs=10,\n",
    "#     callbacks=keras.callbacks.EarlyStopping(verbose=1, patience=3),\n",
    "#     steps_per_epoch=int((0.7*ds_size) // batch_size)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder.save_weights('model_weights.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder.load_weights('model_weights.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contrastive learning on the encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training data\n",
    "ds_train = ds_split['train'].shuffle(ds_size, reshuffle_each_iteration=True).cache().batch(batch_size,drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "ds_val = ds_split['val'].batch(batch_size,drop_remainder=True)\n",
    "ds_test = ds_split['test'].batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrastive loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss_fn(z_i, z_j, tau=0.5):\n",
    "    z_i = tf.math.l2_normalize(z_i, axis=1)\n",
    "    z_j = tf.math.l2_normalize(z_j, axis=1)\n",
    "\n",
    "    # Compute the similarity matrix\n",
    "    similarity_matrix = tf.matmul(z_i, z_j, transpose_b=True) / tau\n",
    "\n",
    "    # Compute the positive similarity\n",
    "    positive_similarity = tf.linalg.diag_part(similarity_matrix)\n",
    "\n",
    "    # Compute the negative similarity\n",
    "    negative_similarity = tf.linalg.set_diag(similarity_matrix, tf.zeros_like(tf.linalg.diag_part(similarity_matrix)))\n",
    "\n",
    "    # Compute the numerator of the loss function\n",
    "    numerator = tf.exp(positive_similarity)\n",
    "\n",
    "    # Compute the denominator of the loss function\n",
    "    denominator = tf.reduce_sum(tf.exp(negative_similarity), axis=1)\n",
    "\n",
    "    # Compute the loss function\n",
    "    loss = -tf.reduce_mean(tf.math.log(numerator / denominator))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the SimCLR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "\n",
    "# Define the contrastive model with model-subclassing\n",
    "class SimCLRModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.tau = tau\n",
    "\n",
    "        self.contrastive_augmenter = keras.Sequential([\n",
    "            layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "            layers.RandomZoom(0.2),\n",
    "            layers.RandomTranslation(height_factor=0.2, width_factor=0.2),\n",
    "        ], name='Data_augmentation')\n",
    "        \n",
    "        self.encoder = autoencoder.encoder\n",
    "\n",
    "        self.projection_head = keras.Sequential([\n",
    "                layers.Dense(256, activation='relu'),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Dense(128, activation='relu'),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Dense(projection_dim),\n",
    "            ], name='Projection_head')\n",
    "        \n",
    "        self.classification_head = keras.Sequential([\n",
    "                layers.Dense(128, activation='relu', input_shape=(128,)),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Dense(30) #nb labels\n",
    "            ], name='Classification_head')\n",
    "\n",
    "    def compile(self, contrastive_optimizer, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "\n",
    "        self.contrastive_optimizer = contrastive_optimizer\n",
    "\n",
    "        self.contrastive_loss_tracker = keras.metrics.Mean(name=\"c_loss\")\n",
    "        self.mean_cosine_similarity = keras.metrics.Mean(name=\"mean_cosine_similarity\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.contrastive_loss_tracker,\n",
    "            self.mean_cosine_similarity,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        train_image, _ = data\n",
    "        \n",
    "        # Each set of unlabeled images is augmented separately\n",
    "        augmented_image_1 = self.contrastive_augmenter(train_image, training=True)\n",
    "        augmented_image_2 = self.contrastive_augmenter(train_image, training=True)\n",
    "        \n",
    "        if tf.reduce_all(augmented_image_1 == augmented_image_2):\n",
    "            print(\"Augmented train images are identical!\")\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Extract features and compute projections for the first set of images\n",
    "            features_1 = self.encoder(augmented_image_1, training=True)\n",
    "            projections_1 = self.projection_head(features_1, training=True)\n",
    "            \n",
    "            # Extract features and compute projections for the second set of images\n",
    "            features_2 = self.encoder(augmented_image_2, training=True)\n",
    "            projections_2 = self.projection_head(features_2, training=True)\n",
    "            \n",
    "            # Compute contrastive loss\n",
    "            contrastive_loss = contrastive_loss_fn(projections_1, projections_2, self.tau)\n",
    "        \n",
    "        # Compute gradients and apply updates for the contrastive loss\n",
    "        gradients = tape.gradient(\n",
    "            contrastive_loss,\n",
    "            self.encoder.trainable_weights + self.projection_head.trainable_weights,\n",
    "        )\n",
    "        self.contrastive_optimizer.apply_gradients(\n",
    "            zip(\n",
    "                gradients,\n",
    "                self.encoder.trainable_weights + self.projection_head.trainable_weights,\n",
    "            )\n",
    "        )\n",
    "        self.contrastive_loss_tracker.update_state(contrastive_loss)\n",
    "        \n",
    "        cosine_similarity = tf.reduce_mean(keras.losses.cosine_similarity(projections_1, projections_2))\n",
    "        self.mean_cosine_similarity.update_state(cosine_similarity)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics[:2]}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        test_image, _ = data\n",
    "\n",
    "        # Compute contrastive loss on the validation set\n",
    "        augmented_image_1 = self.contrastive_augmenter(test_image, training=True)\n",
    "        augmented_image_2 = self.contrastive_augmenter(test_image, training=True)\n",
    "\n",
    "        features_1 = self.encoder(augmented_image_1, training=False)\n",
    "        features_2 = self.encoder(augmented_image_2, training=False)\n",
    "\n",
    "        projections_1 = self.projection_head(features_1, training=False)\n",
    "        projections_2 = self.projection_head(features_2, training=False)\n",
    "        \n",
    "        contrastive_loss = contrastive_loss_fn(projections_1, projections_2, self.tau)\n",
    "        self.contrastive_loss_tracker.update_state(contrastive_loss)\n",
    "\n",
    "        cosine_similarity = tf.reduce_mean(keras.losses.cosine_similarity(projections_1, projections_2))\n",
    "        self.mean_cosine_similarity.update_state(cosine_similarity)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and train SimCLR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretraining_model = SimCLRModel()\n",
    "\n",
    "pretraining_model.compile(\n",
    "    contrastive_optimizer=keras.optimizers.Adam(),\n",
    ")\n",
    "\n",
    "pretraining_history = pretraining_model.fit(\n",
    "    ds_train.repeat(), epochs=15, validation_data=ds_val, steps_per_epoch=int((0.7*ds_size) // batch_size),\n",
    ")\n",
    "\n",
    "pretraining_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('c_loss', color=color)\n",
    "ax1.plot(pretraining_history.history['c_loss'], color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('mean_cosine_similarity', color=color) \n",
    "ax2.plot(pretraining_history.history['mean_cosine_similarity'], color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.title('Evolution of metrics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the encoder weights\n",
    "pretraining_model.encoder.trainable = False\n",
    "\n",
    "# Create a new classification model\n",
    "encoder_output = pretraining_model.encoder(pretraining_model.encoder.layers[0].input)\n",
    "classification_model = keras.Model(\n",
    "    inputs=pretraining_model.encoder.layers[0].input,\n",
    "    outputs=pretraining_model.classification_head(encoder_output)\n",
    ")\n",
    "classification_model.summary(show_trainable=True, expand_nested=True)\n",
    "\n",
    "classification_model.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "classification_history = classification_model.fit(ds_train, epochs=5, validation_data=ds_val, steps_per_epoch=int((0.7*ds_size) // batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = classification_model.evaluate(ds_test)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Evaluation Loss:\", evaluation[0])\n",
    "print(\"Evaluation Accuracy: {:.2f}%\".format(evaluation[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
