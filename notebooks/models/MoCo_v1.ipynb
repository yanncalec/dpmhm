{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of the MoCo algorithm with training the encoder and after the clasification_head\n",
    "\n",
    "**The encoder can be pretrained using an unsupervised way. It is after trained using the SimCLR algorithm and the classification head is trained by supervised learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 13:42:29.259857: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-02 13:42:29.264743: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-02 13:42:29.326754: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-02 13:42:30.598242: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-07-02 13:42:33.191728: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-07-02 13:42:33.191772: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:134] retrieving CUDA diagnostic information for host: is230816\n",
      "2024-07-02 13:42:33.191788: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:141] hostname: is230816\n",
      "2024-07-02 13:42:33.191950: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:165] libcuda reported version is: 535.183.1\n",
      "2024-07-02 13:42:33.191995: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:169] kernel reported version is: 535.183.1\n",
      "2024-07-02 13:42:33.192008: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:248] kernel version seems to match DSO: 535.183.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metadata': {'Dataset': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       "  'FaultComponent': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       "  'FaultLocation': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       "  'FaultSize': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  'FileName': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       "  'LoadForce': TensorSpec(shape=(), dtype=tf.uint32, name=None),\n",
       "  'NominalRPM': TensorSpec(shape=(), dtype=tf.uint32, name=None),\n",
       "  'RPM': TensorSpec(shape=(), dtype=tf.uint32, name=None)},\n",
       " 'sampling_rate': TensorSpec(shape=(), dtype=tf.uint32, name=None),\n",
       " 'signal': {'BA': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'DE': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'FE': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # disable GPU devices\n",
    "os.environ[\"TFDS_DATA_DIR\"] = os.path.expanduser(\"~/tensorflow_datasets\")  # default location of tfds database\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import keras\n",
    "from keras import layers, models, regularizers\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Turn off logging for TF\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "from dpmhm.datasets import preprocessing, feature, utils, transformer\n",
    "\n",
    "ds_all, ds_info = tfds.load(\n",
    "    'CWRU',\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "ds0 = ds_all['train']\n",
    "ds0.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = Path('/volatile/home/bm279471/tmp/few_shot_cwru')\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# compactor = transformer.DatasetCompactor(ds0,\n",
    "#                                          channels=['DE', 'FE', 'BA'],\n",
    "#                                          keys=['FaultLocation', 'FaultComponent', 'FaultSize'],\n",
    "#                                          resampling_rate=12000)\n",
    "\n",
    "# # Feature extractor\n",
    "# # Spectrogram is computed on a time window of 0.025 second every 0.0125 second, then converted to decibel scale.\n",
    "# _func = lambda x, sr: feature.spectral_features(x, sr, 'spectrogram',\n",
    "# #                                                 n_mfcc=256,\n",
    "#                                                 time_window=0.025, hop_step=0.0125, n_fft=512,\n",
    "#                                                 normalize=False, to_db=True)[0]\n",
    "\n",
    "# extractor = transformer.FeatureExtractor(compactor.dataset, _func)\n",
    "\n",
    "# # A window of width w correspond to w*0.0125 seconds\n",
    "# window = transformer.WindowSlider(extractor.dataset, window_size=(64,64), hop_size=(32,32))\n",
    "# # window = transformer.WindowSlider(extractor.dataset, window_size=(256, 80), hop_size=40)  # 1s, full bandwidth\n",
    "# # window = transformer.WindowSlider(extractor.dataset, window_size=64, hop_size=32)\n",
    "\n",
    "# labels = list(compactor.full_label_dict.keys())\n",
    "\n",
    "# preproc = preprocessing.get_mapping_supervised(labels)\n",
    "    \n",
    "# ds_window = window.dataset.map(preproc, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# eles = list(ds_window.take(10).as_numpy_iterator())\n",
    "# input_shape = eles[0][0].shape\n",
    "\n",
    "# ds_window = ds_window.map(lambda x,y: (tf.ensure_shape(x, input_shape), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# splits = {'train':0.7, 'transfer':0.1,'val':0.1, 'test':0.1}\n",
    "# ds_split = utils.split_dataset(ds_window, splits, labels=[i+1 for i in range(len(labels))])\n",
    "\n",
    "# ds_split['train'].save(str(outdir/'ds_train'))\n",
    "# ds_split['val'].save(str(outdir/'ds_val'))\n",
    "# ds_split['transfer'].save(str(outdir/'ds_transfer'))\n",
    "# ds_split['test'].save(str(outdir/'ds_test'))\n",
    "\n",
    "# with open(outdir/'lb.json', 'w') as fp:\n",
    "#     json.dump(labels,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = tf.data.Dataset.load(str(outdir/'ds_train'))\n",
    "ds_val = tf.data.Dataset.load(str(outdir/'ds_val'))\n",
    "ds_transfer = tf.data.Dataset.load(str(outdir/'ds_transfer'))\n",
    "ds_test = tf.data.Dataset.load(str(outdir/'ds_test'))\n",
    "\n",
    "with open(outdir/'lb.json', 'r') as fp:\n",
    "    labels = list(json.load(fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 13:42:36.600320: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-02 13:42:37.105418: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-02 13:42:37.596897: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-02 13:42:38.041646: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "ds_size = utils.get_dataset_size(ds_train) + utils.get_dataset_size(ds_val) +utils.get_dataset_size(ds_transfer) + utils.get_dataset_size(ds_test)\n",
    "n_embedding  = 128 \n",
    "kernel_size = (3,3) \n",
    "tau = 0.1\n",
    "projection_dim = 128\n",
    "momentum_coeff=0.99\n",
    "queue_size=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 13:42:39.219906: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-07-02 13:42:39.225414: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "ds_train = ds_train.shuffle(ds_size, reshuffle_each_iteration=True).cache().batch(batch_size,drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "ds_val = ds_val.batch(batch_size,drop_remainder=True)\n",
    "ds_transfer=ds_transfer.shuffle(ds_size, reshuffle_each_iteration=True).cache().batch(batch_size,drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(1)\n",
    "\n",
    "eles = list(ds_train.take(1).as_numpy_iterator())\n",
    "input_shape = eles[0][0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class Encoder(models.Model):\n",
    "    \"\"\"Convolution Auto-Encoder stacks.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Shape (H,W) of the input tensor must be power of 2.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape, n_embedding, kernel_size, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "        self.input_shape = input_shape\n",
    "        self.n_embedding = n_embedding\n",
    "        self.kernel_size = kernel_size\n",
    "        activation = 'relu'\n",
    "        padding = 'same'\n",
    "        strides = (2, 2)\n",
    "        pool_size = (2, 2)\n",
    "        a_reg = 0.\n",
    "\n",
    "        # Encoder\n",
    "        input_enc = layers.Input(shape=input_shape, name='input_enc')\n",
    "        x = layers.Conv2D(32, kernel_size=kernel_size, activation=activation, padding=padding, name='conv1_enc')(input_enc)\n",
    "        x = layers.MaxPooling2D(pool_size=pool_size, strides=strides, name='pool1_enc')(x)\n",
    "        x = layers.BatchNormalization(name='bn1_enc')(x)\n",
    "\n",
    "        x = layers.Conv2D(64, kernel_size=kernel_size, activation=activation, padding=padding, name='conv2_enc')(x)\n",
    "        x = layers.MaxPooling2D(pool_size=pool_size, strides=strides, name='pool2_enc')(x)\n",
    "        x = layers.BatchNormalization(name='bn2_enc')(x)\n",
    "\n",
    "        x = layers.Conv2D(128, kernel_size=kernel_size, activation=activation, padding=padding, name='conv3_enc')(x)\n",
    "        x = layers.MaxPooling2D(pool_size=pool_size, strides=strides, name='pool3_enc')(x)\n",
    "        x = layers.BatchNormalization(name='bn3_enc')(x)\n",
    "\n",
    "        x = layers.Flatten(name='flatten')(x)\n",
    "        if a_reg > 0:\n",
    "            x = layers.Dense(n_embedding, activation=activation, activity_regularizer=regularizers.L1(a_reg), name='fc1_enc')(x)\n",
    "        else:\n",
    "            x = layers.Dense(n_embedding, activation=activation, name='fc1_enc')(x)\n",
    "\n",
    "        self.encoder = models.Model(input_enc, x, name='encoder')\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        return self.encoder(x, training=False)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(Encoder, self).get_config()\n",
    "        config.update({\n",
    "            \"input_shape\": self.input_shape,\n",
    "            \"n_embedding\": self.n_embedding,\n",
    "            \"kernel_size\": self.kernel_size\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "\n",
    "encoder = Encoder(input_shape,n_embedding,kernel_size)\n",
    "config = encoder.get_config()\n",
    "encoder_clone = Encoder.from_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the MoCo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MoCo(keras.Model):\n",
    "    def __init__(self,momentum_coeff,temperature,queue_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.contrastive_augmenter = keras.Sequential([\n",
    "            layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "            layers.RandomZoom(0.2),\n",
    "            layers.RandomTranslation(height_factor=0.2, width_factor=0.2),\n",
    "        ], name='Data_augmentation')\n",
    "\n",
    "        self.encoder = encoder\n",
    "\n",
    "        self.projection_head = keras.Sequential([\n",
    "                layers.Dense(projection_dim, activation=None),\n",
    "            ], name='Projection_head')\n",
    "        \n",
    "        self.momentum_coeff = momentum_coeff\n",
    "        self.temperature = temperature\n",
    "\n",
    "        # the momentum networks are initialized from their online counterparts\n",
    "        self.m_encoder = encoder_clone\n",
    "        self.m_projection_head = keras.models.clone_model(self.projection_head)\n",
    "\n",
    "        feature_dimensions = self.encoder.encoder.output_shape[1]\n",
    "        self.feature_queue = tf.Variable(\n",
    "            tf.math.l2_normalize(\n",
    "                tf.random.normal(shape=(queue_size, feature_dimensions)), axis=1\n",
    "            ),\n",
    "            trainable=False,\n",
    "        )\n",
    "\n",
    "    def compile(self, contrastive_optimizer, probe_optimizer, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "\n",
    "        self.contrastive_optimizer = contrastive_optimizer\n",
    "        self.probe_optimizer = probe_optimizer\n",
    "\n",
    "        # self.contrastive_loss will be defined as a method\n",
    "        self.probe_loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "        self.contrastive_accuracy = keras.metrics.SparseCategoricalAccuracy()\n",
    "        self.probe_accuracy = keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "    def reset_metrics(self):\n",
    "        self.contrastive_accuracy.reset_state()\n",
    "        self.probe_accuracy.reset_state()\n",
    "\n",
    "    def update_contrastive_accuracy(self, features_1, features_2):\n",
    "        # self-supervised metric inspired by the SimCLR loss\n",
    "\n",
    "        # cosine similarity: the dot product of the l2-normalized feature vectors\n",
    "        features_1 = tf.math.l2_normalize(features_1, axis=1)\n",
    "        features_2 = tf.math.l2_normalize(features_2, axis=1)\n",
    "        similarities = tf.matmul(features_1, features_2, transpose_b=True)\n",
    "\n",
    "        # the similarity between the representations of two augmented views of the\n",
    "        # same image should be higher than their similarity with other views\n",
    "        batch_size = tf.shape(features_1)[0]\n",
    "        contrastive_labels = tf.range(batch_size)\n",
    "        self.contrastive_accuracy.update_state(\n",
    "            tf.concat([contrastive_labels, contrastive_labels], axis=0),\n",
    "            tf.concat([similarities, tf.transpose(similarities)], axis=0),\n",
    "        )\n",
    "    \n",
    "    def cosine_similarity(features_1, features_2):\n",
    "        features_1 = tf.math.l2_normalize(features_1, axis=1)\n",
    "        features_2 = tf.math.l2_normalize(features_2, axis=1)\n",
    "        similarities = tf.matmul(features_1, features_2, transpose_b=True)\n",
    "        return similarities\n",
    "\n",
    "    def contrastive_loss(self, query, key):\n",
    "        # similar to the SimCLR loss, however it uses the momentum networks'\n",
    "        # representations of the differently augmented views as targets\n",
    "        query = tf.math.l2_normalize(query, axis=1)\n",
    "        key = tf.math.l2_normalize(key, axis=1)\n",
    "\n",
    "        similarities = (\n",
    "            tf.matmul(\n",
    "                query,\n",
    "                tf.concat((key, self.feature_queue), axis=0),\n",
    "                transpose_b=True,\n",
    "            )\n",
    "            / self.temperature\n",
    "        )\n",
    "\n",
    "        batch_size = tf.shape(query)[0]\n",
    "        contrastive_labels = tf.range(batch_size)\n",
    "        loss = keras.losses.sparse_categorical_crossentropy(\n",
    "            tf.concat([contrastive_labels], axis=0),\n",
    "            tf.concat([similarities], axis=0),\n",
    "            from_logits=True,\n",
    "        )\n",
    "\n",
    "        # feature queue update\n",
    "        self.feature_queue.assign(\n",
    "            tf.concat(\n",
    "                [\n",
    "                    key,\n",
    "                    self.feature_queue[: -batch_size],\n",
    "                ],\n",
    "                axis=0,\n",
    "            )[:self.feature_queue.shape[0]]\n",
    "        )\n",
    "        return tf.reduce_mean(loss)\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        train_image, _ = data\n",
    "\n",
    "        augmented_image = self.contrastive_augmenter(train_image)\n",
    "        with tf.GradientTape() as tape:\n",
    "            features = self.encoder(train_image, training=True)\n",
    "            query = self.projection_head(features)\n",
    "        \n",
    "            m_features = self.m_encoder(augmented_image, training=False)\n",
    "            key = self.m_projection_head(m_features)\n",
    "            contrastive_loss = self.contrastive_loss(query, key)\n",
    "\n",
    "        gradients = tape.gradient(\n",
    "            contrastive_loss,\n",
    "            self.encoder.trainable_weights + self.projection_head.trainable_weights,)\n",
    "\n",
    "        self.contrastive_optimizer.apply_gradients(\n",
    "            zip(gradients,self.encoder.trainable_weights + self.projection_head.trainable_weights,))\n",
    "        \n",
    "        self.update_contrastive_accuracy(query, key)\n",
    "\n",
    "        # the momentum networks are updated by exponential moving average\n",
    "        for weight, m_weight in zip(self.encoder.weights, self.m_encoder.weights):\n",
    "            m_weight.assign(\n",
    "                self.momentum_coeff * m_weight + (1 - self.momentum_coeff) * weight\n",
    "            )\n",
    "        for weight, m_weight in zip(\n",
    "            self.projection_head.weights, self.m_projection_head.weights\n",
    "        ):\n",
    "            m_weight.assign(\n",
    "                self.momentum_coeff * m_weight + (1 - self.momentum_coeff) * weight\n",
    "            )\n",
    "\n",
    "        return {\n",
    "            \"c_loss\": contrastive_loss,\n",
    "            \"c_acc\": self.contrastive_accuracy.result(),\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        test_image, _ = data\n",
    "        augmented_image = self.contrastive_augmenter(test_image)\n",
    "        \n",
    "        features = self.encoder(test_image, training=False)\n",
    "        query = self.projection_head(features)\n",
    "    \n",
    "        m_features = self.m_encoder(augmented_image, training=False)\n",
    "        key = self.m_projection_head(m_features)\n",
    "        self.update_contrastive_accuracy(query, key)\n",
    "\n",
    "        return {\n",
    "            \"c_acc\": self.contrastive_accuracy.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the MoCo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MoCo_model = MoCo(momentum_coeff, tau, queue_size)\n",
    "     \n",
    "# MoCo_model.compile(\n",
    "#     contrastive_optimizer=keras.optimizers.Adam(),\n",
    "#     probe_optimizer=keras.optimizers.Adam(),\n",
    "# )\n",
    "\n",
    "# history = MoCo_model.fit(\n",
    "#     ds_train.repeat(), \n",
    "#     epochs=30, \n",
    "#     validation_data=ds_val, \n",
    "#     steps_per_epoch=int((0.7*ds_size) // batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print evolution of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax1 = plt.subplots()\n",
    "\n",
    "# color = 'tab:red'\n",
    "# ax1.set_xlabel('Epochs')\n",
    "# ax1.set_ylabel('c_loss', color=color)\n",
    "# ax1.plot(history.history['c_loss'], color=color)\n",
    "# ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "# color = 'tab:blue'\n",
    "# ax2.set_ylabel('c_acc', color=color) \n",
    "# ax2.plot(history.history['val_c_acc'], color=color)\n",
    "# ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# fig.tight_layout()\n",
    "# plt.title('Evolution of metrics')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MoCo_model.save_weights('moco.weights.h5')\n",
    "MoCo_model.load_weights('moco.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the classification model and train the classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/volatile/home/bm279471/Documents/.venv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                </span>┃<span style=\"font-weight: bold\"> Output Shape          </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Trai… </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━┩\n",
       "│ input_enc (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,142,848</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│    └ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)   │ ?                     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,142,848</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ input_enc           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ conv1_enc (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ pool1_enc           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)              │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ bn1_enc             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ conv2_enc (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ pool2_enc           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)              │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ bn2_enc             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ conv3_enc (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ pool3_enc           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)              │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ bn3_enc             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ fc1_enc (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,704</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ Classification_head         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,894</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│    └ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│    └ batch_normalization    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│    └ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,870</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n",
       "└─────────────────────────────┴───────────────────────┴────────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mTrai…\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━┩\n",
       "│ input_enc (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ encoder (\u001b[38;5;33mEncoder\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │  \u001b[38;5;34m1,142,848\u001b[0m │   \u001b[1;91mN\u001b[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│    └ encoder (\u001b[38;5;33mFunctional\u001b[0m)   │ ?                     │  \u001b[38;5;34m1,142,848\u001b[0m │   \u001b[1;91mN\u001b[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ input_enc           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ conv1_enc (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │        \u001b[38;5;34m896\u001b[0m │   \u001b[1;91mN\u001b[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ pool1_enc           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)              │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ bn1_enc             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │        \u001b[38;5;34m128\u001b[0m │   \u001b[1;91mN\u001b[0m   │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)        │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ conv2_enc (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m18,496\u001b[0m │   \u001b[1;91mN\u001b[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ pool2_enc           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)              │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ bn2_enc             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │   \u001b[1;91mN\u001b[0m   │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)        │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ conv3_enc (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m73,856\u001b[0m │   \u001b[1;91mN\u001b[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ pool3_enc           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)              │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ bn3_enc             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │        \u001b[38;5;34m512\u001b[0m │   \u001b[1;91mN\u001b[0m   │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)        │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)          │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ fc1_enc (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │  \u001b[38;5;34m1,048,704\u001b[0m │   \u001b[1;91mN\u001b[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ Classification_head         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)            │     \u001b[38;5;34m20,894\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│    └ dense_1 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │     \u001b[38;5;34m16,512\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│    └ batch_normalization    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │        \u001b[38;5;34m512\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)        │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│    └ dense_2 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)            │      \u001b[38;5;34m3,870\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n",
       "└─────────────────────────────┴───────────────────────┴────────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,163,742</span> (4.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,163,742\u001b[0m (4.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,638</span> (80.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,638\u001b[0m (80.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,143,104</span> (4.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,143,104\u001b[0m (4.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 263ms/step - accuracy: 0.0910 - loss: 3.5673 - val_accuracy: 0.2894 - val_loss: 2.6015 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 344ms/step - accuracy: 0.4044 - loss: 2.1846 - val_accuracy: 0.4775 - val_loss: 1.8850 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 341ms/step - accuracy: 0.5719 - loss: 1.6754 - val_accuracy: 0.5869 - val_loss: 1.5223 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 350ms/step - accuracy: 0.6719 - loss: 1.3551 - val_accuracy: 0.6913 - val_loss: 1.3036 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 360ms/step - accuracy: 0.7437 - loss: 1.1216 - val_accuracy: 0.7412 - val_loss: 1.1551 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 338ms/step - accuracy: 0.7905 - loss: 0.9497 - val_accuracy: 0.7694 - val_loss: 1.0136 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 368ms/step - accuracy: 0.8274 - loss: 0.7931 - val_accuracy: 0.8056 - val_loss: 0.9087 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 349ms/step - accuracy: 0.8605 - loss: 0.6709 - val_accuracy: 0.8294 - val_loss: 0.8151 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 355ms/step - accuracy: 0.8936 - loss: 0.5679 - val_accuracy: 0.8525 - val_loss: 0.7240 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 338ms/step - accuracy: 0.9142 - loss: 0.4800 - val_accuracy: 0.8575 - val_loss: 0.6536 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 342ms/step - accuracy: 0.9268 - loss: 0.4106 - val_accuracy: 0.8731 - val_loss: 0.5869 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 344ms/step - accuracy: 0.9425 - loss: 0.3544 - val_accuracy: 0.8825 - val_loss: 0.5532 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 355ms/step - accuracy: 0.9541 - loss: 0.3111 - val_accuracy: 0.8969 - val_loss: 0.4967 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 351ms/step - accuracy: 0.9562 - loss: 0.2681 - val_accuracy: 0.9025 - val_loss: 0.4620 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 356ms/step - accuracy: 0.9677 - loss: 0.2347 - val_accuracy: 0.9106 - val_loss: 0.4174 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 366ms/step - accuracy: 0.9733 - loss: 0.2079 - val_accuracy: 0.9137 - val_loss: 0.3971 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 374ms/step - accuracy: 0.9779 - loss: 0.1803 - val_accuracy: 0.9225 - val_loss: 0.3717 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 382ms/step - accuracy: 0.9794 - loss: 0.1589 - val_accuracy: 0.9194 - val_loss: 0.3576 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 365ms/step - accuracy: 0.9792 - loss: 0.1482 - val_accuracy: 0.9244 - val_loss: 0.3371 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 373ms/step - accuracy: 0.9836 - loss: 0.1302 - val_accuracy: 0.9225 - val_loss: 0.3265 - learning_rate: 0.0010\n",
      "Epoch 21/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 377ms/step - accuracy: 0.9846 - loss: 0.1175 - val_accuracy: 0.9212 - val_loss: 0.3133 - learning_rate: 0.0010\n",
      "Epoch 22/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 379ms/step - accuracy: 0.9878 - loss: 0.1031 - val_accuracy: 0.9275 - val_loss: 0.2991 - learning_rate: 0.0010\n",
      "Epoch 23/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 376ms/step - accuracy: 0.9876 - loss: 0.0936 - val_accuracy: 0.9237 - val_loss: 0.3052 - learning_rate: 0.0010\n",
      "Epoch 24/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 377ms/step - accuracy: 0.9913 - loss: 0.0874 - val_accuracy: 0.9281 - val_loss: 0.2895 - learning_rate: 0.0010\n",
      "Epoch 25/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 374ms/step - accuracy: 0.9919 - loss: 0.0779 - val_accuracy: 0.9306 - val_loss: 0.2846 - learning_rate: 0.0010\n",
      "Epoch 26/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 366ms/step - accuracy: 0.9926 - loss: 0.0693 - val_accuracy: 0.9331 - val_loss: 0.2775 - learning_rate: 0.0010\n",
      "Epoch 27/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 368ms/step - accuracy: 0.9951 - loss: 0.0616 - val_accuracy: 0.9294 - val_loss: 0.2694 - learning_rate: 0.0010\n",
      "Epoch 28/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 375ms/step - accuracy: 0.9951 - loss: 0.0558 - val_accuracy: 0.9344 - val_loss: 0.2609 - learning_rate: 0.0010\n",
      "Epoch 29/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 358ms/step - accuracy: 0.9951 - loss: 0.0511 - val_accuracy: 0.9262 - val_loss: 0.2662 - learning_rate: 0.0010\n",
      "Epoch 30/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 384ms/step - accuracy: 0.9934 - loss: 0.0469 - val_accuracy: 0.9350 - val_loss: 0.2560 - learning_rate: 0.0010\n",
      "Epoch 31/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 387ms/step - accuracy: 0.9951 - loss: 0.0434 - val_accuracy: 0.9362 - val_loss: 0.2544 - learning_rate: 0.0010\n",
      "Epoch 32/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 388ms/step - accuracy: 0.9948 - loss: 0.0392 - val_accuracy: 0.9344 - val_loss: 0.2515 - learning_rate: 0.0010\n",
      "Epoch 33/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 387ms/step - accuracy: 0.9981 - loss: 0.0362 - val_accuracy: 0.9325 - val_loss: 0.2533 - learning_rate: 0.0010\n",
      "Epoch 34/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 346ms/step - accuracy: 0.9981 - loss: 0.0334 - val_accuracy: 0.9331 - val_loss: 0.2519 - learning_rate: 0.0010\n",
      "Epoch 35/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 385ms/step - accuracy: 0.9991 - loss: 0.0311 - val_accuracy: 0.9375 - val_loss: 0.2393 - learning_rate: 1.0000e-04\n",
      "Epoch 36/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 331ms/step - accuracy: 0.9995 - loss: 0.0272 - val_accuracy: 0.9413 - val_loss: 0.2364 - learning_rate: 1.0000e-04\n",
      "Epoch 37/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 275ms/step - accuracy: 0.9983 - loss: 0.0261 - val_accuracy: 0.9413 - val_loss: 0.2350 - learning_rate: 1.0000e-04\n",
      "Epoch 38/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 278ms/step - accuracy: 0.9983 - loss: 0.0255 - val_accuracy: 0.9425 - val_loss: 0.2343 - learning_rate: 1.0000e-04\n",
      "Epoch 39/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 274ms/step - accuracy: 0.9983 - loss: 0.0250 - val_accuracy: 0.9425 - val_loss: 0.2338 - learning_rate: 1.0000e-04\n",
      "Epoch 40/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 279ms/step - accuracy: 0.9983 - loss: 0.0246 - val_accuracy: 0.9431 - val_loss: 0.2332 - learning_rate: 1.0000e-04\n",
      "Epoch 41/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 273ms/step - accuracy: 0.9983 - loss: 0.0243 - val_accuracy: 0.9438 - val_loss: 0.2327 - learning_rate: 1.0000e-04\n",
      "Epoch 42/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 277ms/step - accuracy: 0.9983 - loss: 0.0240 - val_accuracy: 0.9438 - val_loss: 0.2320 - learning_rate: 1.0000e-04\n",
      "Epoch 43/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 273ms/step - accuracy: 0.9983 - loss: 0.0237 - val_accuracy: 0.9444 - val_loss: 0.2316 - learning_rate: 1.0000e-04\n",
      "Epoch 44/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 279ms/step - accuracy: 0.9987 - loss: 0.0234 - val_accuracy: 0.9444 - val_loss: 0.2315 - learning_rate: 1.0000e-04\n",
      "Epoch 45/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 273ms/step - accuracy: 0.9987 - loss: 0.0231 - val_accuracy: 0.9444 - val_loss: 0.2314 - learning_rate: 1.0000e-04\n",
      "Epoch 46/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 278ms/step - accuracy: 0.9998 - loss: 0.0229 - val_accuracy: 0.9450 - val_loss: 0.2308 - learning_rate: 1.0000e-04\n",
      "Epoch 47/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 274ms/step - accuracy: 0.9998 - loss: 0.0225 - val_accuracy: 0.9438 - val_loss: 0.2311 - learning_rate: 1.0000e-04\n",
      "Epoch 48/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 287ms/step - accuracy: 0.9998 - loss: 0.0223 - val_accuracy: 0.9444 - val_loss: 0.2311 - learning_rate: 1.0000e-04\n",
      "Epoch 49/60\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 275ms/step - accuracy: 1.0000 - loss: 0.0219 - val_accuracy: 0.9444 - val_loss: 0.2310 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# Freeze the encoder weights\n",
    "MoCo_model.encoder.trainable = False\n",
    "\n",
    "classification_head = keras.Sequential([\n",
    "                layers.Dense(128, activation='relu', input_shape=(128,)),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Dense(30) #nb labels\n",
    "            ], name='Classification_head')\n",
    "\n",
    "# Create a new classification model\n",
    "encoder_output = MoCo_model.encoder(MoCo_model.encoder.layers[0].input, training=False)\n",
    "classification_model = keras.Model(\n",
    "    inputs=MoCo_model.encoder.layers[0].input,\n",
    "    outputs=classification_head(encoder_output)\n",
    ")\n",
    "classification_model.summary(show_trainable=True, expand_nested=True)\n",
    "\n",
    "classification_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(), \n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=3,       \n",
    "    restore_best_weights=True, \n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.1,         \n",
    "    patience=2          \n",
    ")\n",
    "\n",
    "history = classification_model.fit(\n",
    "    ds_transfer.repeat(), \n",
    "    epochs=60, \n",
    "    validation_data=ds_val, \n",
    "    steps_per_epoch=int((0.1*ds_size) // batch_size),\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1654/1654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 26ms/step - accuracy: 0.9265 - loss: 0.2960\n",
      "Evaluation Accuracy: 93.11%\n"
     ]
    }
   ],
   "source": [
    "evaluation = classification_model.evaluate(ds_test)\n",
    "\n",
    "print(\"Evaluation Accuracy: {:.2f}%\".format(evaluation[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 350ms/step - accuracy: 0.9984 - loss: 0.0234 - val_accuracy: 0.9463 - val_loss: 0.2256 - learning_rate: 1.0000e-04\n",
      "Epoch 2/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 360ms/step - accuracy: 0.9998 - loss: 0.0197 - val_accuracy: 0.9488 - val_loss: 0.2167 - learning_rate: 1.0000e-04\n",
      "Epoch 3/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 354ms/step - accuracy: 0.9998 - loss: 0.0178 - val_accuracy: 0.9481 - val_loss: 0.2125 - learning_rate: 1.0000e-04\n",
      "Epoch 4/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 362ms/step - accuracy: 0.9998 - loss: 0.0164 - val_accuracy: 0.9488 - val_loss: 0.2061 - learning_rate: 1.0000e-04\n",
      "Epoch 5/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 360ms/step - accuracy: 1.0000 - loss: 0.0148 - val_accuracy: 0.9506 - val_loss: 0.2047 - learning_rate: 1.0000e-04\n",
      "Epoch 6/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 366ms/step - accuracy: 1.0000 - loss: 0.0136 - val_accuracy: 0.9494 - val_loss: 0.2011 - learning_rate: 1.0000e-04\n",
      "Epoch 7/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 356ms/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 0.9513 - val_loss: 0.1974 - learning_rate: 1.0000e-04\n",
      "Epoch 8/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 348ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 0.9525 - val_loss: 0.1952 - learning_rate: 1.0000e-04\n",
      "Epoch 9/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 367ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 0.9544 - val_loss: 0.1933 - learning_rate: 1.0000e-04\n",
      "Epoch 10/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 367ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.9550 - val_loss: 0.1907 - learning_rate: 1.0000e-04\n",
      "Epoch 11/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 355ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.9563 - val_loss: 0.1888 - learning_rate: 1.0000e-04\n",
      "Epoch 12/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 355ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.9556 - val_loss: 0.1867 - learning_rate: 1.0000e-04\n",
      "Epoch 13/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 362ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 0.9550 - val_loss: 0.1848 - learning_rate: 1.0000e-04\n",
      "Epoch 14/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 421ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 0.9569 - val_loss: 0.1829 - learning_rate: 1.0000e-04\n",
      "Epoch 15/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 441ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9569 - val_loss: 0.1824 - learning_rate: 1.0000e-04\n",
      "Epoch 16/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 459ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.9588 - val_loss: 0.1804 - learning_rate: 1.0000e-04\n",
      "Epoch 17/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 457ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.9594 - val_loss: 0.1795 - learning_rate: 1.0000e-04\n",
      "Epoch 18/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 436ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.9581 - val_loss: 0.1776 - learning_rate: 1.0000e-04\n",
      "Epoch 19/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 455ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.9600 - val_loss: 0.1755 - learning_rate: 1.0000e-04\n",
      "Epoch 20/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 450ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9594 - val_loss: 0.1751 - learning_rate: 1.0000e-04\n",
      "Epoch 21/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 453ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9600 - val_loss: 0.1737 - learning_rate: 1.0000e-04\n",
      "Epoch 22/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 411ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9594 - val_loss: 0.1730 - learning_rate: 1.0000e-04\n",
      "Epoch 23/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 413ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9588 - val_loss: 0.1729 - learning_rate: 1.0000e-04\n",
      "Epoch 24/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 393ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9606 - val_loss: 0.1714 - learning_rate: 1.0000e-04\n",
      "Epoch 25/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 462ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9606 - val_loss: 0.1692 - learning_rate: 1.0000e-04\n",
      "Epoch 26/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 442ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9594 - val_loss: 0.1696 - learning_rate: 1.0000e-04\n",
      "Epoch 27/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 445ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9613 - val_loss: 0.1674 - learning_rate: 1.0000e-04\n",
      "Epoch 28/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 438ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9606 - val_loss: 0.1661 - learning_rate: 1.0000e-04\n",
      "Epoch 29/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 431ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9625 - val_loss: 0.1658 - learning_rate: 1.0000e-04\n",
      "Epoch 30/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 446ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9631 - val_loss: 0.1651 - learning_rate: 1.0000e-04\n",
      "Epoch 31/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 438ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9644 - val_loss: 0.1650 - learning_rate: 1.0000e-04\n",
      "Epoch 32/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 458ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9631 - val_loss: 0.1631 - learning_rate: 1.0000e-04\n",
      "Epoch 33/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 464ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9644 - val_loss: 0.1625 - learning_rate: 1.0000e-04\n",
      "Epoch 34/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 460ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9638 - val_loss: 0.1626 - learning_rate: 1.0000e-04\n",
      "Epoch 35/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 443ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9638 - val_loss: 0.1626 - learning_rate: 1.0000e-04\n",
      "Epoch 36/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 425ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9644 - val_loss: 0.1625 - learning_rate: 1.0000e-05\n",
      "Epoch 37/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 455ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9644 - val_loss: 0.1625 - learning_rate: 1.0000e-05\n",
      "Epoch 38/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 433ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9644 - val_loss: 0.1625 - learning_rate: 1.0000e-06\n",
      "Epoch 39/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 429ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9644 - val_loss: 0.1625 - learning_rate: 1.0000e-06\n",
      "Epoch 40/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 439ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9650 - val_loss: 0.1625 - learning_rate: 1.0000e-07\n"
     ]
    }
   ],
   "source": [
    "MoCo_model.encoder.trainable = True\n",
    "\n",
    "classification_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-4), \n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=3,       \n",
    "    restore_best_weights=True, \n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.1,         \n",
    "    patience=2          \n",
    ")\n",
    "\n",
    "history = classification_model.fit(\n",
    "    ds_transfer.repeat(), \n",
    "    epochs=40, \n",
    "    validation_data=ds_val, \n",
    "    steps_per_epoch=int((0.1*ds_size) // batch_size),\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   1/1654\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 1.6808e-05"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1654/1654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 29ms/step - accuracy: 0.9517 - loss: 0.2194\n",
      "Evaluation Accuracy: 95.41%\n"
     ]
    }
   ],
   "source": [
    "evaluation = classification_model.evaluate(ds_test)\n",
    "\n",
    "print(\"Evaluation Accuracy: {:.2f}%\".format(evaluation[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
