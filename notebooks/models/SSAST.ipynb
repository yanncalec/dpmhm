{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 14:59:08.356083: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-02 14:59:08.362178: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-02 14:59:08.471386: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-02 14:59:10.064093: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-07-02 14:59:13.327519: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-07-02 14:59:13.327593: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:134] retrieving CUDA diagnostic information for host: is230816\n",
      "2024-07-02 14:59:13.327609: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:141] hostname: is230816\n",
      "2024-07-02 14:59:13.327802: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:165] libcuda reported version is: 535.183.1\n",
      "2024-07-02 14:59:13.327843: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:169] kernel reported version is: 535.183.1\n",
      "2024-07-02 14:59:13.327854: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:248] kernel version seems to match DSO: 535.183.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metadata': {'Dataset': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       "  'FaultComponent': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       "  'FaultLocation': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       "  'FaultSize': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  'FileName': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       "  'LoadForce': TensorSpec(shape=(), dtype=tf.uint32, name=None),\n",
       "  'NominalRPM': TensorSpec(shape=(), dtype=tf.uint32, name=None),\n",
       "  'RPM': TensorSpec(shape=(), dtype=tf.uint32, name=None)},\n",
       " 'sampling_rate': TensorSpec(shape=(), dtype=tf.uint32, name=None),\n",
       " 'signal': {'BA': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'DE': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'FE': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # disable GPU devices\n",
    "os.environ[\"TFDS_DATA_DIR\"] = os.path.expanduser(\"~/tensorflow_datasets\")  # default location of tfds database\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import keras\n",
    "from keras import layers, models, metrics, losses\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Turn off logging for TF\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "from dpmhm.datasets import preprocessing, feature, utils, transformer\n",
    "\n",
    "ds_all, ds_info = tfds.load(\n",
    "    'CWRU',\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "ds0 = ds_all['train']\n",
    "ds0.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = Path('/volatile/home/bm279471/tmp/few_shot_cwru')\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# compactor = transformer.DatasetCompactor(ds0,\n",
    "#                                          channels=['DE', 'FE', 'BA'],\n",
    "#                                          keys=['FaultLocation', 'FaultComponent', 'FaultSize'],\n",
    "#                                          resampling_rate=12000)\n",
    "\n",
    "# # Feature extractor\n",
    "# # Spectrogram is computed on a time window of 0.025 second every 0.0125 second, then converted to decibel scale.\n",
    "# _func = lambda x, sr: feature.spectral_features(x, sr, 'spectrogram',\n",
    "# #                                                 n_mfcc=256,\n",
    "#                                                 time_window=0.025, hop_step=0.0125, n_fft=512,\n",
    "#                                                 normalize=False, to_db=True)[0]\n",
    "\n",
    "# extractor = transformer.FeatureExtractor(compactor.dataset, _func)\n",
    "\n",
    "# # A window of width w correspond to w*0.0125 seconds\n",
    "# window = transformer.WindowSlider(extractor.dataset, window_size=(64,64), hop_size=(32,32))\n",
    "# # window = transformer.WindowSlider(extractor.dataset, window_size=(256, 80), hop_size=40)  # 1s, full bandwidth\n",
    "# # window = transformer.WindowSlider(extractor.dataset, window_size=64, hop_size=32)\n",
    "\n",
    "# labels = list(compactor.full_label_dict.keys())\n",
    "\n",
    "# preproc = preprocessing.get_mapping_supervised(labels)\n",
    "    \n",
    "# ds_window = window.dataset.map(preproc, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# eles = list(ds_window.take(10).as_numpy_iterator())\n",
    "# input_shape = eles[0][0].shape\n",
    "\n",
    "# ds_window = ds_window.map(lambda x,y: (tf.ensure_shape(x, input_shape), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# splits = {'train':0.7, 'transfer':0.1,'val':0.1, 'test':0.1}\n",
    "# ds_split = utils.split_dataset(ds_window, splits, labels=[i+1 for i in range(len(labels))])\n",
    "\n",
    "# ds_split['train'].save(str(outdir/'ds_train'))\n",
    "# ds_split['val'].save(str(outdir/'ds_val'))\n",
    "# ds_split['transfer'].save(str(outdir/'ds_transfer'))\n",
    "# ds_split['test'].save(str(outdir/'ds_test'))\n",
    "\n",
    "# with open(outdir/'lb.json', 'w') as fp:\n",
    "#     json.dump(labels,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = tf.data.Dataset.load(str(outdir/'ds_train'))\n",
    "ds_val = tf.data.Dataset.load(str(outdir/'ds_val'))\n",
    "ds_transfer = tf.data.Dataset.load(str(outdir/'ds_transfer'))\n",
    "ds_test = tf.data.Dataset.load(str(outdir/'ds_test'))\n",
    "\n",
    "with open(outdir/'lb.json', 'r') as fp:\n",
    "    labels = list(json.load(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 14:59:17.187310: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-02 14:59:19.386263: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-02 14:59:20.018620: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-02 14:59:20.659158: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "ds_size = utils.get_dataset_size(ds_train) + utils.get_dataset_size(ds_val) +utils.get_dataset_size(ds_transfer) + utils.get_dataset_size(ds_test)\n",
    "n_embedding  = 128 \n",
    "kernel_size = (3,3)\n",
    "projection_dim = 128\n",
    "nb_classes=len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 14:59:22.400424: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-07-02 14:59:22.406911: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "ds_train = ds_train.shuffle(ds_size, reshuffle_each_iteration=True).cache().batch(batch_size,drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "ds_val = ds_val.batch(batch_size,drop_remainder=True)\n",
    "ds_transfer=ds_transfer.shuffle(ds_size, reshuffle_each_iteration=True).cache().batch(batch_size,drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(1)\n",
    "\n",
    "eles = list(ds_train.take(1).as_numpy_iterator())\n",
    "input_shape = eles[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 [TensorShape([32, 64, 64, 3]), TensorShape([32, 64, 64, 3]), TensorShape([288, 9]), TensorShape([288])]\n"
     ]
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class AddPositionEmbs(layers.Layer):\n",
    "    \"\"\"Adds (optionally learned) positional embeddings to the inputs.\"\"\"\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert (\n",
    "            len(input_shape) == 3\n",
    "        ), f\"Number of dimensions should be 3, got {len(input_shape)}\"\n",
    "        self.pe = tf.Variable(\n",
    "            name=\"pos_embedding\",\n",
    "            initial_value=tf.random_normal_initializer(stddev=0.06)(\n",
    "                shape=(1, input_shape[1], input_shape[2])\n",
    "            ),\n",
    "            dtype=\"float32\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + tf.cast(self.pe, dtype=inputs.dtype)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, *args, num_heads, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        embedding_dim = input_shape[-1]\n",
    "        num_heads = self.num_heads\n",
    "        if embedding_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embedding_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.projection_dim = embedding_dim // num_heads\n",
    "        self.query_dense = layers.Dense(embedding_dim, name=\"query\")\n",
    "        self.key_dense = layers.Dense(embedding_dim, name=\"key\")\n",
    "        self.value_dense = layers.Dense(embedding_dim, name=\"value\")\n",
    "        self.combine_heads = layers.Dense(embedding_dim, name=\"out\")\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], score.dtype)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "        query = self.separate_heads(query, batch_size)\n",
    "        key = self.separate_heads(key, batch_size)\n",
    "        value = self.separate_heads(value, batch_size)\n",
    "\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embedding_dim))\n",
    "        output = self.combine_heads(concat_attention)\n",
    "        return output, weights\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"num_heads\": self.num_heads})\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class TransformerBlock(layers.Layer):\n",
    "    \"\"\"Implements a Transformer block.\"\"\"\n",
    "\n",
    "    def __init__(self, *args, num_heads, mlp_dim, dropout, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.mlp_dim = mlp_dim\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.att = MultiHeadSelfAttention(\n",
    "            num_heads=self.num_heads,\n",
    "            name=\"MultiHeadDotProductAttention_1\",\n",
    "        )\n",
    "        self.mlpblock = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(\n",
    "                    self.mlp_dim,\n",
    "                    activation=\"linear\",\n",
    "                    name=f\"{self.name}_Dense_0\",\n",
    "                ),\n",
    "                layers.Lambda(\n",
    "                    lambda x: keras.activations.gelu(x, approximate=False)\n",
    "                )\n",
    "                if hasattr(keras.activations, \"gelu\")\n",
    "                else layers.Lambda(\n",
    "                    lambda x: tf.nn.gelu(x, approximate=False)\n",
    "                ),\n",
    "                layers.Dropout(self.dropout),\n",
    "                layers.Dense(input_shape[-1], name=f\"{self.name}_Dense_1\"),\n",
    "                layers.Dropout(self.dropout),\n",
    "            ],\n",
    "            name=\"MlpBlock_3\",\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(\n",
    "            epsilon=1e-6, name=\"LayerNorm_0\"\n",
    "        )\n",
    "        self.layernorm2 = layers.LayerNormalization(\n",
    "            epsilon=1e-6, name=\"LayerNorm_2\"\n",
    "        )\n",
    "        self.dropout_layer = layers.Dropout(self.dropout)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        x = self.layernorm1(inputs)\n",
    "        x, weights = self.att(x)\n",
    "        x = self.dropout_layer(x, training=training)\n",
    "        x = x + inputs\n",
    "        y = self.layernorm2(x)\n",
    "        y = self.mlpblock(y)\n",
    "        return x + y, weights\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"num_heads\": self.num_heads,\n",
    "                \"mlp_dim\": self.mlp_dim,\n",
    "                \"dropout\": self.dropout,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "@tf.function()\n",
    "def SampleMaskIndex(seq_len, N, C):\n",
    "        I = set()\n",
    "        while len(I) < N:\n",
    "            i = np.random.randint(0, seq_len)  # uniform distribution over {1, N}\n",
    "            Ic = set(range(max(0, i-C+1), min(seq_len, i+C)))\n",
    "            I = I.union(Ic)\n",
    "        I = list(I)[:N]  # guarantee to mask exactly N patches\n",
    "        return I\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class Mask(layers.Layer):\n",
    "    def __init__(self, mask_ratio=0.15, batch_size=32, embedding_dim=128, seq_len=16, cluster_factor=3, **kwargs):\n",
    "        super(Mask, self).__init__(**kwargs)\n",
    "        self.mask_ratio = mask_ratio\n",
    "        self.batch_size=batch_size\n",
    "        self.embedding_dim=embedding_dim\n",
    "        self.seq_len=seq_len\n",
    "        self.cluster_factor=cluster_factor\n",
    "        self.learnable_mask = self.add_weight(\n",
    "            shape=(self.batch_size, seq_len, embedding_dim),\n",
    "            initializer=\"glorot_uniform\",  \n",
    "            trainable=True,\n",
    "            name=\"learnable_mask\",\n",
    "        )\n",
    "\n",
    "    def call(self, y):\n",
    "        N = tf.cast(self.seq_len * self.mask_ratio, tf.int32)\n",
    "\n",
    "        masked_indices = SampleMaskIndex(self.seq_len, N, self.cluster_factor)\n",
    "\n",
    "        # Create the mask Tensor and the masked embeddings\n",
    "        mask = tf.ones((self.batch_size, self.seq_len, self.embedding_dim))\n",
    "\n",
    "        indices = tf.constant([[i, j] for i in range(self.batch_size) for j in masked_indices])\n",
    "        updates = tf.zeros((len(indices), self.embedding_dim))\n",
    "\n",
    "        mask = tf.tensor_scatter_nd_update(mask, indices, updates)\n",
    "        y_masked = y * mask + (tf.ones((self.batch_size, self.seq_len, self.embedding_dim)) - mask) * self.learnable_mask\n",
    "\n",
    "        # Create a list of candidates for each masked patch\n",
    "        candidate_patches = []\n",
    "        for i in range(self.batch_size):\n",
    "            batch_candidates=[]\n",
    "            for j, idx in enumerate(masked_indices):\n",
    "                # for each masked patch, we introduce the masked patch and then the rest of the masked patches\n",
    "                patches = []\n",
    "                patches.append(y[i, idx, :])  # correct index\n",
    "                for masked_idx in masked_indices[:j] + masked_indices[j+1:]:\n",
    "                    patches.append(y[i, masked_idx, :])\n",
    "                batch_candidates.append(patches)\n",
    "            candidate_patches.append(batch_candidates)\n",
    "\n",
    "        return y_masked, mask, candidate_patches, masked_indices\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class SSASTModel(models.Model):\n",
    "    def __init__(self, image_size=(64,64), patch_size=16, num_layers=3, embedding_dim=128, num_heads=4, mlp_dim=128, dropout=0.1, mask_ratio=0.6, batch_size=32, Lambda=10, cluster_factor=3, **kwargs):\n",
    "        super(SSASTModel, self).__init__(**kwargs)\n",
    "        self.seq_len=(image_size[0]//patch_size)*(image_size[1]//patch_size)\n",
    "        self.image_size = image_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.mlp_dim = mlp_dim\n",
    "        self.dropout = dropout\n",
    "        self.batch_size=batch_size\n",
    "        self.Lambda=Lambda\n",
    "        self.mask_ratio=mask_ratio\n",
    "\n",
    "        self.embedding=layers.Conv2D(\n",
    "            filters=self.embedding_dim,\n",
    "            kernel_size=self.patch_size,\n",
    "            strides=self.patch_size,\n",
    "            padding=\"valid\",\n",
    "            name=\"embedding\",\n",
    "        )\n",
    "        self.reshape =layers.Reshape((self.seq_len, self.embedding_dim))\n",
    "        self.position_embedding=AddPositionEmbs(name=\"Transformer_posembed_input\")\n",
    "        self.mask_layer = Mask(mask_ratio=mask_ratio, batch_size=batch_size, embedding_dim=embedding_dim, seq_len=self.seq_len, cluster_factor=cluster_factor)\n",
    "        self.transformer=[\n",
    "            TransformerBlock(\n",
    "                num_heads=self.num_heads,\n",
    "                mlp_dim=self.mlp_dim,\n",
    "                dropout=self.dropout,\n",
    "                name=f\"Transformer_encoderblock_{n}\",\n",
    "            ) for n in range(self.num_layers)\n",
    "        ]\n",
    "        self.transformer_norm = layers.LayerNormalization(\n",
    "            epsilon=1e-6, name=\"Transformer_encoder_norm\"\n",
    "        )\n",
    "        self.embedding_inverse = layers.Conv2DTranspose(\n",
    "            filters=3,\n",
    "            kernel_size=self.patch_size,\n",
    "            strides=self.patch_size,\n",
    "            padding=\"valid\",\n",
    "            name=\"embedding_inverse\",\n",
    "        )\n",
    "        self.reshape_inverse = layers.Reshape((self.image_size[0] // self.patch_size, self.image_size[1] // self.patch_size, self.embedding_dim))\n",
    "\n",
    "    def reconstruction(self, O, mask):\n",
    "        '''Reconstructs the original masked patches from the transformer output and computes it to the spectrogram shape'''\n",
    "        O = (tf.ones((O.shape[0], O.shape[1], O.shape[2])) - mask) * O\n",
    "        return self.embedding_inverse(self.reshape_inverse(O))\n",
    "    \n",
    "    def classification(self, O, mask, candidate_patches, masked_indices):\n",
    "        \"\"\"For each masked patch, selects the correct patch among the candidates patches\"\"\"\n",
    "        masked_patches = (tf.ones((mask.shape[0], mask.shape[1], mask.shape[2])) - mask) * O\n",
    "        classifications = []\n",
    "        for i, elem in enumerate(masked_patches):\n",
    "            patch_classifications = []\n",
    "            for idx, j in enumerate(masked_indices):\n",
    "                patch = elem[j]\n",
    "                candidate_similarities = []\n",
    "                for candidate in candidate_patches[i][idx]:\n",
    "                    similarity = tf.reduce_sum(patch * candidate, axis=-1)\n",
    "                    candidate_similarities.append(similarity)\n",
    "                patch_classification = tf.stack(candidate_similarities)\n",
    "                patch_classifications.append(patch_classification)\n",
    "            classifications.append(patch_classifications)\n",
    "        return classifications\n",
    "\n",
    "    def convert_list_to_tensor(self, L, dtype=tf.float32):\n",
    "        max_len = max(len(inner_list) for inner_list in L)\n",
    "        padded_lists = []\n",
    "        for inner_list in L:\n",
    "            padded_list = [tf.convert_to_tensor(item, dtype=dtype) for item in inner_list]\n",
    "            padded_list += [tf.zeros_like(inner_list[0], dtype=tf.float32)] * (max_len - len(inner_list))\n",
    "            padded_lists.append(tf.stack(padded_list))\n",
    "        return tf.stack(padded_lists)\n",
    "\n",
    "    def call(self, x):\n",
    "        E = self.embedding(x)\n",
    "        E = self.reshape(E)\n",
    "\n",
    "        E_mask, mask, candidate_patches, masked_indices = self.mask_layer.call(E)\n",
    "\n",
    "        O = self.position_embedding(E_mask)\n",
    "        for n in range(self.num_layers):\n",
    "            O, _ = self.transformer[n](O, training=True)\n",
    "        O = self.transformer_norm(O)\n",
    "\n",
    "        r_i = self.reconstruction(O, mask)\n",
    "        c_i = self.classification(O, mask, candidate_patches, masked_indices)\n",
    "\n",
    "        r_i_true = (tf.ones((self.batch_size, E.shape[1], self.embedding_dim)) - mask) * E\n",
    "        r_i_true = self.embedding_inverse(self.reshape_inverse(r_i_true))\n",
    "        c_i_true = [[0 for _ in range(len(masked_indices))] for _ in range(self.batch_size)]  # Set all true indices to 0\n",
    "\n",
    "        c_i = self.convert_list_to_tensor(c_i)\n",
    "        c_i_true = tf.convert_to_tensor(c_i_true, dtype=tf.int64)\n",
    "\n",
    "        c_i = tf.reshape(c_i, [-1, int(self.mask_ratio*self.seq_len)])\n",
    "        c_i_true = tf.reshape(c_i_true, [-1])\n",
    "\n",
    "        return r_i, r_i_true, c_i, c_i_true\n",
    "\n",
    "    def compile(self, optimizer, **kwargs):\n",
    "        super(SSASTModel, self).compile(**kwargs)\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_tracker = metrics.Mean(name=\"loss\")\n",
    "        self.reconstruction_loss_tracker = metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.classification_loss_tracker = metrics.Mean(name=\"classification_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker, self.reconstruction_loss_tracker, self.classification_loss_tracker]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, _ = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            r_i, r_i_true, c_i, c_i_true = self(x, training=True)\n",
    "            reconstruction_loss = self.Lambda*losses.mean_squared_error(r_i_true, r_i)\n",
    "            classification_loss = losses.sparse_categorical_crossentropy(c_i_true, c_i, from_logits=True)\n",
    "            total_loss = tf.reduce_mean(reconstruction_loss) + tf.reduce_mean(classification_loss)\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "\n",
    "        self.loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.classification_loss_tracker.update_state(classification_loss)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, _ = data\n",
    "\n",
    "        r_i, r_i_true, c_i, c_i_true = self(x, training=False)\n",
    "        reconstruction_loss = self.Lambda * losses.mean_squared_error(r_i_true, r_i)\n",
    "        classification_loss = losses.sparse_categorical_crossentropy(c_i_true, c_i, from_logits=True)\n",
    "        total_loss = tf.reduce_mean(reconstruction_loss) + tf.reduce_mean(classification_loss)\n",
    "\n",
    "        self.loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.classification_loss_tracker.update_state(classification_loss)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "ssast_model = SSASTModel(image_size=(input_shape[0], input_shape[1]), Lambda=1000)\n",
    "test_input = tf.random.normal((32, input_shape[0], input_shape[1], 3))\n",
    "test_output = ssast_model(test_input)\n",
    "print(len(test_output), [o.shape for o in test_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssast_model.compile(\n",
    "    optimizer=keras.optimizers.Adam()\n",
    ")\n",
    "\n",
    "# early_stopping = EarlyStopping(\n",
    "#     monitor='val_loss',  \n",
    "#     patience=3,       \n",
    "#     restore_best_weights=True  \n",
    "# )\n",
    "\n",
    "# reduce_lr = ReduceLROnPlateau(\n",
    "#     monitor='val_loss', \n",
    "#     factor=0.1,         \n",
    "#     patience=2          \n",
    "# )\n",
    "\n",
    "# history = ssast_model.fit(\n",
    "#     ds_train.repeat(),\n",
    "#     validation_data=ds_val,\n",
    "#     epochs=4,\n",
    "#     steps_per_epoch=(int(0.7*ds_size)//batch_size),\n",
    "#     callbacks=[early_stopping, reduce_lr]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/volatile/home/bm279471/Documents/.venv/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 112 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# ssast_model.save_weights('ssast.weights.h5')\n",
    "ssast_model.load_weights('ssast.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "# reconstruction_loss = history.history['reconstruction_loss']\n",
    "# val_reconstruction_loss = history.history['val_reconstruction_loss']\n",
    "# classification_loss = history.history['classification_loss']\n",
    "# val_classification_loss = history.history['val_classification_loss']\n",
    "\n",
    "# # Créer une figure et des axes\n",
    "# fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# # Plot loss et val_loss\n",
    "# epochs = np.arange(1, len(loss) + 1)\n",
    "# ax.plot(epochs, loss, label='Training Loss', marker='o', linestyle='-', color='r')\n",
    "# ax.plot(epochs, val_loss, label='Validation Loss', marker='o', linestyle='--', color='r')\n",
    "\n",
    "\n",
    "# ax.plot(epochs, reconstruction_loss, label='Training Reconstruction Loss', marker='o', linestyle='-', color='b')\n",
    "# ax.plot(epochs, val_reconstruction_loss, label='Validation Reconstruction Loss', marker='o', linestyle='--', color='b')\n",
    "\n",
    "# ax.plot(epochs, classification_loss, label='Training Classification Loss', marker='o', linestyle='-', color='g')\n",
    "# ax.plot(epochs, val_classification_loss, label='Validation Classification Loss', marker='o', linestyle='--', color='g')\n",
    "\n",
    "# # Configurer les labels et la légende\n",
    "# ax.set_xlabel('Epochs')\n",
    "# ax.set_ylabel('Loss')\n",
    "# ax.set_title('Training and Validation Losses')\n",
    "# ax.legend()\n",
    "\n",
    "# # Afficher le graphique\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"classification_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"classification_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                </span>┃<span style=\"font-weight: bold\"> Output Shape          </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Trai… </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)          │ ?                     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │ ?                     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ Transformer_posembed_input  │ ?                     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AddPositionEmbs</span>)           │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ Transformer_encoderblock_0  │ ?                     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">99,584</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)          │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ Transformer_encoderblock_1  │ ?                     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">99,584</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)          │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ Transformer_encoderblock_2  │ ?                     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">99,584</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)          │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ Transformer_encoder_norm    │ ?                     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)        │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ MeanPooling                 │ ?                     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)    │                       │  (unbuilt) │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ Classification_head (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ ?                     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "│                             │                       │  (unbuilt) │       │\n",
       "└─────────────────────────────┴───────────────────────┴────────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mTrai…\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mConv2D\u001b[0m)          │ ?                     │     \u001b[38;5;34m98,432\u001b[0m │   \u001b[1;91mN\u001b[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)           │ ?                     │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ Transformer_posembed_input  │ ?                     │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n",
       "│ (\u001b[38;5;33mAddPositionEmbs\u001b[0m)           │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ Transformer_encoderblock_0  │ ?                     │     \u001b[38;5;34m99,584\u001b[0m │   \u001b[1;91mN\u001b[0m   │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)          │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ Transformer_encoderblock_1  │ ?                     │     \u001b[38;5;34m99,584\u001b[0m │   \u001b[1;91mN\u001b[0m   │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)          │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ Transformer_encoderblock_2  │ ?                     │     \u001b[38;5;34m99,584\u001b[0m │   \u001b[1;91mN\u001b[0m   │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)          │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ Transformer_encoder_norm    │ ?                     │        \u001b[38;5;34m256\u001b[0m │   \u001b[1;91mN\u001b[0m   │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)        │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ MeanPooling                 │ ?                     │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)    │                       │  (unbuilt) │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ Classification_head (\u001b[38;5;33mDense\u001b[0m) │ ?                     │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n",
       "│                             │                       │  (unbuilt) │       │\n",
       "└─────────────────────────────┴───────────────────────┴────────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">397,440</span> (1.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m397,440\u001b[0m (1.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">397,440</span> (1.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m397,440\u001b[0m (1.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class ClassificationModel(models.Model):\n",
    "    def __init__(self, model, **kwargs):\n",
    "        super(ClassificationModel, self).__init__(**kwargs)\n",
    "        self.seq_len = model.seq_len\n",
    "        self.image_size = model.image_size\n",
    "        self.patch_size = model.patch_size\n",
    "        self.num_layers = model.num_layers\n",
    "        self.embedding_dim = model.embedding_dim\n",
    "        self.num_heads = model.num_heads\n",
    "        self.mlp_dim = model.mlp_dim\n",
    "        self.dropout = model.dropout\n",
    "        self.batch_size = model.batch_size\n",
    "\n",
    "        self.embedding = model.embedding\n",
    "        self.reshape = model.reshape\n",
    "        self.position_embedding = model.position_embedding\n",
    "        self.transformer = model.transformer\n",
    "        self.transformer_norm = model.transformer_norm\n",
    "        self.meanpooling = layers.GlobalAveragePooling1D(name=\"MeanPooling\")\n",
    "        self.classification_layer = layers.Dense(nb_classes, name=\"Classification_head\")\n",
    "\n",
    "    def _set_non_trainable_layers(self):\n",
    "        for layer in [self.embedding, self.reshape, self.position_embedding, self.transformer_norm]:\n",
    "            layer.trainable = False\n",
    "        for transformer in self.transformer:\n",
    "            transformer.trainable = False\n",
    "            transformer.att.query_dense.trainable = False\n",
    "            transformer.att.key_dense.trainable = False\n",
    "            transformer.att.value_dense.trainable = False\n",
    "            transformer.att.combine_heads.trainable = False\n",
    "            transformer.mlpblock.trainable = False\n",
    "            transformer.layernorm1.trainable = False\n",
    "            transformer.layernorm2.trainable = False\n",
    "            transformer.dropout_layer.trainable = False\n",
    "\n",
    "    def _set_trainable_layers(self):\n",
    "        for layer in [self.embedding, self.reshape, self.position_embedding, self.transformer_norm]:\n",
    "            layer.trainable = True\n",
    "        for transformer in self.transformer:\n",
    "            transformer.trainable = True\n",
    "            transformer.att.query_dense.trainable = True\n",
    "            transformer.att.key_dense.trainable = True\n",
    "            transformer.att.value_dense.trainable = True\n",
    "            transformer.att.combine_heads.trainable = True\n",
    "            transformer.mlpblock.trainable = True\n",
    "            transformer.layernorm1.trainable = True\n",
    "            transformer.layernorm2.trainable = True\n",
    "            transformer.dropout_layer.trainable = True\n",
    "\n",
    "    def call(self, x):\n",
    "        E = self.embedding(x)\n",
    "        E = self.reshape(E)\n",
    "\n",
    "        O = self.position_embedding(E)\n",
    "        for n in range(self.num_layers):\n",
    "            O, _ = self.transformer[n](O, training=True)\n",
    "        O = self.transformer_norm(O)\n",
    "\n",
    "        O = self.meanpooling(O)\n",
    "        O = self.classification_layer(O)\n",
    "        return O\n",
    "    \n",
    "classification_model=ClassificationModel(ssast_model)\n",
    "classification_model._set_non_trainable_layers()\n",
    "\n",
    "classification_model.summary(show_trainable=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 627ms/step - accuracy: 0.0567 - loss: 3.3778 - val_accuracy: 0.0862 - val_loss: 3.2245 - learning_rate: 0.0010\n",
      "Epoch 2/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 517ms/step - accuracy: 0.1150 - loss: 3.1980 - val_accuracy: 0.1019 - val_loss: 3.1152 - learning_rate: 0.0010\n",
      "Epoch 3/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 519ms/step - accuracy: 0.1269 - loss: 3.1039 - val_accuracy: 0.1244 - val_loss: 3.0468 - learning_rate: 0.0010\n",
      "Epoch 4/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 510ms/step - accuracy: 0.1440 - loss: 3.0403 - val_accuracy: 0.1456 - val_loss: 2.9961 - learning_rate: 0.0010\n",
      "Epoch 5/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 529ms/step - accuracy: 0.1647 - loss: 2.9853 - val_accuracy: 0.1488 - val_loss: 2.9535 - learning_rate: 0.0010\n",
      "Epoch 6/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 531ms/step - accuracy: 0.1762 - loss: 2.9437 - val_accuracy: 0.1644 - val_loss: 2.9190 - learning_rate: 0.0010\n",
      "Epoch 7/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 514ms/step - accuracy: 0.1854 - loss: 2.9074 - val_accuracy: 0.1737 - val_loss: 2.8864 - learning_rate: 0.0010\n",
      "Epoch 8/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 506ms/step - accuracy: 0.1886 - loss: 2.8733 - val_accuracy: 0.1694 - val_loss: 2.8609 - learning_rate: 0.0010\n",
      "Epoch 9/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 508ms/step - accuracy: 0.1958 - loss: 2.8450 - val_accuracy: 0.1825 - val_loss: 2.8353 - learning_rate: 0.0010\n",
      "Epoch 10/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 516ms/step - accuracy: 0.2021 - loss: 2.8172 - val_accuracy: 0.1875 - val_loss: 2.8123 - learning_rate: 0.0010\n",
      "Epoch 11/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 537ms/step - accuracy: 0.2115 - loss: 2.7945 - val_accuracy: 0.1863 - val_loss: 2.7900 - learning_rate: 0.0010\n",
      "Epoch 12/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 500ms/step - accuracy: 0.2063 - loss: 2.7684 - val_accuracy: 0.1994 - val_loss: 2.7687 - learning_rate: 0.0010\n",
      "Epoch 13/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 363ms/step - accuracy: 0.2401 - loss: 2.7489 - val_accuracy: 0.1981 - val_loss: 2.7515 - learning_rate: 0.0010\n",
      "Epoch 14/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 371ms/step - accuracy: 0.2354 - loss: 2.7230 - val_accuracy: 0.2119 - val_loss: 2.7318 - learning_rate: 0.0010\n",
      "Epoch 15/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 379ms/step - accuracy: 0.2459 - loss: 2.7047 - val_accuracy: 0.2150 - val_loss: 2.7144 - learning_rate: 0.0010\n",
      "Epoch 16/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 380ms/step - accuracy: 0.2535 - loss: 2.6848 - val_accuracy: 0.2313 - val_loss: 2.7018 - learning_rate: 0.0010\n",
      "Epoch 17/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 388ms/step - accuracy: 0.2598 - loss: 2.6673 - val_accuracy: 0.2375 - val_loss: 2.6841 - learning_rate: 0.0010\n",
      "Epoch 18/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 343ms/step - accuracy: 0.2606 - loss: 2.6494 - val_accuracy: 0.2362 - val_loss: 2.6711 - learning_rate: 0.0010\n",
      "Epoch 19/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 355ms/step - accuracy: 0.2685 - loss: 2.6340 - val_accuracy: 0.2412 - val_loss: 2.6563 - learning_rate: 0.0010\n",
      "Epoch 20/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 361ms/step - accuracy: 0.2842 - loss: 2.6146 - val_accuracy: 0.2488 - val_loss: 2.6391 - learning_rate: 0.0010\n",
      "Epoch 21/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 347ms/step - accuracy: 0.2877 - loss: 2.6014 - val_accuracy: 0.2519 - val_loss: 2.6278 - learning_rate: 0.0010\n",
      "Epoch 22/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 350ms/step - accuracy: 0.2944 - loss: 2.5829 - val_accuracy: 0.2569 - val_loss: 2.6130 - learning_rate: 0.0010\n",
      "Epoch 23/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 348ms/step - accuracy: 0.2833 - loss: 2.5688 - val_accuracy: 0.2663 - val_loss: 2.6013 - learning_rate: 0.0010\n",
      "Epoch 24/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 386ms/step - accuracy: 0.2952 - loss: 2.5529 - val_accuracy: 0.2663 - val_loss: 2.5887 - learning_rate: 0.0010\n",
      "Epoch 25/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 392ms/step - accuracy: 0.3055 - loss: 2.5469 - val_accuracy: 0.2725 - val_loss: 2.5765 - learning_rate: 0.0010\n",
      "Epoch 26/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 354ms/step - accuracy: 0.3241 - loss: 2.5260 - val_accuracy: 0.2788 - val_loss: 2.5684 - learning_rate: 0.0010\n",
      "Epoch 27/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 410ms/step - accuracy: 0.3056 - loss: 2.5172 - val_accuracy: 0.2775 - val_loss: 2.5554 - learning_rate: 0.0010\n",
      "Epoch 28/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 365ms/step - accuracy: 0.3215 - loss: 2.4981 - val_accuracy: 0.2956 - val_loss: 2.5448 - learning_rate: 0.0010\n",
      "Epoch 29/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 362ms/step - accuracy: 0.3253 - loss: 2.4876 - val_accuracy: 0.2956 - val_loss: 2.5340 - learning_rate: 0.0010\n",
      "Epoch 30/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 388ms/step - accuracy: 0.3311 - loss: 2.4747 - val_accuracy: 0.3069 - val_loss: 2.5200 - learning_rate: 0.0010\n",
      "Epoch 31/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 483ms/step - accuracy: 0.3344 - loss: 2.4606 - val_accuracy: 0.3013 - val_loss: 2.5131 - learning_rate: 0.0010\n",
      "Epoch 32/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 537ms/step - accuracy: 0.3430 - loss: 2.4510 - val_accuracy: 0.3119 - val_loss: 2.5053 - learning_rate: 0.0010\n",
      "Epoch 33/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 519ms/step - accuracy: 0.3506 - loss: 2.4361 - val_accuracy: 0.3137 - val_loss: 2.4926 - learning_rate: 0.0010\n",
      "Epoch 34/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 528ms/step - accuracy: 0.3459 - loss: 2.4314 - val_accuracy: 0.3212 - val_loss: 2.4850 - learning_rate: 0.0010\n",
      "Epoch 35/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 511ms/step - accuracy: 0.3571 - loss: 2.4175 - val_accuracy: 0.3212 - val_loss: 2.4724 - learning_rate: 0.0010\n",
      "Epoch 36/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 575ms/step - accuracy: 0.3699 - loss: 2.4075 - val_accuracy: 0.3294 - val_loss: 2.4661 - learning_rate: 0.0010\n",
      "Epoch 37/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 522ms/step - accuracy: 0.3754 - loss: 2.3988 - val_accuracy: 0.3381 - val_loss: 2.4530 - learning_rate: 0.0010\n",
      "Epoch 38/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 526ms/step - accuracy: 0.3720 - loss: 2.3862 - val_accuracy: 0.3338 - val_loss: 2.4462 - learning_rate: 0.0010\n",
      "Epoch 39/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 489ms/step - accuracy: 0.3842 - loss: 2.3764 - val_accuracy: 0.3425 - val_loss: 2.4355 - learning_rate: 0.0010\n",
      "Epoch 40/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 549ms/step - accuracy: 0.3815 - loss: 2.3635 - val_accuracy: 0.3425 - val_loss: 2.4257 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "classification_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(), \n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=5,       \n",
    "    restore_best_weights=True  \n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.1,         \n",
    "    patience=2          \n",
    ")\n",
    "\n",
    "classification_history = classification_model.fit(\n",
    "    ds_transfer.repeat(),\n",
    "    validation_data=ds_val,\n",
    "    epochs=40,\n",
    "    steps_per_epoch=(int(0.1*ds_size)//batch_size),\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1654/1654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 113ms/step - accuracy: 0.3295 - loss: 2.4944\n",
      "Evaluation accuracy : 33.31%\n"
     ]
    }
   ],
   "source": [
    "evaluation = classification_model.evaluate(ds_test)\n",
    "print(\"Evaluation accuracy : {:.2f}%\".format(evaluation[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 907ms/step - accuracy: 0.3978 - loss: 2.3031 - val_accuracy: 0.3619 - val_loss: 2.2379 - learning_rate: 1.0000e-05\n",
      "Epoch 2/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 785ms/step - accuracy: 0.4324 - loss: 2.0594 - val_accuracy: 0.4075 - val_loss: 2.1034 - learning_rate: 1.0000e-05\n",
      "Epoch 3/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 659ms/step - accuracy: 0.4794 - loss: 1.8625 - val_accuracy: 0.4356 - val_loss: 1.9598 - learning_rate: 1.0000e-05\n",
      "Epoch 4/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 712ms/step - accuracy: 0.5151 - loss: 1.6990 - val_accuracy: 0.4669 - val_loss: 1.8509 - learning_rate: 1.0000e-05\n",
      "Epoch 5/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 712ms/step - accuracy: 0.5636 - loss: 1.5735 - val_accuracy: 0.4906 - val_loss: 1.7584 - learning_rate: 1.0000e-05\n",
      "Epoch 6/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 713ms/step - accuracy: 0.5900 - loss: 1.4892 - val_accuracy: 0.5100 - val_loss: 1.6857 - learning_rate: 1.0000e-05\n",
      "Epoch 7/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 709ms/step - accuracy: 0.6031 - loss: 1.4104 - val_accuracy: 0.5350 - val_loss: 1.6180 - learning_rate: 1.0000e-05\n",
      "Epoch 8/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 713ms/step - accuracy: 0.6291 - loss: 1.3595 - val_accuracy: 0.5506 - val_loss: 1.5714 - learning_rate: 1.0000e-05\n",
      "Epoch 9/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 570ms/step - accuracy: 0.6464 - loss: 1.2929 - val_accuracy: 0.5675 - val_loss: 1.5103 - learning_rate: 1.0000e-05\n",
      "Epoch 10/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 523ms/step - accuracy: 0.6628 - loss: 1.2455 - val_accuracy: 0.5806 - val_loss: 1.4574 - learning_rate: 1.0000e-05\n",
      "Epoch 11/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 518ms/step - accuracy: 0.6907 - loss: 1.1864 - val_accuracy: 0.5962 - val_loss: 1.4174 - learning_rate: 1.0000e-05\n",
      "Epoch 12/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 520ms/step - accuracy: 0.7053 - loss: 1.1397 - val_accuracy: 0.6194 - val_loss: 1.3744 - learning_rate: 1.0000e-05\n",
      "Epoch 13/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 522ms/step - accuracy: 0.7173 - loss: 1.0954 - val_accuracy: 0.6275 - val_loss: 1.3240 - learning_rate: 1.0000e-05\n",
      "Epoch 14/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 599ms/step - accuracy: 0.7449 - loss: 1.0542 - val_accuracy: 0.6331 - val_loss: 1.2924 - learning_rate: 1.0000e-05\n",
      "Epoch 15/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 714ms/step - accuracy: 0.7504 - loss: 1.0214 - val_accuracy: 0.6637 - val_loss: 1.2557 - learning_rate: 1.0000e-05\n",
      "Epoch 16/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 714ms/step - accuracy: 0.7679 - loss: 0.9771 - val_accuracy: 0.6800 - val_loss: 1.2264 - learning_rate: 1.0000e-05\n",
      "Epoch 17/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 706ms/step - accuracy: 0.7795 - loss: 0.9492 - val_accuracy: 0.6825 - val_loss: 1.2163 - learning_rate: 1.0000e-05\n",
      "Epoch 18/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 709ms/step - accuracy: 0.7977 - loss: 0.9138 - val_accuracy: 0.6850 - val_loss: 1.1711 - learning_rate: 1.0000e-05\n",
      "Epoch 19/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 711ms/step - accuracy: 0.8120 - loss: 0.8785 - val_accuracy: 0.7100 - val_loss: 1.1359 - learning_rate: 1.0000e-05\n",
      "Epoch 20/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 709ms/step - accuracy: 0.8173 - loss: 0.8524 - val_accuracy: 0.7119 - val_loss: 1.1116 - learning_rate: 1.0000e-05\n",
      "Epoch 21/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 708ms/step - accuracy: 0.8255 - loss: 0.8195 - val_accuracy: 0.7169 - val_loss: 1.0930 - learning_rate: 1.0000e-05\n",
      "Epoch 22/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 711ms/step - accuracy: 0.8335 - loss: 0.8026 - val_accuracy: 0.7312 - val_loss: 1.0508 - learning_rate: 1.0000e-05\n",
      "Epoch 23/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 713ms/step - accuracy: 0.8528 - loss: 0.7709 - val_accuracy: 0.7294 - val_loss: 1.0237 - learning_rate: 1.0000e-05\n",
      "Epoch 24/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 710ms/step - accuracy: 0.8581 - loss: 0.7420 - val_accuracy: 0.7456 - val_loss: 1.0027 - learning_rate: 1.0000e-05\n",
      "Epoch 25/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 710ms/step - accuracy: 0.8614 - loss: 0.7217 - val_accuracy: 0.7475 - val_loss: 0.9898 - learning_rate: 1.0000e-05\n",
      "Epoch 26/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 638ms/step - accuracy: 0.8680 - loss: 0.6963 - val_accuracy: 0.7656 - val_loss: 0.9668 - learning_rate: 1.0000e-05\n",
      "Epoch 27/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 497ms/step - accuracy: 0.8799 - loss: 0.6737 - val_accuracy: 0.7650 - val_loss: 0.9446 - learning_rate: 1.0000e-05\n",
      "Epoch 28/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 495ms/step - accuracy: 0.8834 - loss: 0.6554 - val_accuracy: 0.7656 - val_loss: 0.9298 - learning_rate: 1.0000e-05\n",
      "Epoch 29/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 499ms/step - accuracy: 0.8878 - loss: 0.6345 - val_accuracy: 0.7738 - val_loss: 0.9033 - learning_rate: 1.0000e-05\n",
      "Epoch 30/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 500ms/step - accuracy: 0.8894 - loss: 0.6118 - val_accuracy: 0.7900 - val_loss: 0.8790 - learning_rate: 1.0000e-05\n",
      "Epoch 31/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 492ms/step - accuracy: 0.9080 - loss: 0.5820 - val_accuracy: 0.8012 - val_loss: 0.8557 - learning_rate: 1.0000e-05\n",
      "Epoch 32/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 498ms/step - accuracy: 0.9058 - loss: 0.5711 - val_accuracy: 0.7862 - val_loss: 0.8517 - learning_rate: 1.0000e-05\n",
      "Epoch 33/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 500ms/step - accuracy: 0.9157 - loss: 0.5479 - val_accuracy: 0.7981 - val_loss: 0.8314 - learning_rate: 1.0000e-05\n",
      "Epoch 34/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 496ms/step - accuracy: 0.9189 - loss: 0.5446 - val_accuracy: 0.8081 - val_loss: 0.8053 - learning_rate: 1.0000e-05\n",
      "Epoch 35/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 495ms/step - accuracy: 0.9194 - loss: 0.5202 - val_accuracy: 0.8163 - val_loss: 0.7913 - learning_rate: 1.0000e-05\n",
      "Epoch 36/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 496ms/step - accuracy: 0.9159 - loss: 0.5087 - val_accuracy: 0.8175 - val_loss: 0.7655 - learning_rate: 1.0000e-05\n",
      "Epoch 37/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 498ms/step - accuracy: 0.9277 - loss: 0.4810 - val_accuracy: 0.8175 - val_loss: 0.7526 - learning_rate: 1.0000e-05\n",
      "Epoch 38/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 473ms/step - accuracy: 0.9281 - loss: 0.4694 - val_accuracy: 0.8244 - val_loss: 0.7491 - learning_rate: 1.0000e-05\n",
      "Epoch 39/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 419ms/step - accuracy: 0.9358 - loss: 0.4567 - val_accuracy: 0.8250 - val_loss: 0.7305 - learning_rate: 1.0000e-05\n",
      "Epoch 40/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 419ms/step - accuracy: 0.9432 - loss: 0.4419 - val_accuracy: 0.8325 - val_loss: 0.7291 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "classification_model._set_trainable_layers()\n",
    "\n",
    "classification_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-5), \n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=5,       \n",
    "    restore_best_weights=True  \n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.1,         \n",
    "    patience=2          \n",
    ")\n",
    "\n",
    "classification_history = classification_model.fit(\n",
    "    ds_transfer.repeat(),\n",
    "    validation_data=ds_val,\n",
    "    epochs=40,\n",
    "    steps_per_epoch=(int(0.1*ds_size)//batch_size),\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1654/1654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 60ms/step - accuracy: 0.8055 - loss: 0.7815\n",
      "Evaluation accuracy : 81.98%\n"
     ]
    }
   ],
   "source": [
    "evaluation = classification_model.evaluate(ds_test)\n",
    "print(\"Evaluation accuracy : {:.2f}%\".format(evaluation[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
