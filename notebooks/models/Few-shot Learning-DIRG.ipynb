{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19108fd3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Few-shot Learning on DIRG\n",
    "\n",
    "We demonstrate the FS learning framework on the dataset `DIRG`, which has fewer classes, a higher sampling rate and more channels than `CWRU`. It turns out `DIRG` is significantly harder. Here are some points worth further study to improve the performance:\n",
    "\n",
    "- characteristics of the feature: STFS window length, spectral patch shape\n",
    "- choose of channels: 'A1' and/or 'A2'. A pre-input layer is necessary if the number of channels isn't 3\n",
    "\n",
    "The best performance obtained using 20% of data for training is ~ 70% after the fine tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d72f3e2e-f1c6-4a57-b688-5594292a60d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Minimal\n"
     ]
    }
   ],
   "source": [
    "%xmode minimal\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Turn off logging for TF\n",
    "import logging\n",
    "# tf.get_logger().setLevel(logging.ERROR)\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # disable GPU devices\n",
    "os.environ[\"TFDS_DATA_DIR\"] = os.path.expanduser(\"~/tensorflow_datasets\")  # default location of tfds database\n",
    "\n",
    "import os\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "import keras\n",
    "from keras import layers, models, ops\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# from IPython.display import Audio\n",
    "\n",
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa9e43e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dpmhm\n",
    "# dpmhm.datasets.get_dataset_list()\n",
    "\n",
    "from dpmhm.datasets import preprocessing, feature, utils, transformer, query_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9777985f-37a8-469d-8a0e-f9169bb767b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_name = 'DIRG'\n",
    "\n",
    "outdir = Path(f'/home/han/tmp/dpmhm/few-shot/{ds_name}')\n",
    "os.makedirs(outdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bff78678-050e-4911-bced-2b4cf4ac5f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'signal': {'A1': 3, 'A2': 3},\n",
       " 'sampling_rate': [51200, 102400],\n",
       " 'keys': {'FaultComponent': {'InnerRing', 'Roller'},\n",
       "  'FaultSize': {0, 150, 250, 450}},\n",
       " 'filters': {'RotatingSpeed': {100, 200, 300, 400, 500},\n",
       "  'NominalLoadForce': {0, 1000, 1400, 1800}},\n",
       " 'type': 'initiated+failure',\n",
       " 'split': ['vibration', 'endurance']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_parameters(ds_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6c5e43-be47-4cc8-9020-93e8e3ee35a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c6ec45e-3f84-4acb-a039-48ecce463364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dictionary of labels: {'6c2972e6362a149d': ['InnerRing', '450'], 'f1ec5257d3156fa9': ['Roller', '150'], '536057fae7e77d53': ['None', '0'], 'e67b723eb0cefad6': ['Roller', '250'], '3f589794bedff28d': ['InnerRing', '250'], '0e585b7656ed7f4c': ['InnerRing', '150'], '8f6697984c79c128': ['Roller', '450']}\n",
      "Integer index of labels: {'6c2972e6362a149d': 1, 'f1ec5257d3156fa9': 2, '536057fae7e77d53': 3, 'e67b723eb0cefad6': 4, '3f589794bedff28d': 5, '0e585b7656ed7f4c': 6, '8f6697984c79c128': 7}\n"
     ]
    }
   ],
   "source": [
    "_func = lambda x, sr: feature.spectral_features(\n",
    "    x, sr, 'spectrogram',\n",
    "    # n_mfcc=256,\n",
    "    time_window=0.025, hop_step=0.0125,\n",
    "    # n_fft=512,\n",
    "    normalize=False, to_db=True)[0]\n",
    "\n",
    "compactor_kwargs = dict(\n",
    "    # # CWRU\n",
    "    # channels=[],\n",
    "    # keys=['FaultLocation', 'FaultComponent', 'FaultSize'],\n",
    "    # DIRG\n",
    "    # channels=['A1', 'A2'],\n",
    "    channels=['A1'],\n",
    "    keys=['FaultComponent', 'FaultSize'],\n",
    ")\n",
    "\n",
    "window_kwargs = dict(\n",
    "    # window_size=(128,64), \n",
    "    # hop_size=(128,64),\n",
    "    window_size=(64,64), \n",
    "    hop_size=(64,64),\n",
    "    # hop_size=(32,32)    \n",
    ")\n",
    "\n",
    "ds0, full_label_dict = dpmhm.datasets.spectral_window_pipeline(\n",
    "    ds_name, \n",
    "    split='variation',\n",
    "    spectral_feature=_func,\n",
    "    compactor_kwargs=compactor_kwargs,\n",
    "    window_kwargs=window_kwargs,\n",
    ")\n",
    "\n",
    "print('Full dictionary of labels:', full_label_dict)\n",
    "\n",
    "label_index_dict = preprocessing.get_label_mapping(list(full_label_dict.keys()))\n",
    "print('Integer index of labels:', label_index_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8cb18b-4419-452d-ad11-542fcb024823",
   "metadata": {},
   "source": [
    "### Split for few-shot learning with OOD\n",
    "\n",
    "Jump directly to the next section \"Export and reload...\" if a dataset has already be produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e7c75df-2d89-4103-8aad-d8bfd0da4ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = preprocessing.get_mapping_supervised(list(full_label_dict.keys()))\n",
    "\n",
    "ds1 = utils.restore_shape(\n",
    "    ds0.map(preproc, num_parallel_calls=tf.data.AUTOTUNE),\n",
    "    key=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "081f3e25-cde8-4d86-8f64-e53efbab1f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOD labels\n",
    "labels_ood = [1]\n",
    "labels = [l for l in label_index_dict.values() if l not in labels_ood]\n",
    "\n",
    "# Extract OOD samples and concatenate into a single OOD category\n",
    "# use key=1 here because `ds1` is a tuple dataset and 1 is the index of the label field\n",
    "foo = utils.extract_by_category(ds1, labels_ood, key=1)  \n",
    "ds_ood = None\n",
    "for k, dv in foo.items():\n",
    "    try:\n",
    "        ds_ood = ds_ood.concatenate(dv)\n",
    "    except:\n",
    "        ds_ood = dv\n",
    "\n",
    "# Few-shot split\n",
    "splits = {'train':0.2, 'val':0.7, 'test':0.1}\n",
    "ds_split = utils.split_dataset(ds1, splits=splits, labels=labels, key=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cc8dc8-eeef-4479-860c-d91c3c9e9946",
   "metadata": {},
   "source": [
    "#### Export and reload the preprocessed dataset \n",
    "\n",
    "For a better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9bce97c-9fe2-4415-8c88-7fe221419f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbdir = outdir / utils.md5_encoder([compactor_kwargs, window_kwargs])\n",
    "# Bug in Tensorflow: folder name containing '[ ]'\n",
    "# dbdir = outdir/f\"channels[{compactor_kwargs['channels']}]_windowsize[{window_kwargs['window_size']}]\"\n",
    "\n",
    "os.makedirs(dbdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24955c71-81bc-4fd2-9b16-efeb33423fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, dv in ds_split.items():\n",
    "    dv.save(str(dbdir/k))\n",
    "\n",
    "ds_ood.save(str(dbdir/'ood'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1667f70-0440-41ea-8ed7-612a1b86618d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(64, 64, 3), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None)) tf.Tensor(3264, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "ds_split = {}\n",
    "\n",
    "for k in ['train', 'val', 'test']:\n",
    "    ds_split[k] = tf.data.Dataset.load(str(dbdir/k))\n",
    "\n",
    "ds_ood = tf.data.Dataset.load(str(dbdir/'ood'))\n",
    "\n",
    "print(ds_ood.element_spec, ds_ood.cardinality())\n",
    "\n",
    "# ds_split['train'].cardinality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66278f67-6964-42b8-b313-a3770a8ec674",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor: shape=(64, 64, 3), dtype=float32, numpy=\n",
       "  array([[[46.202293, 62.192078, 58.752598],\n",
       "          [37.077477, 68.385185, 64.99098 ],\n",
       "          [37.469414, 68.46131 , 65.06549 ],\n",
       "          ...,\n",
       "          [38.334637, 68.47639 , 64.78662 ],\n",
       "          [37.787514, 68.39858 , 64.78197 ],\n",
       "          [37.9596  , 68.31246 , 64.82229 ]],\n",
       "  \n",
       "         [[45.900124, 61.477142, 58.044533],\n",
       "          [34.768158, 66.16981 , 62.738518],\n",
       "          [35.287384, 66.20686 , 62.83062 ],\n",
       "          ...,\n",
       "          [36.609238, 66.22987 , 62.547684],\n",
       "          [35.634476, 66.151245, 62.536148],\n",
       "          [35.66985 , 66.06192 , 62.581184]],\n",
       "  \n",
       "         [[45.232895, 59.29322 , 55.8773  ],\n",
       "          [26.86792 , 58.688934, 55.0765  ],\n",
       "          [27.811806, 58.5095  , 55.254154],\n",
       "          ...,\n",
       "          [31.445742, 58.571144, 54.966766],\n",
       "          [28.559397, 58.508118, 54.881035],\n",
       "          [27.7387  , 58.38472 , 54.955673]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[40.85623 , 34.909885, 47.234863],\n",
       "          [38.9846  , 35.704426, 39.57624 ],\n",
       "          [47.470913, 39.260773, 49.57502 ],\n",
       "          ...,\n",
       "          [49.55198 , 39.844864, 46.970802],\n",
       "          [46.720924, 40.8898  , 41.593117],\n",
       "          [46.381893, 42.53513 , 36.135326]],\n",
       "  \n",
       "         [[26.852625, 40.790344, 48.474422],\n",
       "          [49.32714 , 41.144928, 46.42162 ],\n",
       "          [48.517822, 42.319542, 52.539642],\n",
       "          ...,\n",
       "          [50.16606 , 42.581963, 49.39933 ],\n",
       "          [43.54706 , 41.041428, 42.167824],\n",
       "          [53.30643 , 43.546425, 47.40673 ]],\n",
       "  \n",
       "         [[37.294342, 43.76499 , 46.95771 ],\n",
       "          [54.91249 , 43.570053, 53.232872],\n",
       "          [51.96609 , 43.133705, 55.71796 ],\n",
       "          ...,\n",
       "          [50.347015, 43.625587, 52.72342 ],\n",
       "          [55.164715, 39.561256, 54.179733],\n",
       "          [57.023815, 42.7623  , 52.937416]]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(), dtype=int32, numpy=1>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ds_ood.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639a4e02-a166-4e29-96f5-511693ae2880",
   "metadata": {},
   "source": [
    "## Train a VGGish network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98852014-e25f-4ae3-bc7b-30dd2351d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "shuffle_size = max(1000, ds_split['train'].cardinality())\n",
    "\n",
    "ds_train = ds_split['train']\\\n",
    "    .shuffle(shuffle_size, reshuffle_each_iteration=True)\\\n",
    "    .batch(batch_size, drop_remainder=True)\\\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    "ds_val = ds_split['val'].batch(batch_size, drop_remainder=True)\n",
    "ds_test = ds_split['test'].batch(batch_size, drop_remainder=True)\n",
    "\n",
    "ds_ood_test = ds_ood.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "n_classes = len(full_label_dict) + 1\n",
    "\n",
    "input_shape = ds_split['train'].element_spec[0].shape\n",
    "\n",
    "if input_shape[-1] != 3:\n",
    "    # If the number of channels in the orignal data isn't 3, use a first layer to adapt to the base model\n",
    "    input_model = models.Sequential([\n",
    "        layers.Input(shape=input_shape, name='input'),\n",
    "        layers.Conv2D(3, kernel_size=(1,1), activation=None, padding='same')\n",
    "    ])\n",
    "    # input_shape = input_model(layers.Input(input_shape)).shape\n",
    "    input_shape1 = (*input_shape[:-1], 3)\n",
    "else:\n",
    "    input_model = models.Sequential([\n",
    "        layers.Input(shape=input_shape, name='input'),\n",
    "    ])\n",
    "    input_shape1 = input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25696352-23a1-4acd-aaa3-b0d57bac2b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16, resnet\n",
    "\n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=input_shape1, pooling='max')\n",
    "# base_model = resnet.ResNet50(include_top=False, weights='imagenet', input_shape=input_shape1, pooling='max')\n",
    "\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a4b9e94-b10a-4801-9767-27e6207bdffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Input(input_shape)\n",
    "\n",
    "adapt_model = models.Sequential([\n",
    "    layers.Flatten(name=\"flatten\"),\n",
    "    # layers.Dense(256, activation=\"relu\", name=\"fc1\"),\n",
    "    layers.Dense(4096, activation=\"relu\", name=\"fc1\"),\n",
    "    layers.BatchNormalization(),\n",
    "    # layers.Dense(128, activation=\"relu\", name=\"fc2\"),\n",
    "    layers.Dense(4096, activation=\"relu\", name=\"fc2\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(n_classes, activation=None, name=\"predictions\")\n",
    "])\n",
    "\n",
    "y = adapt_model(base_model(input_model(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dfa7aa2-322f-4378-bb0c-f21b41191309",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Model(x, y)\n",
    "\n",
    "from_logits = 'softmax' not in str(model.layers[-1].get_layer('predictions').activation)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=from_logits),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e75520a7-4bfc-421d-8f66-6615af88a3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 635ms/step - accuracy: 0.2962 - loss: 5.0769 - val_accuracy: 0.5406 - val_loss: 2.5787\n",
      "Epoch 2/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 624ms/step - accuracy: 0.5170 - loss: 1.3911 - val_accuracy: 0.5109 - val_loss: 2.2224\n",
      "Epoch 3/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 619ms/step - accuracy: 0.5728 - loss: 1.2863 - val_accuracy: 0.5047 - val_loss: 1.9262\n",
      "Epoch 4/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 613ms/step - accuracy: 0.5929 - loss: 1.1848 - val_accuracy: 0.4547 - val_loss: 2.0364\n",
      "Epoch 5/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 612ms/step - accuracy: 0.6211 - loss: 1.1043 - val_accuracy: 0.6641 - val_loss: 1.0572\n",
      "Epoch 6/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 617ms/step - accuracy: 0.6842 - loss: 0.9084 - val_accuracy: 0.6219 - val_loss: 1.4327\n",
      "Epoch 7/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 619ms/step - accuracy: 0.7033 - loss: 0.8741 - val_accuracy: 0.6141 - val_loss: 1.4032\n",
      "Epoch 8/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 615ms/step - accuracy: 0.7057 - loss: 0.8914 - val_accuracy: 0.6547 - val_loss: 1.3211\n",
      "Epoch 8: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val.take(10),\n",
    "    epochs=20,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bb4d5f2-775d-4f81-b809-d8181130d926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 615ms/step - accuracy: 0.8655 - loss: 0.4330 - val_accuracy: 0.6109 - val_loss: 1.4836\n",
      "Epoch 2/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 619ms/step - accuracy: 0.8683 - loss: 0.3869 - val_accuracy: 0.8328 - val_loss: 0.5917\n",
      "Epoch 3/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 615ms/step - accuracy: 0.8867 - loss: 0.3569 - val_accuracy: 0.6672 - val_loss: 1.4470\n",
      "Epoch 4/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 619ms/step - accuracy: 0.8894 - loss: 0.3431 - val_accuracy: 0.6328 - val_loss: 1.5205\n",
      "Epoch 5/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 617ms/step - accuracy: 0.8784 - loss: 0.4009 - val_accuracy: 0.8188 - val_loss: 0.8124\n",
      "Epoch 6/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 626ms/step - accuracy: 0.9045 - loss: 0.3068 - val_accuracy: 0.7750 - val_loss: 0.8625\n",
      "Epoch 7/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 615ms/step - accuracy: 0.9189 - loss: 0.2760 - val_accuracy: 0.6656 - val_loss: 1.6977\n",
      "Epoch 7: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val.take(10),\n",
    "    epochs=20,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f57531f-d686-4f08-8f1e-ac04b9a72c8b",
   "metadata": {},
   "source": [
    "Performance of the trained model on test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66bef9d5-354a-4312-a5dd-050e609fc186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 477ms/step - accuracy: 0.5940 - loss: 1.9041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.0414507389068604, 0.546875]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfd5f6a-f2a6-4564-9219-ecd2d0d518ab",
   "metadata": {},
   "source": [
    "On the contrary, on OOD data completely failed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5c53910-6b3b-4b94-a0c8-6227045106bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 479ms/step - accuracy: 0.0000e+00 - loss: 11.8054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.648832321166992, 0.0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(ds_ood_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37575857-d5cc-4f10-a7f5-ffd1542d31a7",
   "metadata": {},
   "source": [
    "### Fine tuning\n",
    "\n",
    "Fine tuning in the few-shot learning scenario may still improve the model's performance, despite the insufficient training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77f5eaf4-9eca-4dbf-8ebf-74fd7c6935f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=from_logits),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96ad8508-d9d5-4b37-a869-b13d2fcf7d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 2s/step - accuracy: 0.9179 - loss: 0.2620 - val_accuracy: 0.7828 - val_loss: 0.9710\n",
      "Epoch 2/2\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 2s/step - accuracy: 0.9498 - loss: 0.1710 - val_accuracy: 0.8234 - val_loss: 0.7939\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val.take(10),\n",
    "    epochs=2,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "165702e6-83c5-4c24-9d33-6e016cbca1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 477ms/step - accuracy: 0.7230 - loss: 1.2123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.307074785232544, 0.6854166388511658]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76d15fbf-3a11-4c82-b4eb-10afd4499766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 472ms/step - accuracy: 0.0000e+00 - loss: 11.1884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.05380916595459, 0.0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(ds_ood_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3730a7f8-e494-4db5-a59e-af69c092475c",
   "metadata": {},
   "source": [
    "### Adaptation on OOD data\n",
    "\n",
    "We may adapt the model on OOD data, however this may incur the catastrophic forget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5bff9bc3-5da6-4aaa-b1b8-1cc461f2a7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the OOD data\n",
    "ds_ood_split = utils.split_dataset(ds_ood, {'train':0.2, 'val':0.7, 'test':0.1}, key=1)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "ds_ood_train = ds_ood_split['train']\\\n",
    "    .shuffle(1000, reshuffle_each_iteration=True)\\\n",
    "    .batch(batch_size, drop_remainder=True)\\\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    "ds_ood_val = ds_ood_split['val'].batch(batch_size, drop_remainder=True)\n",
    "ds_ood_test = ds_ood_split['test'].batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b102769-cb55-40ed-be94-5da1fb3d3fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=from_logits),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa267f4d-e27d-4280-a7be-90d3fbf3482d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.0000e+00 - loss: 27.8739 - val_accuracy: 0.0000e+00 - val_loss: 3.5991\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.2042 - loss: 2.8744 - val_accuracy: 0.4805 - val_loss: 2.8254\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.4021 - loss: 2.1012 - val_accuracy: 0.5234 - val_loss: 0.7230\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.5021 - loss: 0.8861 - val_accuracy: 0.4961 - val_loss: 0.7041\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.3688 - loss: 0.7533 - val_accuracy: 0.5000 - val_loss: 0.6899\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.5500 - loss: 0.7189 - val_accuracy: 0.4922 - val_loss: 0.6937\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.6542 - loss: 0.6928 - val_accuracy: 0.5000 - val_loss: 0.7093\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.5354 - loss: 0.7058 - val_accuracy: 0.5195 - val_loss: 0.7011\n",
      "Epoch 8: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    ds_ood_train,\n",
    "    validation_data=ds_ood_val,\n",
    "    epochs=10,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5dab2a63-aae2-4fb1-b44a-b919d84f79a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.5625 - loss: 0.6792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6783491373062134, 0.5625]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(ds_ood_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d8b26753-201d-4f05-9af4-1629329de358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 346ms/step - accuracy: 0.0000e+00 - loss: 11.6353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.451746940612793, 0.0]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3c02d4-86f7-428e-a345-2726151d08ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1708ea-08d0-4321-8bff-4d4736d8bcfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80ec1b7b-27f8-447e-8f77-956353a3789b",
   "metadata": {},
   "source": [
    "## Alternative of the splitting scheme\n",
    "\n",
    "Here we applied the split step first. It's also possible (and equivalent) to apply the preprocessing step which converts string labels to integer indexes after the split, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e5de1f-23d2-4181-a40d-87ff25dc939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split for few-shot learning with OOD\n",
    "\n",
    "# OOD labels\n",
    "# labels_ood = ['0881fa248109963a']  # CWRU: the 3 channels data contain no normal samples\n",
    "labels_ood = ['55503c950ed81973']  # ['FanEnd', 'Ball', '0.014']\n",
    "# Other labels\n",
    "labels = [l for l in full_label_dict if l not in labels_ood]\n",
    "# labels = list(full_label_dict.keys())\n",
    "\n",
    "# Extract OOD samples and concatenate into a single OOD category\n",
    "foo = utils.extract_by_category(ds0, labels_ood)\n",
    "for k, dv in foo.items():\n",
    "    try:\n",
    "        ds_ood = ds_ood.concatenate(dv)\n",
    "    except:\n",
    "        ds_ood = dv\n",
    "\n",
    "# Few-shot split\n",
    "splits = {'train':0.2, 'val':0.7, 'test':0.1}\n",
    "ds_split = utils.split_dataset(ds0, splits=splits, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb90fc5-f46d-4b30-a186-5f2c3d4739eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = preprocessing.get_mapping_supervised(list(full_label_dict.keys()))\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "ds_train = ds_split['train']\\\n",
    "    .map(preproc, num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "    .shuffle(1000, reshuffle_each_iteration=True)\\\n",
    "    .batch(batch_size, drop_remainder=True)\\\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    "ds_val = ds_split['val']\\\n",
    "    .map(preproc, num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "    .batch(batch_size, drop_remainder=True)\n",
    "ds_test = ds_split['test']\\\n",
    "    .map(preproc, num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "    .batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96afe352-b519-4dbf-8d2c-60f3b8e91eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outdir/'full_labels.json', 'w') as fp:\n",
    "    json.dump(full_label_dict,fp)\n",
    "\n",
    "with open(outdir/'label_mapping.json', 'w') as fp:\n",
    "    json.dump(label_index_dict,fp)\n",
    "\n",
    "# dp_split = {}\n",
    "# for k, dv in ds_split.items():\n",
    "#     dp_split[k] = utils.restore_shape(\n",
    "#         ds_split[k].map(preproc, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "#     )\n",
    "# )\n",
    "# # ds_size = utils.get_dataset_size(ds_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9121933-1804-4802-910e-0bbba2fecd71",
   "metadata": {},
   "source": [
    "# EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f9f6df-7ed9-4fd4-8d61-f88fd22a2985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dpmhm-yVS8YoI0-py3.11)",
   "language": "python",
   "name": "dpmhm-yvs8yoi0-py3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
