{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 12:57:16.990886: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-20 12:57:16.996325: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-20 12:57:17.077884: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-20 12:57:18.444035: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-06-20 12:57:21.543824: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-06-20 12:57:21.543872: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:134] retrieving CUDA diagnostic information for host: is230816\n",
      "2024-06-20 12:57:21.543888: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:141] hostname: is230816\n",
      "2024-06-20 12:57:21.544020: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:165] libcuda reported version is: 535.171.4\n",
      "2024-06-20 12:57:21.544058: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:169] kernel reported version is: 535.171.4\n",
      "2024-06-20 12:57:21.544070: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:248] kernel version seems to match DSO: 535.171.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metadata': {'Dataset': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       "  'FaultComponent': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       "  'FaultLocation': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       "  'FaultSize': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  'FileName': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       "  'LoadForce': TensorSpec(shape=(), dtype=tf.uint32, name=None),\n",
       "  'NominalRPM': TensorSpec(shape=(), dtype=tf.uint32, name=None),\n",
       "  'RPM': TensorSpec(shape=(), dtype=tf.uint32, name=None)},\n",
       " 'sampling_rate': TensorSpec(shape=(), dtype=tf.uint32, name=None),\n",
       " 'signal': {'BA': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'DE': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'FE': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # disable GPU devices\n",
    "os.environ[\"TFDS_DATA_DIR\"] = os.path.expanduser(\"~/tensorflow_datasets\")  # default location of tfds database\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import keras\n",
    "from keras import layers, models\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Turn off logging for TF\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "from dpmhm.datasets import preprocessing, feature, utils, transformer\n",
    "\n",
    "ds_all, ds_info = tfds.load(\n",
    "    'CWRU',\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "ds0 = ds_all['train']\n",
    "ds0.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 12:57:25.215332: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-20 12:57:25.848350: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-20 12:57:26.482213: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-20 12:57:27.513911: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-20 12:57:28.397075: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-20 12:57:33.042408: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-20 12:57:33.052066: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "compactor = transformer.DatasetCompactor(ds0,\n",
    "                                         channels=['DE', 'FE', 'BA'],\n",
    "                                         keys=['FaultLocation', 'FaultComponent', 'FaultSize'],\n",
    "                                         resampling_rate=12000)\n",
    "\n",
    "# Feature extractor\n",
    "# Spectrogram is computed on a time window of 0.025 second every 0.0125 second, then converted to decibel scale.\n",
    "_func = lambda x, sr: feature.spectral_features(x, sr, 'spectrogram',\n",
    "#                                                 n_mfcc=256,\n",
    "                                                time_window=0.025, hop_step=0.0125, n_fft=512,\n",
    "                                                normalize=False, to_db=True)[0]\n",
    "\n",
    "extractor = transformer.FeatureExtractor(compactor.dataset, _func)\n",
    "\n",
    "# A window of width w correspond to w*0.0125 seconds\n",
    "# window = transformer.WindowSlider(extractor.dataset, window_size=(64,64), hop_size=(32,32))\n",
    "window = transformer.WindowSlider(extractor.dataset, window_size=(256, 80), hop_size=40)  # 1s, full bandwidth\n",
    "# window = transformer.WindowSlider(extractor.dataset, window_size=64, hop_size=32)\n",
    "\n",
    "labels = list(compactor.full_label_dict.keys())\n",
    "\n",
    "preproc = preprocessing.get_mapping_supervised(labels)\n",
    "    \n",
    "ds_window = window.dataset.map(preproc, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "eles = list(ds_window.take(10).as_numpy_iterator())\n",
    "input_shape = eles[0][0].shape\n",
    "\n",
    "ds_window = ds_window.map(lambda x,y: (tf.ensure_shape(x, input_shape), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "splits = {'train':0.7, 'val':0.2, 'test':0.1}\n",
    "ds_split = utils.split_dataset(ds_window, splits, ds_size=int(ds_window.cardinality()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 12:57:37.853775: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-20 12:57:37.873176: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "ds_size = sum([1 for _ in ds_window])\n",
    "n_embedding  = 128 \n",
    "kernel_size = (3,3)\n",
    "projection_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 30)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"AST\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"AST\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ class_token (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ClassToken</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Transformer_posembed_input      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AddPositionEmbs</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Transformer_encoderblock_0      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">99,584</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)] │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Transformer_encoderblock_1      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">99,584</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)] │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Transformer_encoderblock_2      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">99,584</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)] │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Transformer_encoder_norm        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ExtractToken (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ head (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,870</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m3\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │        \u001b[38;5;34m98,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ class_token (\u001b[38;5;33mClassToken\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Transformer_posembed_input      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAddPositionEmbs\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Transformer_encoderblock_0      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │        \u001b[38;5;34m99,584\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)] │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Transformer_encoderblock_1      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │        \u001b[38;5;34m99,584\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)] │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Transformer_encoderblock_2      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │        \u001b[38;5;34m99,584\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)] │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Transformer_encoder_norm        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ExtractToken (\u001b[38;5;33mLambda\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ head (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m3,870\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">401,310</span> (1.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m401,310\u001b[0m (1.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">401,310</span> (1.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m401,310\u001b[0m (1.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://github.com/faustomorales/vit-keras/tree/master\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class ClassToken(layers.Layer):\n",
    "    \"\"\"Append a class token to an input layer.\"\"\"\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        cls_init = tf.zeros_initializer()\n",
    "        self.embedding_dim = input_shape[-1]\n",
    "        self.cls = tf.Variable(\n",
    "            name=\"cls\",\n",
    "            initial_value=cls_init(shape=(1, 1, self.embedding_dim), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        cls_broadcasted = tf.cast(\n",
    "            tf.broadcast_to(self.cls, [batch_size, 1, self.embedding_dim]),\n",
    "            dtype=inputs.dtype,\n",
    "        )\n",
    "        return tf.concat([cls_broadcasted, inputs], 1)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class AddPositionEmbs(layers.Layer):\n",
    "    \"\"\"Adds (optionally learned) positional embeddings to the inputs.\"\"\"\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert (\n",
    "            len(input_shape) == 3\n",
    "        ), f\"Number of dimensions should be 3, got {len(input_shape)}\"\n",
    "        self.pe = tf.Variable(\n",
    "            name=\"pos_embedding\",\n",
    "            initial_value=tf.random_normal_initializer(stddev=0.06)(\n",
    "                shape=(1, input_shape[1], input_shape[2])\n",
    "            ),\n",
    "            dtype=\"float32\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + tf.cast(self.pe, dtype=inputs.dtype)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, *args, num_heads, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        embedding_dim = input_shape[-1]\n",
    "        num_heads = self.num_heads\n",
    "        if embedding_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embedding_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.projection_dim = embedding_dim // num_heads\n",
    "        self.query_dense = layers.Dense(embedding_dim, name=\"query\")\n",
    "        self.key_dense = layers.Dense(embedding_dim, name=\"key\")\n",
    "        self.value_dense = layers.Dense(embedding_dim, name=\"value\")\n",
    "        self.combine_heads = layers.Dense(embedding_dim, name=\"out\")\n",
    "\n",
    "    # pylint: disable=no-self-use\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], score.dtype)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "        query = self.separate_heads(query, batch_size)\n",
    "        key = self.separate_heads(key, batch_size)\n",
    "        value = self.separate_heads(value, batch_size)\n",
    "\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embedding_dim))\n",
    "        output = self.combine_heads(concat_attention)\n",
    "        return output, weights\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"num_heads\": self.num_heads})\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class TransformerBlock(layers.Layer):\n",
    "    \"\"\"Implements a Transformer block.\"\"\"\n",
    "\n",
    "    def __init__(self, *args, num_heads, mlp_dim, dropout, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.mlp_dim = mlp_dim\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.att = MultiHeadSelfAttention(\n",
    "            num_heads=self.num_heads,\n",
    "            name=\"MultiHeadDotProductAttention_1\",\n",
    "        )\n",
    "        self.mlpblock = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(\n",
    "                    self.mlp_dim,\n",
    "                    activation=\"linear\",\n",
    "                    name=f\"{self.name}_Dense_0\",\n",
    "                ),\n",
    "                layers.Lambda(\n",
    "                    lambda x: keras.activations.gelu(x, approximate=False)\n",
    "                )\n",
    "                if hasattr(keras.activations, \"gelu\")\n",
    "                else layers.Lambda(\n",
    "                    lambda x: tf.nn.gelu(x, approximate=False)\n",
    "                ),\n",
    "                layers.Dropout(self.dropout),\n",
    "                layers.Dense(input_shape[-1], name=f\"{self.name}_Dense_1\"),\n",
    "                layers.Dropout(self.dropout),\n",
    "            ],\n",
    "            name=\"MlpBlock_3\",\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(\n",
    "            epsilon=1e-6, name=\"LayerNorm_0\"\n",
    "        )\n",
    "        self.layernorm2 = layers.LayerNormalization(\n",
    "            epsilon=1e-6, name=\"LayerNorm_2\"\n",
    "        )\n",
    "        self.dropout_layer = layers.Dropout(self.dropout)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        x = self.layernorm1(inputs)\n",
    "        x, weights = self.att(x)\n",
    "        x = self.dropout_layer(x, training=training)\n",
    "        x = x + inputs\n",
    "        y = self.layernorm2(x)\n",
    "        y = self.mlpblock(y)\n",
    "        return x + y, weights\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"num_heads\": self.num_heads,\n",
    "                \"mlp_dim\": self.mlp_dim,\n",
    "                \"dropout\": self.dropout,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "     \n",
    "def build_model(image_size=(64,64),patch_size=16,num_layers=3,embedding_dim=128, num_heads=4,mlp_dim=128,classes=30,dropout=0.1):\n",
    "\n",
    "    assert (image_size[0] % patch_size == 0) and (image_size[1] % patch_size == 0), \"image_size must be a multiple of patch_size\"\n",
    "\n",
    "    x = layers.Input(shape=(image_size[0], image_size[1], 3))\n",
    "    y = layers.Conv2D(\n",
    "        filters=embedding_dim,\n",
    "        kernel_size=patch_size,\n",
    "        strides=patch_size,\n",
    "        padding=\"valid\",\n",
    "        name=\"embedding\",\n",
    "    )(x)\n",
    "\n",
    "    y = layers.Reshape((y.shape[1] * y.shape[2], embedding_dim))(y)\n",
    "    y = ClassToken(name=\"class_token\")(y)\n",
    "    y = AddPositionEmbs(name=\"Transformer_posembed_input\")(y)\n",
    "    for n in range(num_layers):\n",
    "        y, _ = TransformerBlock(\n",
    "            num_heads=num_heads,\n",
    "            mlp_dim=mlp_dim,\n",
    "            dropout=dropout,\n",
    "            name=f\"Transformer_encoderblock_{n}\",\n",
    "        )(y, training=True)\n",
    "    y = layers.LayerNormalization(\n",
    "        epsilon=1e-6, name=\"Transformer_encoder_norm\"\n",
    "    )(y)\n",
    "    y = layers.Lambda(lambda v: v[:, 0], name=\"ExtractToken\")(y)\n",
    "    y = layers.Dense(classes, name=\"head\")(y)\n",
    "    return models.Model(inputs=x, outputs=y, name='AST')\n",
    "\n",
    "ast_model=build_model(image_size=(input_shape[0], input_shape[1]))\n",
    "test_input = tf.random.normal((32, input_shape[0], input_shape[1], 3))\n",
    "test_output = ast_model(test_input)\n",
    "print(test_output.shape)\n",
    "ast_model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 13:00:53.216311: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.2378 - loss: 2.7887"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 13:01:05.332580: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 326ms/step - accuracy: 0.2426 - loss: 2.7669 - val_accuracy: 0.7135 - val_loss: 0.6317 - learning_rate: 0.0010\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 13:01:06.078394: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/usr/lib/python3.11/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - accuracy: 0.8342 - loss: 0.5603 - val_accuracy: 0.8385 - val_loss: 0.2196 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 175ms/step - accuracy: 0.8125 - loss: 0.4791"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 13:01:14.815266: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - accuracy: 0.9507 - loss: 0.1733 - val_accuracy: 0.9010 - val_loss: 0.0598 - learning_rate: 0.0010\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 13:01:23.404323: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - accuracy: 0.9921 - loss: 0.0463 - val_accuracy: 0.9167 - val_loss: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 13:01:32.050181: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 0.9167 - val_loss: 0.0020 - learning_rate: 0.0010\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 13:01:40.578417: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9167 - val_loss: 0.0014 - learning_rate: 0.0010\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 13:01:49.088041: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 210ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9167 - val_loss: 0.0011 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 182ms/step - accuracy: 1.0000 - loss: 0.0040"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 13:01:57.489828: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9167 - val_loss: 8.5696e-04 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 173ms/step - accuracy: 1.0000 - loss: 0.0028"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 13:02:06.226314: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9167 - val_loss: 6.9512e-04 - learning_rate: 0.0010\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 13:02:14.976700: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9167 - val_loss: 5.9347e-04 - learning_rate: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 13:02:23.766832: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    }
   ],
   "source": [
    "ds_train = ds_split['train'].shuffle(ds_size, reshuffle_each_iteration=True).cache().batch(batch_size,drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "ds_val = ds_split['val'].cache().batch(batch_size,drop_remainder=True)\n",
    "ds_test = ds_split['test'].batch(1)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "ast_model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=3,       \n",
    "    restore_best_weights=True  \n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.1,         \n",
    "    patience=2          \n",
    ")\n",
    "\n",
    "history = ast_model.fit(\n",
    "    ds_train.repeat(),\n",
    "    validation_data=ds_val,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=(int(0.7*ds_size)//batch_size),\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     31/Unknown \u001b[1m5s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.9894e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 13:02:28.225549: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.4343e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 13:02:29.280345: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0006272450555115938, 1.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast_model.evaluate(ds_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
