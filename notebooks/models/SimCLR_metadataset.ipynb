{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of SimCLR with training the encoder and after the classification head\n",
    "\n",
    "**The encoder can be pretrained using an unsupervised way. It is after trained using the SimCLR algorithm and the classification head is trained by supervised learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 14:56:37.215196: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-02 14:56:37.220766: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-02 14:56:37.283591: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-02 14:56:38.345609: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # disable GPU devices\n",
    "os.environ[\"TFDS_DATA_DIR\"] = os.path.expanduser(\"~/tensorflow_datasets\")  # default location of tfds database\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import keras\n",
    "from keras import layers, models, regularizers\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Turn off logging for TF\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "from dpmhm.datasets import preprocessing, feature, utils, transformer, query_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_elem_dirg=10000\n",
    "nb_elem_paderborn= 10000\n",
    "ds_train_size = nb_elem_dirg+nb_elem_paderborn\n",
    "\n",
    "batch_size = 64\n",
    "n_embedding  = 256 \n",
    "kernel_size = (3,3) \n",
    "tau = 0.1\n",
    "projection_dim = 128 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = Path('/volatile/home/bm279471/tmp/meta_dataset')\n",
    "os.makedirs(outdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pipeline(ds_name:str, *, split:str='all', channels:list=[], keys:list=None):\n",
    "#     \"\"\"Pipeline of preprocessing.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     ds_name\n",
    "#         name of the dataset\n",
    "#     split, optional\n",
    "#         split to load, by default 'all'\n",
    "#     channels, optional\n",
    "#         channels to load, by default load all channels simultaneously\n",
    "#     keys, optional\n",
    "#         keys for the ramnification of labels\n",
    "\n",
    "#     \"\"\"\n",
    "#     ds0 = tfds.load(ds_name, split=split)\n",
    "#     if keys is None:\n",
    "#         keys = query_parameters(ds_name)['keys'].keys()\n",
    "\n",
    "#     compactor = transformer.DatasetCompactor(\n",
    "#         ds0,\n",
    "#         channels=channels, # select all channels simultaneously\n",
    "#         keys=keys,\n",
    "#         # resampling_rate=12000,\n",
    "#         # split_channel=True,  # split multidimensional signals into 1d signals, incompatible with the pretrained VGGish model\n",
    "#     )\n",
    "\n",
    "#     _func = lambda x, sr: feature.spectral_features(\n",
    "#         x, sr, 'spectrogram',\n",
    "#         # n_mfcc=256,\n",
    "#         time_window=0.025, hop_step=0.0125,\n",
    "#         # n_fft=512,\n",
    "#         normalize=False, to_db=True)[0]\n",
    "\n",
    "#     extractor = transformer.FeatureExtractor(compactor.dataset, _func)\n",
    "\n",
    "#     window = transformer.WindowSlider(extractor.dataset, window_size=(64,64), hop_size=(32,32))\n",
    "\n",
    "#     labels = list(compactor.full_label_dict.keys())  # need the whole list of labels\n",
    "\n",
    "#     return window.dataset, labels\n",
    "\n",
    "# ds_list = ['CWRU', 'DIRG', 'Paderborn']\n",
    "# ds_all = {}\n",
    "\n",
    "# ds_all['CWRU'] = pipeline('CWRU')\n",
    "# ds_all['DIRG'] = pipeline('DIRG', split='variation', channels=['A1'])\n",
    "# ds_all['Paderborn'] = pipeline('Paderborn', split='healthy[:25%]+artificial[:25%]', channels=['vibration', 'current'])\n",
    "\n",
    "# ds1, ds2, ds3 = ds_all['CWRU'][0], ds_all['DIRG'][0], ds_all['Paderborn'][0]\n",
    "# lb1, lb2, lb3 = ds_all['CWRU'][1], ds_all['DIRG'][1], ds_all['Paderborn'][1]\n",
    "# print(ds1.element_spec)\n",
    "# print(ds2.element_spec)\n",
    "# print(ds3.element_spec)\n",
    "\n",
    "# ds2=ds2.take(nb_elem_dirg)\n",
    "# ds3=ds3.take(nb_elem_paderborn)\n",
    "# ds_train = ds2.concatenate(ds3)\n",
    "\n",
    "# preproc_train = preprocessing.get_mapping_supervised(lb2+lb3)\n",
    "# preproc_test = preprocessing.get_mapping_supervised(lb1)\n",
    "\n",
    "# ds_train = utils.restore_shape(\n",
    "#     ds_train.map(preproc_train, num_parallel_calls=tf.data.AUTOTUNE))\n",
    "# ds_test = utils.restore_shape(\n",
    "#     ds1.map(preproc_test, num_parallel_calls=tf.data.AUTOTUNE))\n",
    "\n",
    "# eles = list(ds_train.take(10).as_numpy_iterator())\n",
    "# input_shape = eles[0][0].shape\n",
    "\n",
    "# ds_train = ds_train.map(lambda x,y: (tf.ensure_shape(x, input_shape), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# ds_test = ds_test.map(lambda x,y: (tf.ensure_shape(x, input_shape), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# ds_train=ds_train.map(lambda x, y: (layers.Rescaling(2/(tf.reduce_max(x)-tf.reduce_min(x)), offset=1-tf.reduce_max(x)*2/(tf.reduce_max(x)-tf.reduce_min(x)))(x), y))\n",
    "# split_train = {'train':0.8, 'val':0.2}\n",
    "# ds_split_train = utils.split_dataset(ds_train, split_train)\n",
    "\n",
    "# ds_test=ds_test.map(lambda x, y: (layers.Rescaling(2/(tf.reduce_max(x)-tf.reduce_min(x)), offset=1-tf.reduce_max(x)*2/(tf.reduce_max(x)-tf.reduce_min(x)))(x), y))\n",
    "# split_test = {'fine-tuning':0.1,'val':0.05, 'test':0.85}\n",
    "# ds_split_test = utils.split_dataset(ds_test, split_test,labels=[i+1 for i in range(len(lb1))])\n",
    "\n",
    "# import json\n",
    "\n",
    "# ds_split_train['train'].save(str(outdir/'ds_train'))\n",
    "# ds_split_train['val'].save(str(outdir/'ds_val'))\n",
    "# ds_split_test['fine-tuning'].save(str(outdir/'ds_train_ft'))\n",
    "# ds_split_test['val'].save(str(outdir/'ds_val_ft'))\n",
    "# ds_split_test['test'].save(str(outdir/'ds_test_ft'))\n",
    "\n",
    "# with open(outdir/'lb1.json', 'w') as fp:\n",
    "#     json.dump(lb1,fp)\n",
    "# with open(outdir/'lb2.json', 'w') as fp:\n",
    "#     json.dump(lb2,fp)\n",
    "# with open(outdir/'lb3.json', 'w') as fp:\n",
    "#     json.dump(lb3,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 14:56:40.830021: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-07-02 14:56:40.830061: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:134] retrieving CUDA diagnostic information for host: is230816\n",
      "2024-07-02 14:56:40.830078: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:141] hostname: is230816\n",
      "2024-07-02 14:56:40.830196: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:165] libcuda reported version is: 535.183.1\n",
      "2024-07-02 14:56:40.830237: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:169] kernel reported version is: 535.183.1\n",
      "2024-07-02 14:56:40.830262: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:248] kernel version seems to match DSO: 535.183.1\n",
      "2024-07-02 14:56:41.399224: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-02 14:56:41.749895: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-02 14:56:45.291857: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "ds_train = tf.data.Dataset.load(str(outdir/'ds_train'))\n",
    "ds_val = tf.data.Dataset.load(str(outdir/'ds_val'))\n",
    "ds_train_ft = tf.data.Dataset.load(str(outdir/'ds_train_ft'))\n",
    "ds_val_ft = tf.data.Dataset.load(str(outdir/'ds_val_ft'))\n",
    "ds_test_ft = tf.data.Dataset.load(str(outdir/'ds_test_ft'))\n",
    "\n",
    "with open(outdir/'lb1.json', 'r') as fp:\n",
    "    lb1 = list(json.load(fp))\n",
    "with open(outdir/'lb2.json', 'r') as fp:\n",
    "    lb2 = list(json.load(fp))\n",
    "with open(outdir/'lb3.json', 'r') as fp:\n",
    "    lb3 = list(json.load(fp))\n",
    "\n",
    "ds_train_clr = ds_train.map(lambda x,l:(x,x)).shuffle(ds_train_size, reshuffle_each_iteration=False).cache().batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "ds_val_clr = ds_val.cache().batch(batch_size,drop_remainder=True)\n",
    "\n",
    "ds_train_class = ds_train.shuffle(ds_train_size, reshuffle_each_iteration=False).cache().batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "ds_val_class = ds_val.cache().batch(batch_size,drop_remainder=True)\n",
    "\n",
    "ds_test_size = utils.get_dataset_size(ds_train_ft)+utils.get_dataset_size(ds_val_ft)+utils.get_dataset_size(ds_test_ft)\n",
    "\n",
    "ds_train_ft= ds_train_ft.shuffle(ds_test_size, reshuffle_each_iteration=False).cache().batch(batch_size,drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "ds_val_ft = ds_val_ft.cache().batch(batch_size,drop_remainder=True)\n",
    "ds_test_ft=ds_test_ft.cache().batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 14:56:45.513861: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-02 14:56:45.611687: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-02 14:56:49.652874: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 14:56:51.133135: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-07-02 14:56:51.138416: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "ds_test_size = utils.get_dataset_size(ds_train_ft)+utils.get_dataset_size(ds_val_ft)+utils.get_dataset_size(ds_test_ft)\n",
    "eles = list(ds_train_clr.take(1).as_numpy_iterator())\n",
    "input_shape = eles[0][0][0].shape\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With an encoder from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Autoencoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class Encoder(models.Model):\n",
    "    \"\"\"Convolution Auto-Encoder stacks.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Shape (H,W) of the input tensor must be power of 2.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape, n_embedding, kernel_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        activation = 'relu'\n",
    "        padding = 'same'\n",
    "        strides = (2, 2)\n",
    "        pool_size = (2, 2)\n",
    "        a_reg = 0.\n",
    "\n",
    "        # Encoder\n",
    "        input_enc = layers.Input(shape=input_shape, name='input_enc')\n",
    "        x = layers.Conv2D(32, kernel_size=kernel_size, activation=activation, padding=padding, name='conv1_enc')(input_enc)\n",
    "        x = layers.MaxPooling2D(pool_size=pool_size, strides=strides, name='pool1_enc')(x)\n",
    "        x = layers.BatchNormalization(name='bn1_enc')(x)\n",
    "\n",
    "        x = layers.Conv2D(64, kernel_size=kernel_size, activation=activation, padding=padding, name='conv2_enc')(x)\n",
    "        x = layers.MaxPooling2D(pool_size=pool_size, strides=strides, name='pool2_enc')(x)\n",
    "        x = layers.BatchNormalization(name='bn2_enc')(x)\n",
    "\n",
    "        x = layers.Conv2D(128, kernel_size=kernel_size, activation=activation, padding=padding, name='conv3_enc')(x)\n",
    "        x = layers.MaxPooling2D(pool_size=pool_size, strides=strides, name='pool3_enc')(x)\n",
    "        x = layers.BatchNormalization(name='bn3_enc')(x)\n",
    "\n",
    "        x = layers.Flatten(name='flatten')(x)\n",
    "        if a_reg > 0:\n",
    "            x = layers.Dense(n_embedding, activation=activation, activity_regularizer=regularizers.L1(a_reg), name='fc1_enc')(x)\n",
    "        else:\n",
    "            x = layers.Dense(n_embedding, activation=activation, name='fc1_enc')(x)\n",
    "\n",
    "        self.encoder = models.Model(input_enc, x, name='encoder')\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        return self.encoder(x, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_shape,n_embedding,kernel_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contrastive learning on the encoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrastive loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss_fn(z_i, z_j, tau=0.5):\n",
    "    z_i = tf.math.l2_normalize(z_i, axis=1)\n",
    "    z_j = tf.math.l2_normalize(z_j, axis=1)\n",
    "\n",
    "    # Compute the similarity matrix\n",
    "    similarity_matrix = tf.matmul(z_i, z_j, transpose_b=True) / tau\n",
    "\n",
    "    # Compute the positive similarity\n",
    "    positive_similarity = tf.linalg.diag_part(similarity_matrix)\n",
    "\n",
    "    # Compute the negative similarity\n",
    "    negative_similarity = tf.linalg.set_diag(similarity_matrix, tf.zeros_like(tf.linalg.diag_part(similarity_matrix)))\n",
    "\n",
    "    # Compute the numerator of the loss function\n",
    "    numerator = tf.exp(positive_similarity)\n",
    "\n",
    "    # Compute the denominator of the loss function\n",
    "    denominator = tf.reduce_sum(tf.exp(negative_similarity), axis=1)\n",
    "\n",
    "    # Compute the loss function\n",
    "    loss = -tf.reduce_mean(tf.math.log(numerator / denominator))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the SimCLR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "\n",
    "# Define the contrastive model with model-subclassing\n",
    "class SimCLRModel(keras.Model):\n",
    "    def __init__(self, encoder):\n",
    "        super().__init__()\n",
    "\n",
    "        self.tau = tau\n",
    "\n",
    "        self.contrastive_augmenter = keras.Sequential([\n",
    "            layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "            layers.RandomZoom(0.2),\n",
    "            layers.RandomTranslation(height_factor=0.2, width_factor=0.2),\n",
    "        ], name='Data_augmentation')\n",
    "        \n",
    "        self.encoder = encoder\n",
    "\n",
    "        self.projection_head = keras.Sequential([\n",
    "                layers.Dense(256, activation='relu'),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Dense(128, activation='relu'),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Dense(projection_dim),\n",
    "            ], name='Projection_head')\n",
    "        \n",
    "        self.classification_head = keras.Sequential([\n",
    "                layers.Input(shape=(128,)),\n",
    "                layers.Dense(128, activation='relu'),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Dense(len(lb2+lb3)) #nb labels\n",
    "            ], name='Classification_head')\n",
    "\n",
    "    def compile(self, contrastive_optimizer, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "\n",
    "        self.contrastive_optimizer = contrastive_optimizer\n",
    "\n",
    "        self.contrastive_loss_tracker = keras.metrics.Mean(name=\"c_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.contrastive_loss_tracker\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        train_image, _ = data\n",
    "        \n",
    "        # Each set of unlabeled images is augmented separately\n",
    "        augmented_image_1 = self.contrastive_augmenter(train_image, training=True)\n",
    "        augmented_image_2 = self.contrastive_augmenter(train_image, training=True)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Extract features and compute projections for the first set of images\n",
    "            features_1 = self.encoder(augmented_image_1, training=True)\n",
    "            projections_1 = self.projection_head(features_1, training=True)\n",
    "            \n",
    "            # Extract features and compute projections for the second set of images\n",
    "            features_2 = self.encoder(augmented_image_2, training=True)\n",
    "            projections_2 = self.projection_head(features_2, training=True)\n",
    "            \n",
    "            # Compute contrastive loss\n",
    "            contrastive_loss = contrastive_loss_fn(projections_1, projections_2, self.tau) +contrastive_loss_fn(projections_2, projections_1, self.tau)\n",
    "        \n",
    "        # Compute gradients and apply updates for the contrastive loss\n",
    "        gradients = tape.gradient(\n",
    "            contrastive_loss,\n",
    "            self.encoder.trainable_weights + self.projection_head.trainable_weights,\n",
    "        )\n",
    "        self.contrastive_optimizer.apply_gradients(\n",
    "            zip(\n",
    "                gradients,\n",
    "                self.encoder.trainable_weights + self.projection_head.trainable_weights,\n",
    "            )\n",
    "        )\n",
    "        self.contrastive_loss_tracker.update_state(contrastive_loss)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        test_image, _ = data\n",
    "\n",
    "        # Compute contrastive loss on the validation set\n",
    "        augmented_image_1 = self.contrastive_augmenter(test_image, training=True)\n",
    "        augmented_image_2 = self.contrastive_augmenter(test_image, training=True)\n",
    "\n",
    "        features_1 = self.encoder(augmented_image_1, training=False)\n",
    "        features_2 = self.encoder(augmented_image_2, training=False)\n",
    "\n",
    "        projections_1 = self.projection_head(features_1, training=False)\n",
    "        projections_2 = self.projection_head(features_2, training=False)\n",
    "        \n",
    "        contrastive_loss = contrastive_loss_fn(projections_1, projections_2, self.tau) + contrastive_loss_fn(projections_2, projections_1, self.tau)\n",
    "        self.contrastive_loss_tracker.update_state(contrastive_loss)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and train SimCLR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "simclr_model = SimCLRModel(encoder)\n",
    "\n",
    "simclr_model.compile(\n",
    "    contrastive_optimizer=keras.optimizers.Adam(1e-4),\n",
    ")\n",
    "\n",
    "# early_stopping = EarlyStopping(\n",
    "#     monitor='val_c_loss',  \n",
    "#     patience=4,       \n",
    "#     restore_best_weights=True, \n",
    "#     mode='min'\n",
    "# )\n",
    "\n",
    "# reduce_lr = ReduceLROnPlateau(\n",
    "#     monitor='val_c_loss', \n",
    "#     factor=0.1,         \n",
    "#     patience=2, \n",
    "#     mode='min'    \n",
    "# )\n",
    "\n",
    "# simclr_history = simclr_model.fit(\n",
    "#     ds_train_clr.repeat(), \n",
    "#     epochs=30, \n",
    "#     validation_data=ds_val_clr, \n",
    "#     steps_per_epoch=int((0.8*ds_train_size) // batch_size),\n",
    "#     callbacks=[early_stopping, reduce_lr]\n",
    "# )\n",
    "\n",
    "# simclr_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('c_loss')\n",
    "# plt.plot(simclr_history.history['c_loss'], label='c_loss')\n",
    "# plt.plot(simclr_history.history['val_c_loss'], linestyle='dashed', label='val_c_loss')\n",
    "\n",
    "\n",
    "# plt.legend(loc='lower left')\n",
    "# plt.title('Evolution of contrastive loss')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/volatile/home/bm279471/Documents/.venv/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 50 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# simclr_model.save_weights('simclr.weights.h5')\n",
    "simclr_model.load_weights('simclr.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of a classification head on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 346ms/step - accuracy: 0.0977 - loss: 3.4389 - val_accuracy: 0.0547 - val_loss: 3.3217 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - accuracy: 0.2032 - loss: 2.8277 - val_accuracy: 0.0495 - val_loss: 3.2479 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - accuracy: 0.2656 - loss: 2.5448 - val_accuracy: 0.0495 - val_loss: 3.1699 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.3376 - loss: 2.3014 - val_accuracy: 0.0469 - val_loss: 3.1070 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - accuracy: 0.3935 - loss: 2.1303 - val_accuracy: 0.0482 - val_loss: 3.0372 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 381ms/step - accuracy: 0.4516 - loss: 1.9563 - val_accuracy: 0.0586 - val_loss: 2.9469 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 325ms/step - accuracy: 0.4827 - loss: 1.8635 - val_accuracy: 0.1081 - val_loss: 2.8481 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 344ms/step - accuracy: 0.5506 - loss: 1.6760 - val_accuracy: 0.2721 - val_loss: 2.7427 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 352ms/step - accuracy: 0.6057 - loss: 1.5674 - val_accuracy: 0.3932 - val_loss: 2.6360 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 354ms/step - accuracy: 0.6524 - loss: 1.4273 - val_accuracy: 0.4427 - val_loss: 2.5463 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 391ms/step - accuracy: 0.6990 - loss: 1.3147 - val_accuracy: 0.4427 - val_loss: 2.4633 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 350ms/step - accuracy: 0.7190 - loss: 1.2125 - val_accuracy: 0.4049 - val_loss: 2.3733 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 358ms/step - accuracy: 0.7492 - loss: 1.1280 - val_accuracy: 0.4714 - val_loss: 2.2736 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 379ms/step - accuracy: 0.7800 - loss: 1.0618 - val_accuracy: 0.4635 - val_loss: 2.2132 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 369ms/step - accuracy: 0.7720 - loss: 1.0080 - val_accuracy: 0.5182 - val_loss: 2.0832 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 379ms/step - accuracy: 0.8137 - loss: 0.9142 - val_accuracy: 0.5625 - val_loss: 1.9763 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 381ms/step - accuracy: 0.8396 - loss: 0.8354 - val_accuracy: 0.5495 - val_loss: 1.8535 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 664ms/step - accuracy: 0.8589 - loss: 0.7631 - val_accuracy: 0.5495 - val_loss: 1.7750 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 581ms/step - accuracy: 0.8506 - loss: 0.7334 - val_accuracy: 0.6068 - val_loss: 1.6918 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 623ms/step - accuracy: 0.8704 - loss: 0.7047 - val_accuracy: 0.6354 - val_loss: 1.5225 - learning_rate: 0.0010\n",
      "Epoch 21/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 0.8722 - loss: 0.6671 - val_accuracy: 0.6810 - val_loss: 1.4207 - learning_rate: 0.0010\n",
      "Epoch 22/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 345ms/step - accuracy: 0.8882 - loss: 0.6098 - val_accuracy: 0.6615 - val_loss: 1.3173 - learning_rate: 0.0010\n",
      "Epoch 23/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 350ms/step - accuracy: 0.8938 - loss: 0.5696 - val_accuracy: 0.7318 - val_loss: 1.1946 - learning_rate: 0.0010\n",
      "Epoch 24/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.9016 - loss: 0.5251 - val_accuracy: 0.6758 - val_loss: 1.2343 - learning_rate: 0.0010\n",
      "Epoch 25/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 350ms/step - accuracy: 0.9036 - loss: 0.5015 - val_accuracy: 0.6797 - val_loss: 1.1342 - learning_rate: 0.0010\n",
      "Epoch 26/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 346ms/step - accuracy: 0.8994 - loss: 0.5033 - val_accuracy: 0.6758 - val_loss: 1.0876 - learning_rate: 0.0010\n",
      "Epoch 27/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 372ms/step - accuracy: 0.9223 - loss: 0.4475 - val_accuracy: 0.7083 - val_loss: 1.0159 - learning_rate: 0.0010\n",
      "Epoch 28/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 354ms/step - accuracy: 0.9322 - loss: 0.4156 - val_accuracy: 0.8021 - val_loss: 0.8280 - learning_rate: 0.0010\n",
      "Epoch 29/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 377ms/step - accuracy: 0.9316 - loss: 0.3839 - val_accuracy: 0.7539 - val_loss: 0.8951 - learning_rate: 0.0010\n",
      "Epoch 30/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - accuracy: 0.9322 - loss: 0.3792 - val_accuracy: 0.7773 - val_loss: 0.8350 - learning_rate: 0.0010\n",
      "Epoch 31/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 348ms/step - accuracy: 0.9337 - loss: 0.3502 - val_accuracy: 0.8568 - val_loss: 0.6739 - learning_rate: 1.0000e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 346ms/step - accuracy: 0.9584 - loss: 0.3078 - val_accuracy: 0.8802 - val_loss: 0.6203 - learning_rate: 1.0000e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 345ms/step - accuracy: 0.9629 - loss: 0.3091 - val_accuracy: 0.8828 - val_loss: 0.5863 - learning_rate: 1.0000e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 349ms/step - accuracy: 0.9646 - loss: 0.2903 - val_accuracy: 0.8880 - val_loss: 0.5603 - learning_rate: 1.0000e-04\n",
      "Epoch 35/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - accuracy: 0.9707 - loss: 0.2720 - val_accuracy: 0.8945 - val_loss: 0.5382 - learning_rate: 1.0000e-04\n",
      "Epoch 36/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 380ms/step - accuracy: 0.9742 - loss: 0.2757 - val_accuracy: 0.8971 - val_loss: 0.5182 - learning_rate: 1.0000e-04\n",
      "Epoch 37/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 382ms/step - accuracy: 0.9691 - loss: 0.2757 - val_accuracy: 0.8997 - val_loss: 0.5006 - learning_rate: 1.0000e-04\n",
      "Epoch 38/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 384ms/step - accuracy: 0.9670 - loss: 0.2757 - val_accuracy: 0.9036 - val_loss: 0.4866 - learning_rate: 1.0000e-04\n",
      "Epoch 39/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 362ms/step - accuracy: 0.9665 - loss: 0.2830 - val_accuracy: 0.9023 - val_loss: 0.4796 - learning_rate: 1.0000e-04\n",
      "Epoch 40/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 348ms/step - accuracy: 0.9643 - loss: 0.2808 - val_accuracy: 0.9023 - val_loss: 0.4691 - learning_rate: 1.0000e-04\n",
      "Epoch 41/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 347ms/step - accuracy: 0.9702 - loss: 0.2617 - val_accuracy: 0.9036 - val_loss: 0.4634 - learning_rate: 1.0000e-04\n",
      "Epoch 42/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 355ms/step - accuracy: 0.9740 - loss: 0.2600 - val_accuracy: 0.9076 - val_loss: 0.4588 - learning_rate: 1.0000e-04\n",
      "Epoch 43/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 347ms/step - accuracy: 0.9700 - loss: 0.2639 - val_accuracy: 0.9076 - val_loss: 0.4524 - learning_rate: 1.0000e-04\n",
      "Epoch 44/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 344ms/step - accuracy: 0.9643 - loss: 0.2650 - val_accuracy: 0.9049 - val_loss: 0.4482 - learning_rate: 1.0000e-04\n",
      "Epoch 45/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 346ms/step - accuracy: 0.9685 - loss: 0.2715 - val_accuracy: 0.9049 - val_loss: 0.4442 - learning_rate: 1.0000e-04\n",
      "Epoch 46/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 344ms/step - accuracy: 0.9655 - loss: 0.2702 - val_accuracy: 0.9036 - val_loss: 0.4410 - learning_rate: 1.0000e-04\n",
      "Epoch 47/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.9685 - loss: 0.2595 - val_accuracy: 0.9023 - val_loss: 0.4376 - learning_rate: 1.0000e-04\n",
      "Epoch 48/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 341ms/step - accuracy: 0.9754 - loss: 0.2524 - val_accuracy: 0.9076 - val_loss: 0.4350 - learning_rate: 1.0000e-04\n",
      "Epoch 49/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.9726 - loss: 0.2504 - val_accuracy: 0.9062 - val_loss: 0.4319 - learning_rate: 1.0000e-04\n",
      "Epoch 50/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 344ms/step - accuracy: 0.9683 - loss: 0.2516 - val_accuracy: 0.9062 - val_loss: 0.4291 - learning_rate: 1.0000e-04\n",
      "Epoch 51/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 347ms/step - accuracy: 0.9620 - loss: 0.2755 - val_accuracy: 0.9089 - val_loss: 0.4270 - learning_rate: 1.0000e-04\n",
      "Epoch 52/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 348ms/step - accuracy: 0.9675 - loss: 0.2542 - val_accuracy: 0.9062 - val_loss: 0.4256 - learning_rate: 1.0000e-04\n",
      "Epoch 53/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9728 - loss: 0.2443 - val_accuracy: 0.9049 - val_loss: 0.4229 - learning_rate: 1.0000e-04\n",
      "Epoch 54/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 345ms/step - accuracy: 0.9806 - loss: 0.2297 - val_accuracy: 0.9089 - val_loss: 0.4214 - learning_rate: 1.0000e-04\n",
      "Epoch 55/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 414ms/step - accuracy: 0.9743 - loss: 0.2393 - val_accuracy: 0.9115 - val_loss: 0.4191 - learning_rate: 1.0000e-04\n",
      "Epoch 56/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 354ms/step - accuracy: 0.9648 - loss: 0.2427 - val_accuracy: 0.9102 - val_loss: 0.4159 - learning_rate: 1.0000e-04\n",
      "Epoch 57/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 374ms/step - accuracy: 0.9710 - loss: 0.2408 - val_accuracy: 0.9062 - val_loss: 0.4149 - learning_rate: 1.0000e-04\n",
      "Epoch 58/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 381ms/step - accuracy: 0.9718 - loss: 0.2499 - val_accuracy: 0.9089 - val_loss: 0.4143 - learning_rate: 1.0000e-04\n",
      "Epoch 59/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 397ms/step - accuracy: 0.9762 - loss: 0.2344 - val_accuracy: 0.9154 - val_loss: 0.4137 - learning_rate: 1.0000e-04\n",
      "Epoch 60/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 387ms/step - accuracy: 0.9794 - loss: 0.2205 - val_accuracy: 0.9141 - val_loss: 0.4113 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                </span>┃<span style=\"font-weight: bold\"> Output Shape          </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Trai… </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━┩\n",
       "│ input_enc (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,191,552</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│    └ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)   │ ?                     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,191,552</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ input_enc           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ conv1_enc (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ pool1_enc           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)              │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ bn1_enc             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ conv2_enc (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ pool2_enc           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)              │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ bn2_enc             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ conv3_enc (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ pool3_enc           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)              │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ bn3_enc             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ fc1_enc (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,408</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ Classification_head         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,149</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│    └ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│    └ batch_normalization_3  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│    └ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,741</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n",
       "└─────────────────────────────┴───────────────────────┴────────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mTrai…\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━┩\n",
       "│ input_enc (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ encoder (\u001b[38;5;33mEncoder\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │  \u001b[38;5;34m2,191,552\u001b[0m │   \u001b[1;91mN\u001b[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│    └ encoder (\u001b[38;5;33mFunctional\u001b[0m)   │ ?                     │  \u001b[38;5;34m2,191,552\u001b[0m │   \u001b[1;91mN\u001b[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ input_enc           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ conv1_enc (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │        \u001b[38;5;34m896\u001b[0m │   \u001b[1;91mN\u001b[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ pool1_enc           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)              │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ bn1_enc             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │        \u001b[38;5;34m128\u001b[0m │   \u001b[1;91mN\u001b[0m   │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)        │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ conv2_enc (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m18,496\u001b[0m │   \u001b[1;91mN\u001b[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ pool2_enc           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)              │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ bn2_enc             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │   \u001b[1;91mN\u001b[0m   │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)        │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ conv3_enc (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m73,856\u001b[0m │   \u001b[1;91mN\u001b[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ pool3_enc           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)              │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ bn3_enc             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │        \u001b[38;5;34m512\u001b[0m │   \u001b[1;91mN\u001b[0m   │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)        │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)          │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│       └ fc1_enc (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │  \u001b[38;5;34m2,097,408\u001b[0m │   \u001b[1;91mN\u001b[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ Classification_head         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)            │     \u001b[38;5;34m37,149\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│    └ dense_5 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │     \u001b[38;5;34m32,896\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│    └ batch_normalization_3  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │        \u001b[38;5;34m512\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)        │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│    └ dense_6 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)            │      \u001b[38;5;34m3,741\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n",
       "└─────────────────────────────┴───────────────────────┴────────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,302,489</span> (8.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,302,489\u001b[0m (8.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,893</span> (144.11 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m36,893\u001b[0m (144.11 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,191,808</span> (8.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,191,808\u001b[0m (8.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">73,788</span> (288.24 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m73,788\u001b[0m (288.24 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Freeze the encoder weights\n",
    "simclr_model.encoder.trainable = False\n",
    "\n",
    "classification_head_ft= keras.Sequential([\n",
    "    layers.Input(shape=(n_embedding,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(len(lb1)) #nb labels\n",
    "], name='Classification_head')\n",
    "\n",
    "# Create a new classification model\n",
    "encoder_output = simclr_model.encoder(simclr_model.encoder.layers[0].input, training=False)\n",
    "classification_model_cwru_pretrained = keras.Model(\n",
    "    inputs=simclr_model.encoder.layers[0].input,\n",
    "    outputs=classification_head_ft(encoder_output)\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=3,       \n",
    "    restore_best_weights=True  \n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.1,         \n",
    "    patience=2          \n",
    ")\n",
    "\n",
    "classification_model_cwru_pretrained.compile(\n",
    "    optimizer=keras.optimizers.Adam(), \n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "classification_history = classification_model_cwru_pretrained.fit(\n",
    "    ds_train_ft.repeat(), \n",
    "    epochs=60, \n",
    "    validation_data=ds_val_ft, \n",
    "    steps_per_epoch=int((0.1*ds_test_size) // batch_size),\n",
    "    callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "classification_model_cwru_pretrained.summary(show_trainable=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(classification_history.history['loss'], label='loss')\n",
    "plt.plot(classification_history.history['val_loss'], linestyle='dashed', label='val_loss')\n",
    "\n",
    "\n",
    "plt.legend(loc='lower left')\n",
    "plt.title('Evolution of loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the effectiveness of the pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13873/13873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 25ms/step - accuracy: 0.9120 - loss: 0.4133\n",
      "Evaluation accuracy with pretraining on encoder: 90.67%\n"
     ]
    }
   ],
   "source": [
    "evaluation1 = classification_model_cwru_pretrained.evaluate(ds_test_ft)\n",
    "\n",
    "print(\"Evaluation accuracy with pretraining on encoder: {:.2f}%\".format(evaluation1[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 511ms/step - accuracy: 0.9651 - loss: 0.2536 - val_accuracy: 0.9193 - val_loss: 0.3860 - learning_rate: 1.0000e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 497ms/step - accuracy: 0.9827 - loss: 0.2138 - val_accuracy: 0.9245 - val_loss: 0.3657 - learning_rate: 1.0000e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 450ms/step - accuracy: 0.9821 - loss: 0.1938 - val_accuracy: 0.9297 - val_loss: 0.3489 - learning_rate: 1.0000e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 528ms/step - accuracy: 0.9875 - loss: 0.1714 - val_accuracy: 0.9297 - val_loss: 0.3340 - learning_rate: 1.0000e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 438ms/step - accuracy: 0.9881 - loss: 0.1685 - val_accuracy: 0.9258 - val_loss: 0.3212 - learning_rate: 1.0000e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 477ms/step - accuracy: 0.9917 - loss: 0.1624 - val_accuracy: 0.9323 - val_loss: 0.3100 - learning_rate: 1.0000e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 473ms/step - accuracy: 0.9947 - loss: 0.1505 - val_accuracy: 0.9349 - val_loss: 0.3013 - learning_rate: 1.0000e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 501ms/step - accuracy: 0.9905 - loss: 0.1515 - val_accuracy: 0.9375 - val_loss: 0.2928 - learning_rate: 1.0000e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 447ms/step - accuracy: 0.9951 - loss: 0.1373 - val_accuracy: 0.9388 - val_loss: 0.2841 - learning_rate: 1.0000e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 520ms/step - accuracy: 0.9950 - loss: 0.1254 - val_accuracy: 0.9414 - val_loss: 0.2752 - learning_rate: 1.0000e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 410ms/step - accuracy: 0.9982 - loss: 0.1213 - val_accuracy: 0.9414 - val_loss: 0.2681 - learning_rate: 1.0000e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 448ms/step - accuracy: 0.9973 - loss: 0.1144 - val_accuracy: 0.9401 - val_loss: 0.2614 - learning_rate: 1.0000e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 462ms/step - accuracy: 0.9955 - loss: 0.1123 - val_accuracy: 0.9414 - val_loss: 0.2568 - learning_rate: 1.0000e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 432ms/step - accuracy: 0.9928 - loss: 0.1116 - val_accuracy: 0.9427 - val_loss: 0.2511 - learning_rate: 1.0000e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 434ms/step - accuracy: 0.9965 - loss: 0.1081 - val_accuracy: 0.9466 - val_loss: 0.2448 - learning_rate: 1.0000e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 451ms/step - accuracy: 0.9964 - loss: 0.0981 - val_accuracy: 0.9492 - val_loss: 0.2393 - learning_rate: 1.0000e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 437ms/step - accuracy: 0.9981 - loss: 0.0926 - val_accuracy: 0.9518 - val_loss: 0.2339 - learning_rate: 1.0000e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 531ms/step - accuracy: 0.9964 - loss: 0.0894 - val_accuracy: 0.9518 - val_loss: 0.2301 - learning_rate: 1.0000e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 489ms/step - accuracy: 0.9970 - loss: 0.0863 - val_accuracy: 0.9505 - val_loss: 0.2259 - learning_rate: 1.0000e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 507ms/step - accuracy: 0.9925 - loss: 0.0913 - val_accuracy: 0.9518 - val_loss: 0.2225 - learning_rate: 1.0000e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 427ms/step - accuracy: 0.9970 - loss: 0.0863 - val_accuracy: 0.9557 - val_loss: 0.2172 - learning_rate: 1.0000e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 434ms/step - accuracy: 0.9966 - loss: 0.0827 - val_accuracy: 0.9557 - val_loss: 0.2135 - learning_rate: 1.0000e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 415ms/step - accuracy: 0.9982 - loss: 0.0755 - val_accuracy: 0.9570 - val_loss: 0.2098 - learning_rate: 1.0000e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 498ms/step - accuracy: 0.9990 - loss: 0.0707 - val_accuracy: 0.9570 - val_loss: 0.2067 - learning_rate: 1.0000e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 562ms/step - accuracy: 0.9996 - loss: 0.0700 - val_accuracy: 0.9570 - val_loss: 0.2041 - learning_rate: 1.0000e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 434ms/step - accuracy: 0.9946 - loss: 0.0804 - val_accuracy: 0.9570 - val_loss: 0.2005 - learning_rate: 1.0000e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 426ms/step - accuracy: 0.9977 - loss: 0.0703 - val_accuracy: 0.9570 - val_loss: 0.1980 - learning_rate: 1.0000e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 431ms/step - accuracy: 0.9960 - loss: 0.0673 - val_accuracy: 0.9596 - val_loss: 0.1942 - learning_rate: 1.0000e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 424ms/step - accuracy: 0.9984 - loss: 0.0605 - val_accuracy: 0.9596 - val_loss: 0.1913 - learning_rate: 1.0000e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 409ms/step - accuracy: 0.9991 - loss: 0.0594 - val_accuracy: 0.9583 - val_loss: 0.1888 - learning_rate: 1.0000e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 410ms/step - accuracy: 0.9999 - loss: 0.0605 - val_accuracy: 0.9596 - val_loss: 0.1868 - learning_rate: 1.0000e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 429ms/step - accuracy: 1.0000 - loss: 0.0583 - val_accuracy: 0.9596 - val_loss: 0.1845 - learning_rate: 1.0000e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 429ms/step - accuracy: 0.9987 - loss: 0.0601 - val_accuracy: 0.9596 - val_loss: 0.1820 - learning_rate: 1.0000e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 480ms/step - accuracy: 0.9992 - loss: 0.0560 - val_accuracy: 0.9609 - val_loss: 0.1793 - learning_rate: 1.0000e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 482ms/step - accuracy: 0.9995 - loss: 0.0519 - val_accuracy: 0.9635 - val_loss: 0.1770 - learning_rate: 1.0000e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 549ms/step - accuracy: 0.9997 - loss: 0.0507 - val_accuracy: 0.9622 - val_loss: 0.1749 - learning_rate: 1.0000e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 540ms/step - accuracy: 0.9999 - loss: 0.0485 - val_accuracy: 0.9648 - val_loss: 0.1737 - learning_rate: 1.0000e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 515ms/step - accuracy: 1.0000 - loss: 0.0495 - val_accuracy: 0.9648 - val_loss: 0.1715 - learning_rate: 1.0000e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 596ms/step - accuracy: 0.9984 - loss: 0.0491 - val_accuracy: 0.9648 - val_loss: 0.1694 - learning_rate: 1.0000e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 562ms/step - accuracy: 0.9991 - loss: 0.0483 - val_accuracy: 0.9648 - val_loss: 0.1669 - learning_rate: 1.0000e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 559ms/step - accuracy: 0.9995 - loss: 0.0446 - val_accuracy: 0.9661 - val_loss: 0.1651 - learning_rate: 1.0000e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 530ms/step - accuracy: 0.9997 - loss: 0.0428 - val_accuracy: 0.9661 - val_loss: 0.1639 - learning_rate: 1.0000e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 582ms/step - accuracy: 0.9999 - loss: 0.0414 - val_accuracy: 0.9661 - val_loss: 0.1622 - learning_rate: 1.0000e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 514ms/step - accuracy: 1.0000 - loss: 0.0406 - val_accuracy: 0.9661 - val_loss: 0.1611 - learning_rate: 1.0000e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 544ms/step - accuracy: 1.0000 - loss: 0.0433 - val_accuracy: 0.9661 - val_loss: 0.1589 - learning_rate: 1.0000e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 535ms/step - accuracy: 1.0000 - loss: 0.0415 - val_accuracy: 0.9661 - val_loss: 0.1570 - learning_rate: 1.0000e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 598ms/step - accuracy: 1.0000 - loss: 0.0402 - val_accuracy: 0.9661 - val_loss: 0.1555 - learning_rate: 1.0000e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 551ms/step - accuracy: 1.0000 - loss: 0.0372 - val_accuracy: 0.9661 - val_loss: 0.1543 - learning_rate: 1.0000e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 516ms/step - accuracy: 1.0000 - loss: 0.0353 - val_accuracy: 0.9661 - val_loss: 0.1529 - learning_rate: 1.0000e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 522ms/step - accuracy: 1.0000 - loss: 0.0356 - val_accuracy: 0.9661 - val_loss: 0.1518 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# Unfreeze the encoder weights\n",
    "simclr_model.encoder.trainable = True\n",
    "\n",
    "classification_model_cwru_pretrained.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-5), \n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=3,       \n",
    "    restore_best_weights=True  \n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.1,         \n",
    "    patience=2          \n",
    ")\n",
    "\n",
    "classification_history1 = classification_model_cwru_pretrained.fit(\n",
    "    ds_train_ft.repeat(), \n",
    "    epochs=50, \n",
    "    validation_data=ds_val_ft, \n",
    "    steps_per_epoch=int((0.1*ds_test_size) // batch_size),\n",
    "    callbacks=[early_stopping, reduce_lr])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m    1/13873\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:19\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0198"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13873/13873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 27ms/step - accuracy: 0.9692 - loss: 0.1469\n",
      "Evaluation accuracy with pretraining on encoder: 96.53%\n"
     ]
    }
   ],
   "source": [
    "evaluation1 = classification_model_cwru_pretrained.evaluate(ds_test_ft)\n",
    "\n",
    "print(\"Evaluation accuracy with pretraining on encoder: {:.2f}%\".format(evaluation1[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - accuracy: 0.0629 - loss: 3.4001 - val_accuracy: 0.0742 - val_loss: 3.3390\n",
      "Epoch 2/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.1775 - loss: 2.9924 - val_accuracy: 0.1445 - val_loss: 3.3043\n",
      "Epoch 3/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.2572 - loss: 2.7061 - val_accuracy: 0.1654 - val_loss: 3.2642\n",
      "Epoch 4/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 341ms/step - accuracy: 0.3275 - loss: 2.4490 - val_accuracy: 0.1914 - val_loss: 3.2196\n",
      "Epoch 5/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.3917 - loss: 2.2476 - val_accuracy: 0.2318 - val_loss: 3.1745\n",
      "Epoch 6/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 341ms/step - accuracy: 0.4560 - loss: 2.0678 - val_accuracy: 0.2227 - val_loss: 3.1305\n",
      "Epoch 7/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.5171 - loss: 1.9121 - val_accuracy: 0.1901 - val_loss: 3.0875\n",
      "Epoch 8/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.6034 - loss: 1.7431 - val_accuracy: 0.2096 - val_loss: 3.0397\n",
      "Epoch 9/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 347ms/step - accuracy: 0.6381 - loss: 1.6259 - val_accuracy: 0.2279 - val_loss: 2.9870\n",
      "Epoch 10/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 341ms/step - accuracy: 0.7029 - loss: 1.4516 - val_accuracy: 0.2812 - val_loss: 2.9317\n",
      "Epoch 11/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 347ms/step - accuracy: 0.7290 - loss: 1.3391 - val_accuracy: 0.3529 - val_loss: 2.8714\n",
      "Epoch 12/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 342ms/step - accuracy: 0.7270 - loss: 1.2581 - val_accuracy: 0.3789 - val_loss: 2.8091\n",
      "Epoch 13/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 347ms/step - accuracy: 0.7599 - loss: 1.1630 - val_accuracy: 0.4010 - val_loss: 2.7417\n",
      "Epoch 14/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 343ms/step - accuracy: 0.7793 - loss: 1.0941 - val_accuracy: 0.4388 - val_loss: 2.6592\n",
      "Epoch 15/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 341ms/step - accuracy: 0.8048 - loss: 1.0105 - val_accuracy: 0.4857 - val_loss: 2.5657\n",
      "Epoch 16/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 345ms/step - accuracy: 0.8411 - loss: 0.9005 - val_accuracy: 0.5273 - val_loss: 2.4691\n",
      "Epoch 17/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 341ms/step - accuracy: 0.8554 - loss: 0.8236 - val_accuracy: 0.5677 - val_loss: 2.3650\n",
      "Epoch 18/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 346ms/step - accuracy: 0.8619 - loss: 0.8000 - val_accuracy: 0.5859 - val_loss: 2.2687\n",
      "Epoch 19/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 347ms/step - accuracy: 0.8872 - loss: 0.7257 - val_accuracy: 0.6055 - val_loss: 2.1627\n",
      "Epoch 20/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.8853 - loss: 0.6909 - val_accuracy: 0.6237 - val_loss: 2.0415\n",
      "Epoch 21/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 344ms/step - accuracy: 0.8962 - loss: 0.6341 - val_accuracy: 0.6471 - val_loss: 1.9078\n",
      "Epoch 22/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.9173 - loss: 0.5697 - val_accuracy: 0.6641 - val_loss: 1.7815\n",
      "Epoch 23/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 344ms/step - accuracy: 0.9201 - loss: 0.5185 - val_accuracy: 0.6849 - val_loss: 1.6617\n",
      "Epoch 24/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 346ms/step - accuracy: 0.9387 - loss: 0.4904 - val_accuracy: 0.6732 - val_loss: 1.5655\n",
      "Epoch 25/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.9379 - loss: 0.4729 - val_accuracy: 0.6875 - val_loss: 1.4592\n",
      "Epoch 26/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 344ms/step - accuracy: 0.9399 - loss: 0.4567 - val_accuracy: 0.7018 - val_loss: 1.3468\n",
      "Epoch 27/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 341ms/step - accuracy: 0.9478 - loss: 0.4139 - val_accuracy: 0.7148 - val_loss: 1.2549\n",
      "Epoch 28/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 342ms/step - accuracy: 0.9671 - loss: 0.3698 - val_accuracy: 0.7188 - val_loss: 1.1631\n",
      "Epoch 29/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 345ms/step - accuracy: 0.9726 - loss: 0.3220 - val_accuracy: 0.7279 - val_loss: 1.0876\n",
      "Epoch 30/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.9684 - loss: 0.3142 - val_accuracy: 0.7266 - val_loss: 1.0452\n",
      "Epoch 31/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 342ms/step - accuracy: 0.9716 - loss: 0.3054 - val_accuracy: 0.7305 - val_loss: 0.9977\n",
      "Epoch 32/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.9776 - loss: 0.2888 - val_accuracy: 0.7318 - val_loss: 0.9492\n",
      "Epoch 33/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 344ms/step - accuracy: 0.9803 - loss: 0.2662 - val_accuracy: 0.7422 - val_loss: 0.9177\n",
      "Epoch 34/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 344ms/step - accuracy: 0.9804 - loss: 0.2483 - val_accuracy: 0.7383 - val_loss: 0.8876\n",
      "Epoch 35/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.9864 - loss: 0.2163 - val_accuracy: 0.7487 - val_loss: 0.8494\n",
      "Epoch 36/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 346ms/step - accuracy: 0.9863 - loss: 0.1989 - val_accuracy: 0.7513 - val_loss: 0.8383\n",
      "Epoch 37/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.9854 - loss: 0.1978 - val_accuracy: 0.7539 - val_loss: 0.8258\n",
      "Epoch 38/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 346ms/step - accuracy: 0.9876 - loss: 0.1857 - val_accuracy: 0.7526 - val_loss: 0.8080\n",
      "Epoch 39/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 343ms/step - accuracy: 0.9896 - loss: 0.1818 - val_accuracy: 0.7591 - val_loss: 0.7994\n",
      "Epoch 40/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.9921 - loss: 0.1724 - val_accuracy: 0.7565 - val_loss: 0.7950\n",
      "Epoch 41/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 345ms/step - accuracy: 0.9936 - loss: 0.1476 - val_accuracy: 0.7565 - val_loss: 0.7852\n",
      "Epoch 42/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 347ms/step - accuracy: 0.9957 - loss: 0.1321 - val_accuracy: 0.7617 - val_loss: 0.7761\n",
      "Epoch 43/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.9883 - loss: 0.1398 - val_accuracy: 0.7617 - val_loss: 0.7703\n",
      "Epoch 44/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 343ms/step - accuracy: 0.9925 - loss: 0.1296 - val_accuracy: 0.7643 - val_loss: 0.7675\n",
      "Epoch 45/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 342ms/step - accuracy: 0.9957 - loss: 0.1200 - val_accuracy: 0.7643 - val_loss: 0.7675\n",
      "Epoch 46/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.9943 - loss: 0.1176 - val_accuracy: 0.7682 - val_loss: 0.7645\n",
      "Epoch 47/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 343ms/step - accuracy: 0.9973 - loss: 0.1035 - val_accuracy: 0.7604 - val_loss: 0.7586\n",
      "Epoch 48/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.9957 - loss: 0.0922 - val_accuracy: 0.7630 - val_loss: 0.7541\n",
      "Epoch 49/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 343ms/step - accuracy: 0.9984 - loss: 0.0879 - val_accuracy: 0.7669 - val_loss: 0.7550\n",
      "Epoch 50/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 343ms/step - accuracy: 0.9959 - loss: 0.0924 - val_accuracy: 0.7721 - val_loss: 0.7519\n",
      "Epoch 51/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 341ms/step - accuracy: 0.9978 - loss: 0.0884 - val_accuracy: 0.7630 - val_loss: 0.7526\n",
      "Epoch 52/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 346ms/step - accuracy: 0.9978 - loss: 0.0841 - val_accuracy: 0.7656 - val_loss: 0.7549\n",
      "Epoch 53/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 343ms/step - accuracy: 0.9989 - loss: 0.0768 - val_accuracy: 0.7669 - val_loss: 0.7522\n",
      "Epoch 54/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.9974 - loss: 0.0670 - val_accuracy: 0.7734 - val_loss: 0.7468\n",
      "Epoch 55/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 342ms/step - accuracy: 0.9987 - loss: 0.0633 - val_accuracy: 0.7721 - val_loss: 0.7452\n",
      "Epoch 56/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 343ms/step - accuracy: 0.9978 - loss: 0.0672 - val_accuracy: 0.7773 - val_loss: 0.7457\n",
      "Epoch 57/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.9991 - loss: 0.0628 - val_accuracy: 0.7734 - val_loss: 0.7467\n",
      "Epoch 58/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 342ms/step - accuracy: 0.9995 - loss: 0.0606 - val_accuracy: 0.7760 - val_loss: 0.7486\n",
      "Epoch 59/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 344ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.7669 - val_loss: 0.7506\n",
      "Epoch 60/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 1.0000 - loss: 0.0514 - val_accuracy: 0.7747 - val_loss: 0.7438\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(input_shape,n_embedding,kernel_size)\n",
    "\n",
    "simclr_model = SimCLRModel(encoder)\n",
    "\n",
    "# Freeze the encoder weights\n",
    "simclr_model.encoder.trainable = False\n",
    "\n",
    "classification_head_ft= keras.Sequential([\n",
    "    layers.Input(shape=(n_embedding,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(len(lb1)) #nb labels\n",
    "], name='Classification_head')\n",
    "\n",
    "# Create a new classification model\n",
    "encoder_output = simclr_model.encoder(simclr_model.encoder.layers[0].input, training=False)\n",
    "simclr_model_not_pretrained = keras.Model(\n",
    "    inputs=simclr_model.encoder.layers[0].input,\n",
    "    outputs=classification_head_ft(encoder_output)\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=3,       \n",
    "    restore_best_weights=True  \n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.1,         \n",
    "    patience=2          \n",
    ")\n",
    "\n",
    "simclr_model_not_pretrained.compile(\n",
    "    optimizer=keras.optimizers.Adam(), \n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "classification_history = simclr_model_not_pretrained.fit(\n",
    "    ds_train_ft.repeat(), \n",
    "    epochs=60, \n",
    "    validation_data=ds_val_ft, \n",
    "    steps_per_epoch=int((0.1*ds_test_size) // batch_size),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13873/13873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 21ms/step - accuracy: 0.7675 - loss: 0.7493\n",
      "Evaluation accuracy with pretraining on encoder: 77.25%\n"
     ]
    }
   ],
   "source": [
    "evaluation1 = simclr_model_not_pretrained.evaluate(ds_test_ft)\n",
    "\n",
    "print(\"Evaluation accuracy with pretraining on encoder: {:.2f}%\".format(evaluation1[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
