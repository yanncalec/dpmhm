{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19108fd3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SimCLR and Transfer Learning\n",
    "\n",
    "We train a SimCLR base model on a meta-dataset, then transfer it to a CWRU few-shot dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c2594b9-86f8-4878-8a7f-cf22385c41c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %xmode minimal\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # disable GPU devices\n",
    "os.environ[\"TFDS_DATA_DIR\"] = os.path.expanduser(\"~/tensorflow_datasets\")  # default location of tfds database\n",
    "\n",
    "# Turn off logging for TF\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "# import librosa\n",
    "# import librosa.display\n",
    "# from IPython.display import Audio\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())\n",
    "\n",
    "import keras\n",
    "from keras import layers, models, ops, losses, metrics\n",
    "# from keras.applications import resnet, vgg16\n",
    "\n",
    "# tf.config.experimental_run_functions_eagerly(True)\n",
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d2156e-ff0a-4fcc-9583-d0a6243df559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dpmhm\n",
    "# dpmhm.datasets.get_dataset_list()\n",
    "\n",
    "from dpmhm.datasets import preprocessing, transformer, feature, utils, spectral_window_pipeline, spectral_pipeline\n",
    "from dpmhm.models import simclr\n",
    "\n",
    "workdir = Path(os.path.expanduser(\"~/tmp/dpmhm/SimCLR-fewshot\"))\n",
    "os.makedirs(workdir, exist_ok=True)\n",
    "\n",
    "# dpmhm.datasets.query_parameters('Paderborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af4d011a-a7cb-4918-ba09-5d76a3c47cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pipeline(ds_name:str, sr:int, *, \n",
    "              split:str='all', channels:list[str]=[], keys:list[str]=[],\n",
    "              nf:int=512, tw:float=None, hs:float=None, ws:int=128, \n",
    "              normalize:bool=True,\n",
    "              labels:bool=False):\n",
    "    \"\"\"Simple pipeline of data extraction for sliding window.\n",
    "    \n",
    "    Args:\n",
    "        ds_name: name of dataset\n",
    "        sr: original sampling rate\n",
    "        split: active split of dataset\n",
    "        channels: list of active channels\n",
    "        nf: number of frequency bins\n",
    "        tw: time window in second for spectrogram\n",
    "        hs: hop size in window for spectrogram\n",
    "        ws: sliding window size in frequency and time axis\n",
    "    \"\"\"        \n",
    "    if tw is None:\n",
    "        tw = nf / sr\n",
    "    if hs is None:\n",
    "        hs = tw / 4\n",
    "        \n",
    "    _func = lambda x, sr: feature.spectral_features(\n",
    "        x, sr, 'spectrogram',\n",
    "        time_window=tw, \n",
    "        hop_step=hs, \n",
    "        n_fft=nf,\n",
    "        normalize=normalize, to_db=True)[0]\n",
    "    \n",
    "    compactor_kwargs = dict(\n",
    "        resampling_rate=None,\n",
    "        channels=channels,\n",
    "        keys=keys,\n",
    "        split_channel=True\n",
    "    )\n",
    "    \n",
    "    # wl = ws * hs  # time length of spectrogram patches\n",
    "    window_kwargs = dict(\n",
    "        window_size=(ws, ws), # full bandwidth\n",
    "        hop_size=(ws//2, ws//2),\n",
    "    )\n",
    "\n",
    "    extractor, compactor, _ = dpmhm.datasets.spectral_pipeline(\n",
    "        ds_name, \n",
    "        split=split,\n",
    "        spectral_feature=_func,\n",
    "        compactor_kwargs=compactor_kwargs,\n",
    "        shuffle_files=True        \n",
    "    )\n",
    "\n",
    "    window = transformer.WindowSlider(\n",
    "        extractor.dataset,\n",
    "        **window_kwargs\n",
    "        )\n",
    "    dw = window.dataset\n",
    "\n",
    "    # dw = dpmhm.datasets.spectral_window_pipeline(\n",
    "    #     ds_name, \n",
    "    #     split=split,\n",
    "    #     spectral_feature=_func,\n",
    "    #     compactor_kwargs=compactor_kwargs,\n",
    "    #     window_kwargs=window_kwargs,\n",
    "    #     shuffle_files=True        \n",
    "    # )\n",
    "\n",
    "    if labels:\n",
    "        return dw, compactor.full_label_dict\n",
    "    else:\n",
    "        return dw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6c5e43-be47-4cc8-9020-93e8e3ee35a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build a meta-dataset\n",
    "\n",
    "First we load several datasets and extract spectrogram patches of fixed dimension `(128,128)`. This dimension is large enough to accomodate the random crop of shape `(64,64)` that will be created later by spec-augmentation. Also we skip the resampling step which will considerable slow down the loading of datasets, and take randomly the first `Nmax` elements to reduce the size of the final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2841c3e-574b-4aed-af87-e5f9ed8c6a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all = {}\n",
    "\n",
    "nf = 1024  # number of frequency bins\n",
    "Nmax = 2500  # maximum number of elements per dataset\n",
    "shuffle_size = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "162af750-330e-4fd0-9654-8cfb4537cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = _pipeline('DIRG', 51200, split='variation', channels=[], nf=nf)\n",
    "# ds_all['DIRG'] = foo\n",
    "ds_all['DIRG'] = utils.restore_cardinality(foo.shuffle(shuffle_size).take(Nmax))\n",
    "\n",
    "foo = _pipeline('Paderborn', 64000, split='healthy[:10%]+artificial[:10%]', channels=['vibration'], nf=nf)\n",
    "# ds_all['Paderborn'] = foo\n",
    "ds_all['Paderborn'] = utils.restore_cardinality(foo.shuffle(shuffle_size).take(Nmax))\n",
    "\n",
    "foo = _pipeline('Ottawa', 200000, split='all', channels=[], nf=nf)\n",
    "# ds_all['Ottawa'] = foo\n",
    "ds_all['Ottawa'] = utils.restore_cardinality(foo.shuffle(shuffle_size).take(Nmax))\n",
    "\n",
    "foo = _pipeline('Phmap2021', 10544, split='train[:50%]', channels=[], nf=nf)\n",
    "# ds_all['Phmap2021'] = foo\n",
    "ds_all['Phmap2021'] = utils.restore_cardinality(foo.shuffle(shuffle_size).take(Nmax))\n",
    "\n",
    "# eles = list(foo.take(10).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb4565f3-7ad8-4a6e-bcb5-c7df951915a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIRG 2500\n",
      "Paderborn 2500\n",
      "Ottawa 2500\n",
      "Phmap2021 2500\n"
     ]
    }
   ],
   "source": [
    "ds_size = 0\n",
    "for k, foo in ds_all.items():\n",
    "    print(k, int(foo.cardinality()))\n",
    "    ds_size += int(foo.cardinality())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27d74a4b-1b9f-45f5-bb75-b3c2634714db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialization for better performance.\n",
    "# Note that this should be done before the random augmentation.\n",
    "\n",
    "ds1, ds2, ds3, ds4 = ds_all['DIRG'], ds_all['Paderborn'], ds_all['Ottawa'], ds_all['Phmap2021']\n",
    "\n",
    "ds0 = ds1.concatenate(ds2).concatenate(ds3).concatenate(ds4)\n",
    "\n",
    "ds0.save(str(workdir/'simclr_dataset'))\n",
    "ds0 = tf.data.Dataset.load(str(workdir/'simclr_dataset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deb0823d-7846-4ade-81f9-eacb31ed9edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(64, 64, 1), dtype=tf.float32, name=None),\n",
       "  TensorSpec(shape=(64, 64, 1), dtype=tf.float32, name=None)),\n",
       " TensorSpec(shape=(), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_shape = (64, 64)\n",
    "\n",
    "dst = transformer.SpecAugmentTwins(\n",
    "    ds0,\n",
    "    output_shape=window_shape,\n",
    "    crop_kwargs={'prob':0.5},\n",
    "    flip_kwargs={'axis':-1, 'prob':0.5},\n",
    "    blur_kwargs={'sigma':1., 'prob':0.5},\n",
    "    fade_kwargs={'prob':0},\n",
    ").dataset.map(\n",
    "    lambda y1, y2: (tf.transpose(y1, perm=(1,2,0)), tf.transpose(y2, perm=(1,2,0)))  # to channel-last\n",
    ")\n",
    "\n",
    "ds = tf.data.Dataset.zip(dst, utils.constant_dataset())\n",
    "\n",
    "# ds = utils.restore_cardinality(ds, ds_size)\n",
    "input_shape = ds.element_spec[0][0].shape\n",
    "\n",
    "ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b26fb842-f52b-4995-89c1-dd8b6e3b7324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Serialization may disable the random augmentation\n",
    "\n",
    "# ds.save(str(workdir/'simclr_dataset'))\n",
    "# ds = tf.data.Dataset.load(str(workdir/'simclr_dataset'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf217b1-20bd-428f-9fd7-db5f6447ee12",
   "metadata": {},
   "source": [
    "## Base SimCLR model\n",
    "\n",
    "We train a base SimCLR model on the meta-dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22294c27-1e4a-4601-b653-c19b3f272f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(256, 64, 64, 1), dtype=tf.float32, name=None),\n",
       "  TensorSpec(shape=(256, 64, 64, 1), dtype=tf.float32, name=None)),\n",
       " TensorSpec(shape=(256,), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "ds_train = ds.shuffle(ds_size, reshuffle_each_iteration=True)\\\n",
    "    .repeat()\\\n",
    "    .batch(batch_size, drop_remainder=True)\\\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    "# ds_val = ds_split['val'].batch(batch_size, drop_remainder=True)\n",
    "# ds_test = ds_split['test'].batch(1, drop_remainder=True)\n",
    "\n",
    "ds_train.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b55598a-4f7c-4905-acf7-108805617b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sim_clr_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sim_clr_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,142,272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ projector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder (\u001b[38;5;33mSequential\u001b[0m)            │ ?                      │     \u001b[38;5;34m1,142,272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ projector (\u001b[38;5;33mSequential\u001b[0m)          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,142,272</span> (4.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,142,272\u001b[0m (4.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,141,824</span> (4.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,141,824\u001b[0m (4.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# encoder_kwargs = dict(include_top=False, weights='imagenet', pooling='avg')\n",
    "# encoder_kwargs = dict(include_top=False, weights=None, pooling='avg')\n",
    "# model = dpmhm.models.simclr.SimCLR(input_shape, name='VGG16', tau=0.1, **encoder_kwargs)\n",
    "\n",
    "model = dpmhm.models.simclr.SimCLR(input_shape, name='CNN', tau=0.1)\n",
    "\n",
    "model._encoder.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d22744-8004-4ed8-aee1-ed5138ac3c23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 4s/step - loss: 3045046.2500\n",
      "Epoch 2/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 3s/step - loss: 2810577.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 3s/step - loss: 2746814.2500\n",
      "Epoch 4/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 3s/step - loss: 2681460.5000\n",
      "Epoch 5/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 3s/step - loss: 2583657.2500\n",
      "Epoch 6/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 4s/step - loss: 2548780.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m30/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m31s\u001b[0m 4s/step - loss: 2486216.7500"
     ]
    }
   ],
   "source": [
    "hh = model.fit(ds_train,\n",
    "               # validation_data=ds_val,\n",
    "               steps_per_epoch=ds_size // batch_size,\n",
    "               epochs=10)\n",
    "\n",
    "model.save(workdir/'simclr_base.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3857e18d-ac3c-4b45-a437-e07ab41055e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(model.history.history['loss'])\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Loss')\n",
    "fig.savefig(workdir/'convergence.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d2f9a6-5754-4247-a368-76ad2dc062ba",
   "metadata": {},
   "source": [
    "From the trained SimCLR model, we extract the feature transformation part which includes the base encoder and the first two dense layers of the projection head. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8a9ef99-19de-4186-8df4-9c6127753012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"SimCLR_feature\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"SimCLR_feature\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,694</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,166,464</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_2 (\u001b[38;5;33mFunctional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │    \u001b[38;5;34m14,714,694\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_7 (\u001b[38;5;33mFunctional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m3,166,464\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,881,158</span> (68.21 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,881,158\u001b[0m (68.21 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,872,966</span> (68.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,872,966\u001b[0m (68.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> (32.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m8,192\u001b[0m (32.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m model_feature \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39mx, outputs\u001b[38;5;241m=\u001b[39mf, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSimCLR_feature\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m model_feature\u001b[38;5;241m.\u001b[39msummary()  \u001b[38;5;66;03m# shows `None` for batch\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmodel_feature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mworkdir\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msimclr_feature.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/cache/.cache/pypoetry/virtualenvs/dpmhm-yVS8YoI0-py3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/mnt/cache/.cache/pypoetry/virtualenvs/dpmhm-yVS8YoI0-py3.11/lib/python3.11/site-packages/keras/src/backend/common/variables.py:219\u001b[0m, in \u001b[0;36mKerasVariable.value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_autocast(value)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# Uninitialized variable. Return a placeholder.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# This is fine because it's only ever used\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# in during shape inference / graph tracing\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# (anything else would be a bug, to be fixed.)\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_autocast(\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initializer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     )\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_autocast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "x = layers.Input(input_shape)\n",
    "\n",
    "# same same\n",
    "# _proj = models.Model(inputs=model._projector.inputs, outputs=model._projector.layers[3].output)\n",
    "_proj = models.Model(inputs=model._projector.layers[0].input, outputs=model._projector.layers[3].output)\n",
    "\n",
    "# _proj.summary()  # shows a concrete value for batch\n",
    "\n",
    "f = _proj(model._encoder(x))\n",
    "\n",
    "model_feature = models.Model(inputs=x, outputs=f, name='SimCLR_feature')\n",
    "\n",
    "model_feature.summary()  # shows `None` for batch\n",
    "\n",
    "model_feature.save(str(workdir/'simclr_feature.keras'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832377ed-b314-4011-9155-50058405330b",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c6f13ac5-71ad-4fcd-8730-5a4847ac9e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo, full_labels_dict = _pipeline(\n",
    "    'CWRU', 12000, split='all', \n",
    "    channels=[], keys=['FaultLocation', 'FaultComponent', 'FaultSize'], \n",
    "    nf=nf, ws=64, labels=True\n",
    ")\n",
    "\n",
    "labels = list(full_labels_dict.keys())  \n",
    "n_classes = len(labels) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec6b4760-e041-443c-9abb-76d36505aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = preprocessing.get_mapping_supervised(labels)\n",
    "\n",
    "dw = utils.restore_cardinality(\n",
    "    utils.restore_shape(\n",
    "        foo.map(preproc, num_parallel_calls=tf.data.AUTOTUNE),\n",
    "        key=0\n",
    "    )\n",
    ")\n",
    "\n",
    "dw_size = int(dw.cardinality())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "855b5e7c-c8d5-4571-99e6-b3c5c04bdb13",
   "metadata": {},
   "source": [
    "### Supervised fine tuning\n",
    "\n",
    "We add a classification head to the feature transformation network and fine tune the model on some new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "717a9296-8be7-4778-8449-b6733f8ad454",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train':0.7, 'val':0.2, 'test':0.1}\n",
    "batch_size = 32\n",
    "\n",
    "dw_split = utils.split_dataset(\n",
    "    dw, splits, \n",
    "    ds_size=dw_size, \n",
    "    # labels=np.arange(n_classes)\n",
    ")\n",
    "\n",
    "dw_train = dw_split['train']\\\n",
    "    .shuffle(dw_size, reshuffle_each_iteration=True)\\\n",
    "    .batch(batch_size, drop_remainder=True)\\\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    "dw_val = dw_split['val'].batch(batch_size, drop_remainder=True)\n",
    "dw_test = dw_split['test'].batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a28bca4-051a-48ab-8781-884798e9ea8b",
   "metadata": {},
   "source": [
    "The classification head here is a simple MLP. The weights of the feature transformation network are frozen for the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99f13cd1-5223-4bc8-bdbd-51bc28227657",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_feature.trainable = False\n",
    "\n",
    "class_head = models.Sequential([\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(n_classes, activation=None) # nb labels\n",
    "], name='Classification_head')\n",
    "\n",
    "x = layers.Input(input_shape)\n",
    "\n",
    "model_fine = models.Model(inputs=x, outputs=class_head(model_feature(x)))\n",
    "\n",
    "model_fine.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "03fca33b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to automatically build the model. Please build it yourself before calling fit/evaluate/predict. A model is 'built' when its variables have been created and its `self.built` attribute is True. Usually, calling the model on a batch of data is the right way to build it.\nException encountered:\n'Exception encountered when calling Conv2D.call().\n\n\u001b[1m'NoneType' object is not callable\u001b[0m\n\nArguments received by Conv2D.call():\n  • inputs=jnp.ndarray(shape=(32, 64, 64, 1), dtype=float32)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hh \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_fine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdw_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdw_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/cache/.cache/pypoetry/virtualenvs/dpmhm-yVS8YoI0-py3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/mnt/cache/.cache/pypoetry/virtualenvs/dpmhm-yVS8YoI0-py3.11/lib/python3.11/site-packages/keras/src/trainers/trainer.py:999\u001b[0m, in \u001b[0;36mTrainer._symbolic_build\u001b[0;34m(self, iterator, data_batch)\u001b[0m\n\u001b[1;32m    997\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mcompute_output_spec(\u001b[38;5;28mself\u001b[39m, x)\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 999\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to automatically build the model. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease build it yourself before calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1002\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit/evaluate/predict. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1003\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA model is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuilt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m when its variables have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1004\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeen created and its `self.built` attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1005\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis True. Usually, calling the model on a batch \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1006\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof data is the right way to build it.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1007\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException encountered:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1008\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1009\u001b[0m     )\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compile_metrics_unbuilt:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;66;03m# Build all metric state with `backend.compute_output_spec`.\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m     backend\u001b[38;5;241m.\u001b[39mcompute_output_spec(\n\u001b[1;32m   1013\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics,\n\u001b[1;32m   1014\u001b[0m         x,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1018\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unable to automatically build the model. Please build it yourself before calling fit/evaluate/predict. A model is 'built' when its variables have been created and its `self.built` attribute is True. Usually, calling the model on a batch of data is the right way to build it.\nException encountered:\n'Exception encountered when calling Conv2D.call().\n\n\u001b[1m'NoneType' object is not callable\u001b[0m\n\nArguments received by Conv2D.call():\n  • inputs=jnp.ndarray(shape=(32, 64, 64, 1), dtype=float32)'"
     ]
    }
   ],
   "source": [
    "hh = model_fine.fit(\n",
    "    dw_train,\n",
    "    validation_data=dw_val,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2cabf96a-e1b5-4f89-8803-f3e5828f8127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 294ms/step - loss: 2.8925 - sparse_categorical_accuracy: 0.1254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.8936824798583984, 0.140625]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fine.evaluate(dw_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8fc623-6aa1-4421-bb2e-ce9c3c9300ed",
   "metadata": {},
   "source": [
    "#### Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dff02a2d-fa67-49c3-b1cf-92c19f8a0b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_feature.trainable = True\n",
    "\n",
    "model_fine.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-5),\n",
    "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1d1371f-4fba-42c5-90a8-a313e98c7013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - loss: 4.6855 - sparse_categorical_accuracy: 0.0234 - val_loss: 3.5561 - val_sparse_categorical_accuracy: 0.0368\n",
      "Epoch 2/2\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 1s/step - loss: 4.5819 - sparse_categorical_accuracy: 0.0189 - val_loss: 3.8871 - val_sparse_categorical_accuracy: 0.0402\n"
     ]
    }
   ],
   "source": [
    "hh = model_fine.fit(\n",
    "    dw_train,\n",
    "    validation_data=dw_val,\n",
    "    epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6be4ab2f-3a8d-4b5f-8bc1-824aa3376afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 305ms/step - loss: 3.7828 - sparse_categorical_accuracy: 0.0330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.748819589614868, 0.0357142873108387]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fine.evaluate(dw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02196684-d04a-48da-a664-2e3e6dd24b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c933834b-8f37-4d09-aa08-857c028148da",
   "metadata": {},
   "source": [
    "# EOF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43cb9215-3271-4fbc-8cb7-d811eb46fa44",
   "metadata": {},
   "source": [
    "### Few-shot learning\n",
    "\n",
    "In few-shot learning the number of new data per category is limited. We can prepare the data for few-shot learning by splitting separately data of each category.\n",
    "\n",
    "However for unknown reasons, the performance of the few-shot split seems to be very low compared to the normal split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c4d286-ae74-4374-b024-bc56802185d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train':0.2, 'val':0.7, 'test':0.1}\n",
    "batch_size = 64\n",
    "\n",
    "n_classes = len(labels) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1900905-2159-4730-811c-1cad58aed4c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Only for demonstration, here we apply the preprocessing after the split.\n",
    "dw_split = utils.split_dataset(\n",
    "    dw, splits, \n",
    "    labels=labels\n",
    ")\n",
    "\n",
    "for k, dv in dw_split.items():\n",
    "    dv.save(str(workdir/f'fs_split_{k}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "da1feab5-99b4-47bf-b74a-65635826a62b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dw_split = {}\n",
    "for k in splits.keys():\n",
    "    dw_split[k] = tf.data.Dataset.load(str(workdir/f'fs_split_{k}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cd30de0d-b0e0-4f39-8be6-3dbef83e7571",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dw_train = dw_split['train']\\\n",
    "    .map(preproc, num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "    .shuffle(1000, reshuffle_each_iteration=True)\\\n",
    "    .batch(batch_size, drop_remainder=True)\\\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    "dw_val = dw_split['val']\\\n",
    "    .map(preproc, num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "    .batch(batch_size, drop_remainder=True)\n",
    "dw_test = dw_split['test']\\\n",
    "    .map(preproc, num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "    .batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d28dcbc1-3624-4287-a9d1-aa2c439b6034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 172 ms, sys: 13.4 ms, total: 185 ms\n",
      "Wall time: 58.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 23:51:57.085419: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "%time eles = list(dw_train.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36605327-877a-4028-835d-1a03a2ee7610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eles[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a922e20b-8274-4f63-8781-2d83536e7413",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_feature(eles[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "09665753-31d0-46bc-b4dd-62ea791ca6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_feature.trainable = False\n",
    "\n",
    "class_head = models.Sequential([\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(n_classes) # nb labels\n",
    "], name='Classification_head')\n",
    "\n",
    "x = layers.Input(input_shape)\n",
    "\n",
    "model_fs = models.Model(inputs=x, outputs=class_head(model_feature(x)))\n",
    "\n",
    "model_fs.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3990ecfe-8645-4cc1-9d2c-b926ae95d899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to automatically build the model. Please build it yourself before calling fit/evaluate/predict. A model is 'built' when its variables have been created and its `self.built` attribute is True. Usually, calling the model on a batch of data is the right way to build it.\nException encountered:\n'Exception encountered when calling Conv2D.call().\n\n\u001b[1m'NoneType' object is not callable\u001b[0m\n\nArguments received by Conv2D.call():\n  • inputs=jnp.ndarray(shape=(64, 70, 70, 3), dtype=float32)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hh \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_fs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdw_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdw_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/cache/.cache/pypoetry/virtualenvs/dpmhm-yVS8YoI0-py3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/mnt/cache/.cache/pypoetry/virtualenvs/dpmhm-yVS8YoI0-py3.11/lib/python3.11/site-packages/keras/src/trainers/trainer.py:999\u001b[0m, in \u001b[0;36mTrainer._symbolic_build\u001b[0;34m(self, iterator, data_batch)\u001b[0m\n\u001b[1;32m    997\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mcompute_output_spec(\u001b[38;5;28mself\u001b[39m, x)\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 999\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to automatically build the model. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease build it yourself before calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1002\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit/evaluate/predict. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1003\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA model is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuilt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m when its variables have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1004\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeen created and its `self.built` attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1005\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis True. Usually, calling the model on a batch \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1006\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof data is the right way to build it.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1007\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException encountered:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1008\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1009\u001b[0m     )\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compile_metrics_unbuilt:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;66;03m# Build all metric state with `backend.compute_output_spec`.\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m     backend\u001b[38;5;241m.\u001b[39mcompute_output_spec(\n\u001b[1;32m   1013\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics,\n\u001b[1;32m   1014\u001b[0m         x,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1018\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unable to automatically build the model. Please build it yourself before calling fit/evaluate/predict. A model is 'built' when its variables have been created and its `self.built` attribute is True. Usually, calling the model on a batch of data is the right way to build it.\nException encountered:\n'Exception encountered when calling Conv2D.call().\n\n\u001b[1m'NoneType' object is not callable\u001b[0m\n\nArguments received by Conv2D.call():\n  • inputs=jnp.ndarray(shape=(64, 70, 70, 3), dtype=float32)'"
     ]
    }
   ],
   "source": [
    "hh = model_fs.fit(\n",
    "    dw_train,\n",
    "    validation_data=dw_val,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1029de-e257-4da5-a740-4e701503930f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 23:41:21.174297: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-18 23:41:22.954204: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-18 23:41:24.714093: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-18 23:41:26.471666: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-18 23:41:28.231720: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-18 23:41:30.062777: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-18 23:41:31.896178: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-18 23:41:33.754727: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-18 23:41:35.616732: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-18 23:41:37.484919: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-18 23:41:39.284917: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-18 23:41:41.137899: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-18 23:41:42.974720: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-18 23:41:44.735700: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-18 23:41:46.547159: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-18 23:41:48.315764: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-18 23:41:50.082965: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-18 23:41:51.906632: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-18 23:41:53.679263: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-18 23:41:55.533645: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-18 23:41:57.320201: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-18 23:41:59.171508: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-18 23:42:00.959659: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-18 23:42:02.749389: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "model_fs.evaluate(dw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db76559-b74e-4597-ae38-d304547c5528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "801d1599-bf56-4d84-9f6a-49fd3b5fde55",
   "metadata": {},
   "source": [
    "# EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43879b32-a669-4a60-933c-3c01f130cff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9536518b-16c5-4767-99c2-7ba6c18854fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_shape = (64, 64)\n",
    "ds_window = {}\n",
    "\n",
    "for k, ds in ds_all.items():\n",
    "    ds_window[k] = transformer.SpecAugmentTwins(\n",
    "        ds,\n",
    "        output_shape=window_shape,\n",
    "        crop_kwargs={'prob':1},\n",
    "        flip_kwargs={'axis':-1, 'prob':0.5},\n",
    "        blur_kwargs={'sigma':1., 'prob':0.5},\n",
    "        fade_kwargs={'prob':0},\n",
    "    ).dataset.map(\n",
    "        lambda y1, y2: (tf.transpose(y1, perm=(1,2,0)), tf.transpose(y2, perm=(1,2,0)))  # to channel-last\n",
    "    )\n",
    "\n",
    "# for k, ds in ds_all.items():\n",
    "#     ds_window[k] = transformer.SpecAugment(\n",
    "#         ds,\n",
    "#         output_shape=window_shape,\n",
    "#         crop_kwargs={'prob':0.5},\n",
    "#         flip_kwargs={'axis':-1, 'prob':0.5},\n",
    "#         blur_kwargs={'sigma':1., 'prob':0.5},\n",
    "#         fade_kwargs={'prob':0},\n",
    "#     ).dataset.map(lambda x: x['feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ad6b78e-f3eb-4580-85b6-25740f7e7af3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(64, 64, 1), dtype=tf.float32, name=None),\n",
       "  TensorSpec(shape=(64, 64, 1), dtype=tf.float32, name=None)),\n",
       " TensorSpec(shape=(), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds1, ds2, ds3, ds4 = ds_window['DIRG'], ds_window['Paderborn'], ds_window['Ottawa'], ds_window['Phmap2021']\n",
    "\n",
    "ds0 = ds1.concatenate(ds2).concatenate(ds3).concatenate(ds4)\n",
    "ds = tf.data.Dataset.zip(ds0, utils.constant_dataset())\n",
    "# ds, input_shape = utils.twins_dataset_ssl(ds0, stack=False, fake_label=True)\n",
    "\n",
    "ds = utils.restore_cardinality(ds, ds_size)\n",
    "input_shape = ds.element_spec[0][0].shape\n",
    "\n",
    "ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2173187-d975-407f-8e49-bf292a388bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b31de2-f814-456a-880a-442261c74847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dp = tfds.load('Phmap2021', split='all')\n",
    "\n",
    "rsr = 10544\n",
    "nf = 512\n",
    "tw = nf/rsr\n",
    "hs = tw/4\n",
    "\n",
    "_func = lambda x, sr: feature.spectral_features(\n",
    "    x, sr, 'spectrogram',\n",
    "    time_window=tw, hop_step=hs, \n",
    "    n_fft=nf,\n",
    "    normalize=True, to_db=True)[0]\n",
    "\n",
    "compactor_kwargs = dict(\n",
    "    resampling_rate=rsr,\n",
    "    channels=[],\n",
    "    split_channel=True\n",
    ")\n",
    "\n",
    "extractor, compactor, n = dpmhm.datasets.spectral_pipeline(\n",
    "    'Phmap2021', _func, \n",
    "    compactor_kwargs=compactor_kwargs\n",
    ")\n",
    "\n",
    "wl = 1.\n",
    "ws = int(wl/hs)  # time length of spectrogram patches of 1s\n",
    "window_kwargs = dict(\n",
    "    window_size=ws, # full bandwidth\n",
    "    hop_size=ws//2,\n",
    ")\n",
    "\n",
    "window = transformer.WindowSlider(\n",
    "    extractor.dataset,\n",
    "    **window_kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "dp = compactor.dataset\n",
    "\n",
    "for x in dp.take(100).as_numpy_iterator():\n",
    "    print(x['signal'].shape[1]/10544, x['signal'].shape)\n",
    "\n",
    "dp = extractor.dataset\n",
    "\n",
    "for x in dp.take(100).as_numpy_iterator():\n",
    "    print(x['feature'].shape)\n",
    "\n",
    "dp = window.dataset\n",
    "\n",
    "for x in dp.take(100).as_numpy_iterator():\n",
    "    print(x['feature'].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dpmhm-yVS8YoI0-py3.11)",
   "language": "python",
   "name": "dpmhm-yvs8yoi0-py3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
